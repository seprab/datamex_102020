b'<!DOCTYPE html>\n\n<html class="client-nojs" dir="ltr" lang="en">\n<head>\n<meta charset="utf8"/>\n<title>Semi-supervised learning - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"155a2a9a-b9be-4a61-80a1-040815518355","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Semi-supervised_learning","wgTitle":"Semi-supervised learning","wgCurRevisionId":984076465,"wgRevisionId":984076465,"wgArticleId":2829632,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","Harv and Sfn no-target errors","CS1 maint: multiple names: authors list","CS1 Russian-language sources (ru)","All accuracy disputes","Articles with disputed statements from November 2017","CS1 maint: ref=harv","Machine learning"],\n"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Semi-supervised_learning","wgRelevantArticleId":2829632,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q1041418"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options"\n:"loading","ext.math.styles":"ready","ext.cite.styles":"ready","skins.vector.styles.legacy":"ready","mediawiki.toc.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.math.scripts","ext.cite.ux-enhancements","ext.scribunto.logs","site","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta content="" name="ResourceLoaderDynamicStyles"/>\n<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<meta content="MediaWiki 1.36.0-wmf.14" name="generator"/>\n<meta content="origin" name="referrer"/>\n<meta content="origin-when-crossorigin" name="referrer"/>\n<meta content="origin-when-cross-origin" name="referrer"/>\n<meta content="https://upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png" property="og:image"/>\n<link href="//en.m.wikipedia.org/wiki/Semi-supervised_learning" media="only screen and (max-width: 720px)" rel="alternate"/>\n<link href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>\n<link href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" rel="edit" title="Edit this page"/>\n<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>\n<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>\n<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>\n<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>\n<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>\n<link href="https://en.wikipedia.org/wiki/Semi-supervised_learning" rel="canonical"/>\n<link href="//login.wikimedia.org" rel="dns-prefetch"/>\n<link href="//meta.wikimedia.org" rel="dns-prefetch"/>\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Semi-supervised_learning rootpage-Semi-supervised_learning skin-vector action-view skin-vector-legacy"><div class="noprint" id="mw-page-base"></div>\n<div class="noprint" id="mw-head-base"></div>\n<div class="mw-body" id="content" role="main">\n<a id="top"></a>\n<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>\n<div class="mw-indicators mw-body-content">\n</div>\n<h1 class="firstHeading" id="firstHeading" lang="en">Semi-supervised learning</h1>\n<div class="mw-body-content" id="bodyContent">\n<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>\n<div id="contentSub"></div>\n<div id="contentSub2"></div>\n<div id="jump-to-nav"></div>\n<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n<a class="mw-jump-link" href="#searchInput">Jump to search</a>\n<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><td style="padding-top:0.4em;line-height:1.2em">Part of a series on</td></tr><tr><th style="padding:0.2em 0.4em 0.2em;padding-top:0;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a><br/>and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a class="mw-selflink selflink">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="display:inline-block; padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>\xc2\xa0\xe2\x80\xa2 <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a class="mw-redirect" href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li>\n<li><a href="/wiki/Echo_state_network" title="Echo state network">ESN</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li>\n<li><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<div class="thumb tright"><div class="thumbinner" style="width:196px;"><a class="image" href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png"><img alt="" class="thumbimage" data-file-height="449" data-file-width="388" decoding="async" height="225" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/194px-Example_of_unlabeled_data_in_semisupervised_learning.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/291px-Example_of_unlabeled_data_in_semisupervised_learning.png 1.5x, //upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png 2x" width="194"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png" title="Enlarge"></a></div>An example of the influence of unlabeled data in semi-supervised learning. The top panel shows a decision boundary we might adopt after seeing only one positive (white circle) and one negative (black circle) example. The bottom panel shows a decision boundary we might adopt if, in addition to the two labeled examples, we were given a collection of unlabeled data (gray circles). This could be viewed as performing <a href="/wiki/Cluster_analysis" title="Cluster analysis">clustering</a> and then labeling the clusters with the labeled data, pushing the decision boundary away from high-density regions, or learning an underlying one-dimensional manifold where the data reside.</div></div></div>\n<p><b>Semi-supervised learning</b> is an approach to <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> that combines a small amount of <a href="/wiki/Labeled_data" title="Labeled data">labeled data</a> with a large amount of unlabeled data during training. Semi-supervised learning falls between <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a> (with no labeled training data) and <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> (with only labeled training data).\n</p><p>Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render large, fully labeled training sets infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value. Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.\n</p><p>A set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle l}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>l</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle l}</annotation>\n</semantics>\n</math></span><img alt="l" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" style="vertical-align: -0.338ex; width:0.693ex; height:2.176ex;"/></span> <a class="mw-redirect" href="/wiki/Independent_identically_distributed" title="Independent identically distributed">independently identically distributed</a> examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{1},\\dots ,x_{l}\\in X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{l}\\in X}</annotation>\n</semantics>\n</math></span><img alt="x_{1},\\dots ,x_{l}\\in X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76da26bfd12e40809f4b2dae37ecca34ad1c825c" style="vertical-align: -0.671ex; width:14.435ex; height:2.509ex;"/></span> with corresponding labels <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y_{1},\\dots ,y_{l}\\in Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y_{1},\\dots ,y_{l}\\in Y}</annotation>\n</semantics>\n</math></span><img alt="y_{1},\\dots ,y_{l}\\in Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b376abba952ea1dca784912adb9a3bfd006eb6b" style="vertical-align: -0.671ex; width:13.847ex; height:2.509ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle u}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>u</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle u}</annotation>\n</semantics>\n</math></span><img alt="u" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{l+1},\\dots ,x_{l+u}\\in X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{l+1},\\dots ,x_{l+u}\\in X}</annotation>\n</semantics>\n</math></span><img alt="x_{l+1},\\dots ,x_{l+u}\\in X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/60a05a61c90d36f1a9def946c7dd83e826162b26" style="vertical-align: -0.671ex; width:18.423ex; height:2.509ex;"/></span> are processed. Semi-supervised learning combines this information to surpass the <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.\n</p><p>Semi-supervised learning may refer to either <a href="/wiki/Transduction_(machine_learning)" title="Transduction (machine learning)">transductive learning</a> or <a href="/wiki/Inductive_reasoning" title="Inductive reasoning">inductive learning</a>.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> The goal of transductive learning is to infer the correct labels for the given unlabeled data <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{l+1},\\dots ,x_{l+u}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{l+1},\\dots ,x_{l+u}}</annotation>\n</semantics>\n</math></span><img alt="x_{l+1},\\dots ,x_{l+u}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76df04fc221300e6e1d6de65cf9d4f8614280ae6" style="vertical-align: -0.671ex; width:13.602ex; height:2.009ex;"/></span> only. The goal of inductive learning is to infer the correct mapping from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n</semantics>\n</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n</semantics>\n</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span>.\n</p><p>Intuitively, the learning problem can be seen as an exam and labeled data as sample problems that the teacher solves for the class as an aid in solving another set of problems. In the transductive setting, these unsolved problems act as exam questions. In the inductive setting, they become practice problems of the sort that will make up the exam.\n</p><p>It is unnecessary (and, according to <a class="mw-redirect" href="/wiki/Vapnik%27s_principle" title="Vapnik\'s principle">Vapnik\'s principle</a>, imprudent) to perform transductive learning by way of inferring a classification rule over the entire input space; however, in practice, algorithms formally designed for transduction or induction are often used interchangeably.\n</p>\n<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Assumptions"><span class="tocnumber">1</span> <span class="toctext">Assumptions</span></a>\n<ul>\n<li class="toclevel-2 tocsection-2"><a href="#Continuity_assumption"><span class="tocnumber">1.1</span> <span class="toctext">Continuity assumption</span></a></li>\n<li class="toclevel-2 tocsection-3"><a href="#Cluster_assumption"><span class="tocnumber">1.2</span> <span class="toctext">Cluster assumption</span></a></li>\n<li class="toclevel-2 tocsection-4"><a href="#Manifold_assumption"><span class="tocnumber">1.3</span> <span class="toctext">Manifold assumption</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-5"><a href="#History"><span class="tocnumber">2</span> <span class="toctext">History</span></a></li>\n<li class="toclevel-1 tocsection-6"><a href="#Methods"><span class="tocnumber">3</span> <span class="toctext">Methods</span></a>\n<ul>\n<li class="toclevel-2 tocsection-7"><a href="#Generative_models"><span class="tocnumber">3.1</span> <span class="toctext">Generative models</span></a></li>\n<li class="toclevel-2 tocsection-8"><a href="#Low-density_separation"><span class="tocnumber">3.2</span> <span class="toctext">Low-density separation</span></a></li>\n<li class="toclevel-2 tocsection-9"><a href="#Graph-based_methods"><span class="tocnumber">3.3</span> <span class="toctext">Graph-based methods</span></a></li>\n<li class="toclevel-2 tocsection-10"><a href="#Heuristic_approaches"><span class="tocnumber">3.4</span> <span class="toctext">Heuristic approaches</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-11"><a href="#In_human_cognition"><span class="tocnumber">4</span> <span class="toctext">In human cognition</span></a></li>\n<li class="toclevel-1 tocsection-12"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-13"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>\n<li class="toclevel-1 tocsection-14"><a href="#Sources"><span class="tocnumber">7</span> <span class="toctext">Sources</span></a></li>\n<li class="toclevel-1 tocsection-15"><a href="#External_links"><span class="tocnumber">8</span> <span class="toctext">External links</span></a></li>\n</ul>\n</div>\n<h2><span class="mw-headline" id="Assumptions">Assumptions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=1" title="Edit section: Assumptions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>In order to make any use of unlabeled data, some relationship to the underlying distribution of data must exist. Semi-supervised learning algorithms make use of at least one of the following assumptions:<sup class="reference" id="cite_ref-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006_2-0"><a href="#cite_note-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006-2">[2]</a></sup>\n</p>\n<h3><span class="mw-headline" id="Continuity_assumption">Continuity assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=2" title="Edit section: Continuity assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>Points that are close to each other are more likely to share a label.</i> This is also generally assumed in supervised learning and yields a preference for geometrically simple <a href="/wiki/Decision_boundary" title="Decision boundary">decision boundaries</a>. In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes.\n</p>\n<h3><span class="mw-headline" id="Cluster_assumption">Cluster assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=3" title="Edit section: Cluster assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>The data tend to form discrete clusters, and points in the same cluster are more likely to share a label</i> (although data that shares a label may spread across multiple clusters). This is a special case of the smoothness assumption and gives rise to <a href="/wiki/Feature_learning" title="Feature learning">feature learning</a> with clustering algorithms.\n</p>\n<h3><span class="mw-headline" id="Manifold_assumption">Manifold assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=4" title="Edit section: Manifold assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>The data lie approximately on a <a href="/wiki/Manifold" title="Manifold">manifold</a> of much lower dimension than the input space.</i> In this case learning the manifold using both the labeled and unlabeled data can avoid the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>. Then learning can proceed using distances and densities defined on the manifold.\n</p><p>The manifold assumption is practical when high-dimensional data are generated by some process that may be hard to model directly, but which has only a few degrees of freedom. For instance, human voice is controlled by a few vocal folds,<sup class="reference" id="cite_ref-StevensKN_3-0"><a href="#cite_note-StevensKN-3">[3]</a></sup> and images of various facial expressions are controlled by a few muscles. In these cases distances and smoothness in the natural space of the generating problem, is superior to considering the space of all possible acoustic waves or images, respectively.\n</p>\n<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=5" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The heuristic approach of <i>self-training</i> (also known as <i>self-learning</i> or <i>self-labeling</i>) is historically the oldest approach to semi-supervised learning,<sup class="reference" id="cite_ref-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006_2-1"><a href="#cite_note-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006-2">[2]</a></sup> with examples of applications starting in the 1960s.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>\n</p><p>The transductive learning framework was formally introduced by <a href="/wiki/Vladimir_Vapnik" title="Vladimir Vapnik">Vladimir Vapnik</a> in the 1970s.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> Interest in inductive learning using generative models also began in the 1970s. A <a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning"><i>probably approximately correct</i> learning</a> bound for semi-supervised learning of a <a class="mw-redirect" href="/wiki/Gaussian" title="Gaussian">Gaussian</a> mixture was demonstrated by Ratsaby and Venkatesh in 1995.<sup class="reference" id="cite_ref-Ratsaby_6-0"><a href="#cite_note-Ratsaby-6">[6]</a></sup>\n</p><p>Semi-supervised learning has recently become more popular and practically relevant due to the variety of problems for which vast quantities of unlabeled data are available\xe2\x80\x94e.g. text on websites, protein sequences, or images.<sup class="reference" id="cite_ref-survey_7-0"><a href="#cite_note-survey-7">[7]</a></sup>\n</p>\n<h2><span class="mw-headline" id="Methods">Methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=6" title="Edit section: Methods">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<h3><span class="mw-headline" id="Generative_models">Generative models</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=7" title="Edit section: Generative models">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Generative approaches to statistical learning first seek to estimate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(x|y)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(x|y)}</annotation>\n</semantics>\n</math></span><img alt="p(x|y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b99b32ed9c0b94759956558b359f8da3ab98a23f" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;"/></span>,<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a class="mw-redirect" href="/wiki/Wikipedia:Disputed_statement" title="Wikipedia:Disputed statement"><span title="This claim has reliable sources with contradicting facts (November 2017)">disputed</span></a> <span class="metadata"> \xe2\x80\x93 <a href="/wiki/Talk:Semi-supervised_learning" title="Talk:Semi-supervised learning">discuss</a></span></i>]</sup> the distribution of data points belonging to each class. The probability <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(y|x)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(y|x)}</annotation>\n</semantics>\n</math></span><img alt="p(y|x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3cad17372ea694e639c3881b2b5583632cdaa0ac" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;"/></span> that a given point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>x</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n</semantics>\n</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> has label <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n</semantics>\n</math></span><img alt="y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;"/></span> is then proportional to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(x|y)p(y)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(x|y)p(y)}</annotation>\n</semantics>\n</math></span><img alt="p(x|y)p(y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c143e52e1ea6009cb114283e625d14e3d6c8374" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.334ex; height:2.843ex;"/></span> by <a href="/wiki/Bayes%27_theorem" title="Bayes\' theorem">Bayes\' rule</a>. Semi-supervised learning with <a href="/wiki/Generative_model" title="Generative model">generative models</a> can be viewed either as an extension of supervised learning (classification plus information about <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(x)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(x)}</annotation>\n</semantics>\n</math></span><img alt="p(x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8cb7afced134ef75572e5314a5d278c2d644f438" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:4.398ex; height:2.843ex;"/></span>) or as an extension of unsupervised learning (clustering plus some labels).\n</p><p>Generative models assume that the distributions take some particular form <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(x|y,\\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>y</mi>\n<mo>,</mo>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(x|y,\\theta )}</annotation>\n</semantics>\n</math></span><img alt="p(x|y,\\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/814281f66d6aa10e386cfd04488bfe0afd8f13de" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:8.325ex; height:2.843ex;"/></span> parameterized by the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\theta }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n</semantics>\n</math></span><img alt="\\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span>. If these assumptions are incorrect, the unlabeled data may actually decrease the accuracy of the solution relative to what would have been obtained from labeled data alone.<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup> \nHowever, if the assumptions are correct, then the unlabeled data necessarily improves performance.<sup class="reference" id="cite_ref-Ratsaby_6-1"><a href="#cite_note-Ratsaby-6">[6]</a></sup>\n</p><p>The unlabeled data are distributed according to a mixture of individual-class distributions. In order to learn the mixture distribution from the unlabeled data, it must be identifiable, that is, different parameters must yield different summed distributions. Gaussian mixture distributions are identifiable and commonly used for generative models.\n</p><p>The parameterized <a class="mw-redirect" href="/wiki/Joint_distribution" title="Joint distribution">joint distribution</a> can be written as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo>,</mo>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>y</mi>\n<mo>,</mo>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )}</annotation>\n</semantics>\n</math></span><img alt="p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2ac1816799d6f03d29974d31d46052577af1d76" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:25.53ex; height:2.843ex;"/></span> by using the <a href="/wiki/Chain_rule_(probability)" title="Chain rule (probability)">chain rule</a>. Each parameter vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\theta }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n</semantics>\n</math></span><img alt="\\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span> is associated with a decision function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n</mrow>\n</msub>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<munder>\n<mi>argmax</mi>\n<mi>y</mi>\n</munder>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>x</mi>\n<mo>,</mo>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )}</annotation>\n</semantics>\n</math></span><img alt="f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f945455e371eed97409081ee3b088dee3aa03e49" style="vertical-align: -2.671ex; width:24.758ex; height:4.676ex;"/></span>. \nThe parameter is then chosen based on fit to both the labeled and unlabeled data, weighted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\lambda }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\lambda }</annotation>\n</semantics>\n</math></span><img alt="\\lambda " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;"/></span>:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<munder>\n<mi>argmax</mi>\n<mi mathvariant="normal">\xce\x98<!-- \xce\x98 --></mi>\n</munder>\n</mrow>\n<mrow>\n<mo>(</mo>\n<mrow>\n<mi>log</mi>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mo fence="false" stretchy="false">{</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<msubsup>\n<mo fence="false" stretchy="false">}</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n</mrow>\n</msubsup>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n<mo>+</mo>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mi>log</mi>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mo fence="false" stretchy="false">{</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<msubsup>\n<mo fence="false" stretchy="false">}</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mi>l</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</msubsup>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">)</mo>\n</mrow>\n<mo>)</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)}</annotation>\n</semantics>\n</math></span><img alt="{\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a7aa70fbdeafcdc211033ec8e176fa857a802f6" style="vertical-align: -2.505ex; width:50.262ex; height:4.843ex;"/></span><sup class="reference" id="cite_ref-SSL_EoML_9-0"><a href="#cite_note-SSL_EoML-9">[9]</a></sup></dd></dl>\n<h3><span class="mw-headline" id="Low-density_separation">Low-density separation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=8" title="Edit section: Low-density separation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Another major class of methods attempts to place boundaries in regions with few data points (labeled or unlabeled). One of the most commonly used algorithms is the <a href="/wiki/Support_vector_machine#Transductive_support_vector_machines" title="Support vector machine">transductive support vector machine</a>, or TSVM (which, despite its name, may be used for inductive learning as well). Whereas <a class="mw-redirect" href="/wiki/Support_vector_machines" title="Support vector machines">support vector machines</a> for supervised learning seek a decision boundary with maximal <a href="/wiki/Margin_(machine_learning)" title="Margin (machine learning)">margin</a> over the labeled data, the goal of TSVM is a labeling of the unlabeled data such that the decision boundary has maximal margin over all of the data. In addition to the standard <a href="/wiki/Hinge_loss" title="Hinge loss">hinge loss</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle (1-yf(x))_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>y</mi>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>+</mo>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle (1-yf(x))_{+}}</annotation>\n</semantics>\n</math></span><img alt="(1-yf(x))_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/56caba62f006f7d77e475adb6ea090fd8dc829da" style="vertical-align: -0.838ex; width:12.896ex; height:2.843ex;"/></span> for labeled data, a loss function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle (1-|f(x)|)_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>+</mo>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle (1-|f(x)|)_{+}}</annotation>\n</semantics>\n</math></span><img alt="(1-|f(x)|)_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;"/></span> is introduced over the unlabeled data by letting <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y=\\operatorname {sign} {f(x)}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>y</mi>\n<mo>=</mo>\n<mi>sign</mi>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y=\\operatorname {sign} {f(x)}}</annotation>\n</semantics>\n</math></span><img alt="y=\\operatorname {sign} {f(x)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1b9c83b2319d29f77f9c6ffc8b4a8fd3b426bb36" style="vertical-align: -0.838ex; width:13.077ex; height:2.843ex;"/></span>. TSVM then selects <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f^{*}(x)=h^{*}(x)+b}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>\xe2\x88\x97<!-- \xe2\x88\x97 --></mo>\n</mrow>\n</msup>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<msup>\n<mi>h</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>\xe2\x88\x97<!-- \xe2\x88\x97 --></mo>\n</mrow>\n</msup>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<mo>+</mo>\n<mi>b</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f^{*}(x)=h^{*}(x)+b}</annotation>\n</semantics>\n</math></span><img alt="f^{*}(x)=h^{*}(x)+b" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/188cec367978923197f8da14e236e6ec925b7fc1" style="vertical-align: -0.838ex; width:17.982ex; height:2.843ex;"/></span> from a <a href="/wiki/Reproducing_kernel_Hilbert_space" title="Reproducing kernel Hilbert space">reproducing kernel Hilbert space</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> by minimizing the <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularized</a> <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk</a>:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>\xe2\x88\x97<!-- \xe2\x88\x97 --></mo>\n</mrow>\n</msup>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<munder>\n<mi>argmin</mi>\n<mi>f</mi>\n</munder>\n</mrow>\n<mrow>\n<mo>(</mo>\n<mstyle displaystyle="true" scriptlevel="0">\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n</mrow>\n</munderover>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>+</mo>\n</mrow>\n</msub>\n<mo>+</mo>\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>h</mi>\n<msubsup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msubsup>\n<mo>+</mo>\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msub>\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mi>l</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</munderover>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>+</mo>\n</mrow>\n</msub>\n</mstyle>\n<mo>)</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/280fd60cca5b00621dffd739326086e6d1152944" style="vertical-align: -3.171ex; width:68.93ex; height:7.509ex;"/></span></dd></dl>\n<p>An exact solution is intractable due to the non-<a href="/wiki/Convex_function" title="Convex function">convex</a> term <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle (1-|f(x)|)_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<msub>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>+</mo>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle (1-|f(x)|)_{+}}</annotation>\n</semantics>\n</math></span><img alt="(1-|f(x)|)_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;"/></span>, so research focuses on useful approximations.<sup class="reference" id="cite_ref-SSL_EoML_9-1"><a href="#cite_note-SSL_EoML-9">[9]</a></sup>\n</p><p>Other approaches that implement low-density separation include Gaussian process models, information regularization, and entropy minimization (of which TSVM is a special case).\n</p>\n<h3><span class="mw-headline" id="Graph-based_methods">Graph-based methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=9" title="Edit section: Graph-based methods">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Graph-based methods for semi-supervised learning use a graph representation of the data, with a node for each labeled and unlabeled example. The graph may be constructed using domain knowledge or similarity of examples; two common methods are to connect each data point to its <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle k}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>k</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle k}</annotation>\n</semantics>\n</math></span><img alt="k" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;"/></span> nearest neighbors or to examples within some distance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\epsilon }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xcf\xb5<!-- \xcf\xb5 --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\epsilon }</annotation>\n</semantics>\n</math></span><img alt="\\epsilon " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3837cad72483d97bcdde49c85d3b7b859fb3fd2" style="vertical-align: -0.338ex; width:0.944ex; height:1.676ex;"/></span>. The weight <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle W_{ij}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>W</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle W_{ij}}</annotation>\n</semantics>\n</math></span><img alt="W_{ij}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29c09e9d719bb634d8ca5a6172b0562b945bf325" style="vertical-align: -1.005ex; width:3.671ex; height:2.843ex;"/></span> of an edge between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{i}}</annotation>\n</semantics>\n</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{j}}</annotation>\n</semantics>\n</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span> is then set to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mi>e</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mrow>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n<msup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mrow>\n<mi>\xcf\xb5<!-- \xcf\xb5 --></mi>\n</mfrac>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f664e52a49df1855b25aff5a35b7a6a5d0d52764" style="vertical-align: -0.338ex; width:9.167ex; height:4.509ex;"/></span>.\n</p><p>Within the framework of <a href="/wiki/Manifold_regularization" title="Manifold regularization">manifold regularization</a>,<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup><sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> the graph serves as a proxy for the manifold. A term is added to the standard <a href="/wiki/Tikhonov_regularization" title="Tikhonov regularization">Tikhonov regularization</a> problem to enforce smoothness of the solution relative to the manifold (in the intrinsic space of the problem) as well as relative to the ambient input space. The minimization problem becomes\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<munder>\n<mi>argmin</mi>\n<mrow>\n<mi>f</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mrow>\n</munder>\n</mrow>\n<mrow>\n<mo>(</mo>\n<mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<mi>l</mi>\n</mfrac>\n</mrow>\n<mstyle displaystyle="true" scriptlevel="0">\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n</mrow>\n</munderover>\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>+</mo>\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>A</mi>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>f</mi>\n<msubsup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msubsup>\n<mo>+</mo>\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>I</mi>\n</mrow>\n</msub>\n<msub>\n<mo>\xe2\x88\xab<!-- \xe2\x88\xab --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n</mrow>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi mathvariant="normal">\xe2\x88\x87<!-- \xe2\x88\x87 --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n</mrow>\n</mrow>\n</msub>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<msup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mi>d</mi>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<mo>)</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f33f9ab7b0ce90d7a27a4d16f934bacf1cb515f7" style="vertical-align: -3.171ex; width:66.97ex; height:7.509ex;"/></span><sup class="reference" id="cite_ref-SSL_EoML_9-2"><a href="#cite_note-SSL_EoML-9">[9]</a></sup></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> is a reproducing kernel <a href="/wiki/Hilbert_space" title="Hilbert space">Hilbert space</a> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {M}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {M}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {M}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2cc2abebd45ec020509a0ec548b67c9a2cb7cecd" style="vertical-align: -0.338ex; width:2.791ex; height:2.176ex;"/></span> is the manifold on which the data lie. The regularization parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\lambda _{A}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>A</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\lambda _{A}}</annotation>\n</semantics>\n</math></span><img alt="\\lambda _{A}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a3bcf5b35ccd34136b0529d005ffa35e142f2da" style="vertical-align: -0.671ex; width:2.82ex; height:2.509ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\lambda _{I}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>\xce\xbb<!-- \xce\xbb --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>I</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\lambda _{I}}</annotation>\n</semantics>\n</math></span><img alt="\\lambda _{I}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dafdfbafa01e15e5f05c424bd33e41802320399f" style="vertical-align: -0.671ex; width:2.416ex; height:2.509ex;"/></span> control smoothness in the ambient and intrinsic spaces respectively. The graph is used to approximate the intrinsic regularization term. Defining the <a href="/wiki/Laplacian_matrix" title="Laplacian matrix">graph Laplacian</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle L=D-W}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>L</mi>\n<mo>=</mo>\n<mi>D</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>W</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle L=D-W}</annotation>\n</semantics>\n</math></span><img alt="L=D-W" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ee07ee510ca6515e6668dca08cf5a0de2c2544" style="vertical-align: -0.505ex; width:11.881ex; height:2.343ex;"/></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle D_{ii}=\\sum _{j=1}^{l+u}W_{ij}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>D</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</munderover>\n<msub>\n<mi>W</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle D_{ii}=\\sum _{j=1}^{l+u}W_{ij}}</annotation>\n</semantics>\n</math></span><img alt="D_{ii}=\\sum _{j=1}^{l+u}W_{ij}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aa57df37ac824bc13805e4ec8a46f813954b4414" style="vertical-align: -3.338ex; width:13.803ex; height:7.676ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\mathbf {f} }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">f</mi>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\mathbf {f} }</annotation>\n</semantics>\n</math></span><img alt="\\mathbf {f} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dc6194e680a4e7c521f2178c50eea302843a852d" style="vertical-align: -0.338ex; width:1.053ex; height:2.176ex;"/></span> the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle [f(x_{1})\\dots f(x_{l+u})]}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo stretchy="false">[</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo stretchy="false">]</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle [f(x_{1})\\dots f(x_{l+u})]}</annotation>\n</semantics>\n</math></span><img alt="[f(x_{1})\\dots f(x_{l+u})]" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fc6d44b39ef81da8df4a1be81285c9d6045154b" style="vertical-align: -0.838ex; width:17.622ex; height:2.843ex;"/></span>, we have\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">f</mi>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>T</mi>\n</mrow>\n</msup>\n<mi>L</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">f</mi>\n</mrow>\n<mo>=</mo>\n<mstyle displaystyle="true" scriptlevel="0">\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>,</mo>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</munderover>\n<msub>\n<mi>W</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mi>j</mi>\n</mrow>\n</msub>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n<msup>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mo>\xe2\x89\x88<!-- \xe2\x89\x88 --></mo>\n<msub>\n<mo>\xe2\x88\xab<!-- \xe2\x88\xab --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n</mrow>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi mathvariant="normal">\xe2\x88\x87<!-- \xe2\x88\x87 --></mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n</mrow>\n</mrow>\n</msub>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n<msup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mi>d</mi>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ff2e4d31e189b9d0c55afd5f39fb878d546fe63" style="vertical-align: -3.338ex; width:50.247ex; height:7.676ex;"/></span>.</dd></dl>\n<p>The Laplacian can also be used to extend the supervised learning algorithms: <a href="/wiki/Regularized_least_squares" title="Regularized least squares">regularized least squares</a> and support vector machines (SVM) to semi-supervised versions Laplacian regularized least squares and Laplacian SVM.\n</p>\n<h3><span class="mw-headline" id="Heuristic_approaches">Heuristic approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=10" title="Edit section: Heuristic approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Some methods for semi-supervised learning are not intrinsically geared to learning from both unlabeled and labeled data, but instead make use of unlabeled data within a supervised learning framework. For instance, the labeled and unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{1},\\dots ,x_{l+u}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>l</mi>\n<mo>+</mo>\n<mi>u</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{l+u}}</annotation>\n</semantics>\n</math></span><img alt="x_{1},\\dots ,x_{l+u}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/48fa9a910a81b5833b529973e1511c5be43ce25f" style="vertical-align: -0.671ex; width:11.833ex; height:2.009ex;"/></span> may inform a choice of representation, <a class="mw-redirect" href="/wiki/Distance_metric" title="Distance metric">distance metric</a>, or <a href="/wiki/Kernel_(statistics)" title="Kernel (statistics)">kernel</a> for the data in an unsupervised first step. Then supervised learning proceeds from only the labeled examples.\n</p><p><i>Self-training</i> is a wrapper method for semi-supervised learning.<sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> First a supervised learning algorithm is trained based on the labeled data only. This classifier is then applied to the unlabeled data to generate more labeled examples as input for the supervised learning algorithm. Generally only the labels the classifier is most confident in are added at each step.<sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>\n</p><p><a href="/wiki/Co-training" title="Co-training">Co-training</a> is an extension of self-training in which multiple classifiers are trained on different (ideally disjoint) sets of features and generate labeled examples for one another.<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>\n</p>\n<h2><span class="mw-headline" id="In_human_cognition">In human cognition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=11" title="Edit section: In human cognition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Human responses to formal semi-supervised learning problems have yielded varying conclusions about the degree of influence of the unlabeled data.<sup class="reference" id="cite_ref-ZhuGoldberg_15-0"><a href="#cite_note-ZhuGoldberg-15">[15]</a></sup> More natural learning problems may also be viewed as instances of semi-supervised learning. Much of human <a href="/wiki/Concept_learning" title="Concept learning">concept learning</a> involves a small amount of direct instruction (e.g. parental labeling of objects during childhood) combined with large amounts of unlabeled experience (e.g. observation of objects without naming or counting them, or at least without feedback).\n</p><p>Human infants are sensitive to the structure of unlabeled natural categories such as images of dogs and cats or male and female faces.<sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> Infants and children take into account not only unlabeled examples, but the <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">sampling</a> process from which labeled examples arise.<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>\n</p>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a class="mw-redirect" href="/wiki/PU_learning" title="PU learning">PU learning</a></li>\n<li><a href="/wiki/Weak_supervision" title="Weak supervision">Weak supervision</a></li></ul>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=13" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap mw-references-columns"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1">"Semi-Supervised Learning Literature Survey, Page 5". 2007. <a class="mw-redirect" href="/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.99.9681" rel="nofollow">10.1.1.99.9681</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Semi-Supervised+Learning+Literature+Survey%2C+Page+5&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.99.9681&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><style data-mw-deduplicate="TemplateStyles:r982806391">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span>\n</li>\n<li id="cite_note-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTEChapelleSch\xc3\xb6lkopfZienin2006_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="#CITEREFChapelleSch\xc3\xb6lkopfZienin2006">Chapelle, Sch\xc3\xb6lkopf &amp; Zienin 2006</a>.<span class="error harv-error" style="display: none; font-size:100%"> sfn error: no target: CITEREFChapelleSch\xc3\xb6lkopfZienin2006 (<a href="/wiki/Category:Harv_and_Sfn_template_errors" title="Category:Harv and Sfn template errors">help</a>)</span></span>\n</li>\n<li id="cite_note-StevensKN-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-StevensKN_3-0">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFStevens,_Kenneth_N.,_1924-1998">Stevens, Kenneth N., 1924- (1998). <i>Acoustic phonetics</i>. Cambridge, Mass.: MIT Press. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/0-585-08720-2" title="Special:BookSources/0-585-08720-2"><bdi>0-585-08720-2</bdi></a>. <a class="mw-redirect" href="/wiki/OCLC_(identifier)" title="OCLC (identifier)">OCLC</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/oclc/42856189" rel="nofollow">42856189</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Acoustic+phonetics&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=1998&amp;rft_id=info%3Aoclcnum%2F42856189&amp;rft.isbn=0-585-08720-2&amp;rft.au=Stevens%2C+Kenneth+N.%2C+1924-&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><span class="cs1-maint citation-comment">CS1 maint: multiple names: authors list (<a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>)</span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFScudder1965">Scudder, H. (July 1965). "Probability of error of some adaptive pattern-recognition machines". <i>IEEE Transactions on Information Theory</i>. <b>11</b> (3): 363\xe2\x80\x93371. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTIT.1965.1053799" rel="nofollow">10.1109/TIT.1965.1053799</a>. <a class="mw-redirect" href="/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/issn/1557-9654" rel="nofollow">1557-9654</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Information+Theory&amp;rft.atitle=Probability+of+error+of+some+adaptive+pattern-recognition+machines&amp;rft.volume=11&amp;rft.issue=3&amp;rft.pages=363-371&amp;rft.date=1965-07&amp;rft_id=info%3Adoi%2F10.1109%2FTIT.1965.1053799&amp;rft.issn=1557-9654&amp;rft.aulast=Scudder&amp;rft.aufirst=H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFVapnikChervonenkis1974">Vapnik, V.; Chervonenkis, A. (1974). <i>Theory of Pattern Recognition</i> (in Russian). Moscow: Nauka.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Theory+of+Pattern+Recognition&amp;rft.place=Moscow&amp;rft.pub=Nauka&amp;rft.date=1974&amp;rft.aulast=Vapnik&amp;rft.aufirst=V.&amp;rft.au=Chervonenkis%2C+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> cited in <a href="#CITEREFChapelleSch\xc3\xb6lkopfZienin2006">Chapelle, Sch\xc3\xb6lkopf &amp; Zienin 2006</a>, p.\xc2\xa03<span class="error harv-error" style="display: none; font-size:100%"> harvnb error: no target: CITEREFChapelleSch\xc3\xb6lkopfZienin2006 (<a href="/wiki/Category:Harv_and_Sfn_template_errors" title="Category:Harv and Sfn template errors">help</a>)</span></span>\n</li>\n<li id="cite_note-Ratsaby-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-Ratsaby_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Ratsaby_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web cs1" id="CITEREFRatsabyVenkatesh">Ratsaby, J.; Venkatesh, S. <a class="external text" href="http://www.ariel.ac.il/sites/ratsaby/Publications/PDF/colt95.pdf" rel="nofollow">"Learning from a mixture of labeled and unlabeled examples with parametric side information"</a> <span class="cs1-format">(PDF)</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Learning+from+a+mixture+of+labeled+and+unlabeled+examples+with+parametric+side+information&amp;rft.aulast=Ratsaby&amp;rft.aufirst=J.&amp;rft.au=Venkatesh%2C+S.&amp;rft_id=http%3A%2F%2Fwww.ariel.ac.il%2Fsites%2Fratsaby%2FPublications%2FPDF%2Fcolt95.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> in <cite class="citation book cs1"><i>Proceedings of the eighth annual conference on Computational learning theory - COLT \'95</i>. New York, New York, USA: ACM Press. 1995. pp.\xc2\xa0412\xe2\x80\x93417. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1145%2F225298.225348" rel="nofollow">10.1145/225298.225348</a>. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/0-89791-723-5" title="Special:BookSources/0-89791-723-5"><bdi>0-89791-723-5</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Proceedings+of+the+eighth+annual+conference+on+Computational+learning+theory+-+COLT+%2795&amp;rft.place=New+York%2C+New+York%2C+USA&amp;rft.pages=412-417&amp;rft.pub=ACM+Press&amp;rft.date=1995&amp;rft_id=info%3Adoi%2F10.1145%2F225298.225348&amp;rft.isbn=0-89791-723-5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/>. Cited in <a href="#CITEREFChapelleSch\xc3\xb6lkopfZienin2006">Chapelle, Sch\xc3\xb6lkopf &amp; Zienin 2006</a>, p.\xc2\xa04<span class="error harv-error" style="display: none; font-size:100%"> harvnb error: no target: CITEREFChapelleSch\xc3\xb6lkopfZienin2006 (<a href="/wiki/Category:Harv_and_Sfn_template_errors" title="Category:Harv and Sfn template errors">help</a>)</span></span>\n</li>\n<li id="cite_note-survey-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-survey_7-0">^</a></b></span> <span class="reference-text"><cite class="citation web cs1" id="CITEREFZhu2008">Zhu, Xiaojin (2008). <a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf" rel="nofollow">"Semi-supervised learning literature survey"</a> <span class="cs1-format">(PDF)</span>. University of Wisconsin-Madison.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Semi-supervised+learning+literature+survey&amp;rft.pub=University+of+Wisconsin-Madison&amp;rft.date=2008&amp;rft.aulast=Zhu&amp;rft.aufirst=Xiaojin&amp;rft_id=http%3A%2F%2Fpages.cs.wisc.edu%2F~jerryzhu%2Fpub%2Fssl_survey.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation cs2" id="CITEREFFabioIra2006">Fabio, Cozman; Ira, Cohen (2006-09-22), "Risks of Semi-Supervised Learning: How Unlabeled Data Can Degrade Performance of Generative Classifiers", <i>Semi-Supervised Learning</i>, The MIT Press, pp.\xc2\xa056\xe2\x80\x9372, <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.7551%2Fmitpress%2F9780262033589.003.0004" rel="nofollow">10.7551/mitpress/9780262033589.003.0004</a>, <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-262-03358-9" title="Special:BookSources/978-0-262-03358-9"><bdi>978-0-262-03358-9</bdi></a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Semi-Supervised+Learning&amp;rft.atitle=Risks+of+Semi-Supervised+Learning%3A+How+Unlabeled+Data+Can+Degrade+Performance+of+Generative+Classifiers&amp;rft.pages=56-72&amp;rft.date=2006-09-22&amp;rft_id=info%3Adoi%2F10.7551%2Fmitpress%2F9780262033589.003.0004&amp;rft.isbn=978-0-262-03358-9&amp;rft.aulast=Fabio&amp;rft.aufirst=Cozman&amp;rft.au=Ira%2C+Cohen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> In: <a href="#CITEREFChapelleSch\xc3\xb6lkopfZienin2006">Chapelle, Sch\xc3\xb6lkopf &amp; Zienin 2006</a><span class="error harv-error" style="display: none; font-size:100%"> harvnb error: no target: CITEREFChapelleSch\xc3\xb6lkopfZienin2006 (<a href="/wiki/Category:Harv_and_Sfn_template_errors" title="Category:Harv and Sfn template errors">help</a>)</span></span>\n</li>\n<li id="cite_note-SSL_EoML-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-SSL_EoML_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Zhu, Xiaojin. <a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/SSL_EoML.pdf" rel="nofollow">Semi-Supervised Learning</a> University of Wisconsin-Madison.</span>\n</li>\n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFM._BelkinP._Niyogi2004">M. Belkin; P. Niyogi (2004). <a class="external text" href="http://booksc.org/dl/11288633/421f61" rel="nofollow">"Semi-supervised Learning on Riemannian Manifolds"</a>. <i>Machine Learning</i>. <b>56</b> (Special Issue on Clustering): 209\xe2\x80\x93239. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1023%2Fb%3Amach.0000033120.25363.1e" rel="nofollow">10.1023/b:mach.0000033120.25363.1e</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Semi-supervised+Learning+on+Riemannian+Manifolds&amp;rft.volume=56&amp;rft.issue=Special+Issue+on+Clustering&amp;rft.pages=209-239&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1023%2Fb%3Amach.0000033120.25363.1e&amp;rft.au=M.+Belkin&amp;rft.au=P.+Niyogi&amp;rft_id=http%3A%2F%2Fbooksc.org%2Fdl%2F11288633%2F421f61&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">M. Belkin, P. Niyogi, V. Sindhwani. On Manifold Regularization. AISTATS 2005.</span>\n</li>\n<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFTrigueroGarc\xc3\xadaHerrera2013">Triguero, Isaac; Garc\xc3\xada, Salvador; Herrera, Francisco (2013-11-26). "Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study". <i>Knowledge and Information Systems</i>. <b>42</b> (2): 245\xe2\x80\x93284. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs10115-013-0706-y" rel="nofollow">10.1007/s10115-013-0706-y</a>. <a class="mw-redirect" href="/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/issn/0219-1377" rel="nofollow">0219-1377</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Knowledge+and+Information+Systems&amp;rft.atitle=Self-labeled+techniques+for+semi-supervised+learning%3A+taxonomy%2C+software+and+empirical+study&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=245-284&amp;rft.date=2013-11-26&amp;rft_id=info%3Adoi%2F10.1007%2Fs10115-013-0706-y&amp;rft.issn=0219-1377&amp;rft.aulast=Triguero&amp;rft.aufirst=Isaac&amp;rft.au=Garc%C3%ADa%2C+Salvador&amp;rft.au=Herrera%2C+Francisco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFFazakisKarlosKotsiantisSgarbas2015">Fazakis, Nikos; Karlos, Stamatis; Kotsiantis, Sotiris; Sgarbas, Kyriakos (2015-12-29). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606" rel="nofollow">"Self-Trained LMT for Semisupervised Learning"</a>. <i>Computational Intelligence and Neuroscience</i>. <b>2016</b>: 3057481. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1155%2F2016%2F3057481" rel="nofollow">10.1155/2016/3057481</a>. <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606" rel="nofollow">4709606</a></span>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/26839531" rel="nofollow">26839531</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Intelligence+and+Neuroscience&amp;rft.atitle=Self-Trained+LMT+for+Semisupervised+Learning&amp;rft.volume=2016&amp;rft.pages=3057481&amp;rft.date=2015-12-29&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rft_id=info%3Apmid%2F26839531&amp;rft_id=info%3Adoi%2F10.1155%2F2016%2F3057481&amp;rft.aulast=Fazakis&amp;rft.aufirst=Nikos&amp;rft.au=Karlos%2C+Stamatis&amp;rft.au=Kotsiantis%2C+Sotiris&amp;rft.au=Sgarbas%2C+Kyriakos&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFDidaciFumeraRoli2012">Didaci, Luca; Fumera, Giorgio; Roli, Fabio (2012-11-07).  Gimel\xe2\x80\x99farb, Georgy; Hancock, Edwin; Imiya, Atsushi; Kuijper, Arjan; Kudo, Mineichi; Omachi, Shinichiro; Windeatt, Terry; Yamada, Keiji (eds.). <i>Analysis of Co-training Algorithm with Very Small Training Sets</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. pp.\xc2\xa0719\xe2\x80\x93726. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2F978-3-642-34166-3_79" rel="nofollow">10.1007/978-3-642-34166-3_79</a>. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/9783642341656" title="Special:BookSources/9783642341656"><bdi>9783642341656</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Analysis+of+Co-training+Algorithm+with+Very+Small+Training+Sets&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=719-726&amp;rft.pub=Springer+Berlin+Heidelberg&amp;rft.date=2012-11-07&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-642-34166-3_79&amp;rft.isbn=9783642341656&amp;rft.aulast=Didaci&amp;rft.aufirst=Luca&amp;rft.au=Fumera%2C+Giorgio&amp;rft.au=Roli%2C+Fabio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-ZhuGoldberg-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-ZhuGoldberg_15-0">^</a></b></span> <span class="reference-text">\n<cite class="citation book cs1" id="CITEREFZhu2009">Zhu, Xiaojin (2009). <i>Introduction to semi-supervised learning</i>. Goldberg, A. B. (Andrew B.). [San Rafael, Calif.]: Morgan &amp; Claypool Publishers. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-1-59829-548-1" title="Special:BookSources/978-1-59829-548-1"><bdi>978-1-59829-548-1</bdi></a>. <a class="mw-redirect" href="/wiki/OCLC_(identifier)" title="OCLC (identifier)">OCLC</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/oclc/428541480" rel="nofollow">428541480</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+semi-supervised+learning&amp;rft.place=%5BSan+Rafael%2C+Calif.%5D&amp;rft.pub=Morgan+%26+Claypool+Publishers&amp;rft.date=2009&amp;rft_id=info%3Aoclcnum%2F428541480&amp;rft.isbn=978-1-59829-548-1&amp;rft.aulast=Zhu&amp;rft.aufirst=Xiaojin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFYounger_B._A.Fearing_D._D.1999">Younger B. A.; Fearing D. D. (1999). "Parsing Items into Separate Categories: Developmental Change in Infant Categorization". <i>Child Development</i>. <b>70</b> (2): 291\xe2\x80\x93303. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1111%2F1467-8624.00022" rel="nofollow">10.1111/1467-8624.00022</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Child+Development&amp;rft.atitle=Parsing+Items+into+Separate+Categories%3A+Developmental+Change+in+Infant+Categorization&amp;rft.volume=70&amp;rft.issue=2&amp;rft.pages=291-303&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1111%2F1467-8624.00022&amp;rft.au=Younger+B.+A.&amp;rft.au=Fearing+D.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFXu,_F.Tenenbaum,_J._B.2007">Xu, F. &amp; Tenenbaum, J. B. (2007). "Sensitivity to sampling in Bayesian word learning". <i>Developmental Science</i>. <b>10</b> (3): 288\xe2\x80\x93297. <a class="mw-redirect" href="/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.7505" rel="nofollow">10.1.1.141.7505</a></span>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1111%2Fj.1467-7687.2007.00590.x" rel="nofollow">10.1111/j.1467-7687.2007.00590.x</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/17444970" rel="nofollow">17444970</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Developmental+Science&amp;rft.atitle=Sensitivity+to+sampling+in+Bayesian+word+learning&amp;rft.volume=10&amp;rft.issue=3&amp;rft.pages=288-297&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.141.7505&amp;rft_id=info%3Apmid%2F17444970&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-7687.2007.00590.x&amp;rft.au=Xu%2C+F.&amp;rft.au=Tenenbaum%2C+J.+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFGweon,_H.,_Tenenbaum_J.B.,_and_Schulz_L.E2010">Gweon, H., Tenenbaum J.B., and Schulz L.E (2010). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2889113" rel="nofollow">"Infants consider both the sample and the sampling process in inductive generalization"</a>. <i>Proc Natl Acad Sci U S A</i>. <b>107</b> (20): 9066\xe2\x80\x9371. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2010PNAS..107.9066G" rel="nofollow">2010PNAS..107.9066G</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1073%2Fpnas.1003095107" rel="nofollow">10.1073/pnas.1003095107</a>. <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2889113" rel="nofollow">2889113</a></span>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/20435914" rel="nofollow">20435914</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc+Natl+Acad+Sci+U+S+A&amp;rft.atitle=Infants+consider+both+the+sample+and+the+sampling+process+in+inductive+generalization&amp;rft.volume=107&amp;rft.issue=20&amp;rft.pages=9066-71&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2889113&amp;rft_id=info%3Apmid%2F20435914&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1003095107&amp;rft_id=info%3Abibcode%2F2010PNAS..107.9066G&amp;rft.au=Gweon%2C+H.%2C+Tenenbaum+J.B.%2C+and+Schulz+L.E&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2889113&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><span class="cs1-maint citation-comment">CS1 maint: multiple names: authors list (<a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>)</span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n</ol></div></div>\n<h2><span class="mw-headline" id="Sources">Sources</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=14" title="Edit section: Sources">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><cite class="citation book cs1" id="CITEREFChapelleSch\xc3\xb6lkopfZien2006">Chapelle, Olivier; Sch\xc3\xb6lkopf, Bernhard; Zien, Alexander (2006). <i>Semi-supervised learning</i>. Cambridge, Mass.: MIT Press. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-262-03358-9" title="Special:BookSources/978-0-262-03358-9"><bdi>978-0-262-03358-9</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Semi-supervised+learning&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=2006&amp;rft.isbn=978-0-262-03358-9&amp;rft.aulast=Chapelle&amp;rft.aufirst=Olivier&amp;rft.au=Sch%C3%B6lkopf%2C+Bernhard&amp;rft.au=Zien%2C+Alexander&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><span class="cs1-maint citation-comment">CS1 maint: ref=harv (<a href="/wiki/Category:CS1_maint:_ref%3Dharv" title="Category:CS1 maint: ref=harv">link</a>)</span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></li></ul>\n<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=15" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a class="external text" href="http://manifold.cs.uchicago.edu/manifold_regularization/software.html" rel="nofollow">Manifold Regularization</a> A freely available <a href="/wiki/MATLAB" title="MATLAB">MATLAB</a> implementation of the graph-based semi-supervised algorithms Laplacian support vector machines and Laplacian regularized least squares.</li>\n<li><a class="external text" href="http://sci2s.ugr.es/keel/algorithms.php#sub10" rel="nofollow">KEEL: A software tool to assess evolutionary algorithms for Data Mining problems (regression, classification, clustering, pattern mining and so on)</a> KEEL module for semi-supervised learning.</li>\n<li><a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/ssl/software.html" rel="nofollow">Semi-Supervised Learning Software</a> Semi-Supervised Learning Software</li>\n<li><a class="external text" href="http://scikit-learn.org/stable/modules/label_propagation.html" rel="nofollow">1.14. Semi-Supervised \xe2\x80\x94 scikit-learn 0.22.1 documentation</a> Semi-Supervised algorithms in scikit-learn .</li></ul>\n<!-- \nNewPP limit report\nParsed by mw2275\nCached time: 20201025051932\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.504 seconds\nReal time usage: 0.774 seconds\nPreprocessor visited node count: 1510/1000000\nPost\xe2\x80\x90expand include size: 64359/2097152 bytes\nTemplate argument size: 1321/2097152 bytes\nHighest expansion depth: 12/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 61218/5000000 bytes\nLua time usage: 0.228/10.000 seconds\nLua memory usage: 5.96 MB/50 MB\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  443.213      1 -total\n 48.41%  214.573      1 Template:Reflist\n 29.43%  130.431      8 Template:Cite_journal\n 21.01%   93.134      1 Template:Machine_learning_bar\n 20.16%   89.351      1 Template:Sidebar_with_collapsible_lists\n 13.37%   59.278      2 Template:Sfn\n 11.41%   50.557      1 Template:Disputed_inline\n  9.80%   43.456      1 Template:Fix\n  9.47%   41.972      1 Template:Longitem\n  8.62%   38.217      1 Template:Nobold\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:2829632-0!canonical!math=5 and timestamp 20201025051931 and revision id 984076465\n -->\n</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript>\n<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=984076465">https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=984076465</a>"</div></div>\n<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:Harv_and_Sfn_no-target_errors" title="Category:Harv and Sfn no-target errors">Harv and Sfn no-target errors</a></li><li><a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">CS1 maint: multiple names: authors list</a></li><li><a href="/wiki/Category:CS1_Russian-language_sources_(ru)" title="Category:CS1 Russian-language sources (ru)">CS1 Russian-language sources (ru)</a></li><li><a href="/wiki/Category:All_accuracy_disputes" title="Category:All accuracy disputes">All accuracy disputes</a></li><li><a href="/wiki/Category:Articles_with_disputed_statements_from_November_2017" title="Category:Articles with disputed statements from November 2017">Articles with disputed statements from November 2017</a></li><li><a href="/wiki/Category:CS1_maint:_ref%3Dharv" title="Category:CS1 maint: ref=harv">CS1 maint: ref=harv</a></li></ul></div></div>\n</div>\n</div>\n<div id="mw-data-after-content">\n<div class="read-more-container"></div>\n</div>\n<div id="mw-navigation">\n<h2>Navigation menu</h2>\n<div id="mw-head">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-personal-label" class="mw-portlet mw-portlet-personal vector-menu" id="p-personal" role="navigation">\n<h3 id="p-personal-label">\n<span>Personal tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Semi-supervised+learning" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Semi-supervised+learning" title="You\'re encouraged to log in; however, it\'s not mandatory. [o]">Log in</a></li></ul>\n</div>\n</nav>\n<div id="left-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-namespaces-label" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" id="p-namespaces" role="navigation">\n<h3 id="p-namespaces-label">\n<span>Namespaces</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Semi-supervised_learning" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Semi-supervised_learning" rel="discussion" title="Discuss improvements to the content page [t]">Talk</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-variants-label" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" id="p-variants" role="navigation">\n<input aria-labelledby="p-variants-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-variants-label">\n<span>Variants</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n</div>\n<div id="right-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-views-label" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" id="p-views" role="navigation">\n<h3 id="p-views-label">\n<span>Views</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-view"><a href="/wiki/Semi-supervised_learning">Read</a></li><li id="ca-edit"><a accesskey="e" href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" title="Edit this page [e]">Edit</a></li><li id="ca-history"><a accesskey="h" href="/w/index.php?title=Semi-supervised_learning&amp;action=history" title="Past revisions of this page [h]">View history</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-cactions-label" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" id="p-cactions" role="navigation">\n<input aria-labelledby="p-cactions-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-cactions-label">\n<span>More</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n<div id="p-search" role="search">\n<h3>\n<label for="searchInput">Search</label>\n</h3>\n<form action="/w/index.php" id="searchform">\n<div data-search-loc="header-navigation" id="simpleSearch">\n<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>\n<input name="title" type="hidden" value="Special:Search"/>\n<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search">\n<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>\n</input></div>\n</form>\n</div>\n</div>\n</div>\n<div id="mw-panel">\n<div id="p-logo" role="banner">\n<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>\n</div>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-navigation-label" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal portal-first" id="p-navigation" role="navigation">\n<h3 id="p-navigation-label">\n<span>Navigation</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Visit a randomly selected article [x]">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-interaction-label" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" id="p-interaction" role="navigation">\n<h3 id="p-interaction-label">\n<span>Contribute</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-tb-label" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" id="p-tb" role="navigation">\n<h3 id="p-tb-label">\n<span>Tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Semi-supervised_learning" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Semi-supervised_learning" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Semi-supervised_learning&amp;oldid=984076465" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Semi-supervised_learning&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Semi-supervised_learning&amp;id=984076465&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418" title="Structured data on this page hosted by Wikidata [g]">Wikidata item</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-coll-print_export-label" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" id="p-coll-print_export" role="navigation">\n<h3 id="p-coll-print_export-label">\n<span>Print/export</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Semi-supervised_learning&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Semi-supervised_learning&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-lang-label" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" id="p-lang" role="navigation">\n<h3 id="p-lang-label">\n<span>Languages</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Aprendizaje_semisupervisado" hreflang="es" lang="es" title="Aprendizaje semisupervisado \xe2\x80\x93 Spanish">Espa\xc3\xb1ol</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%DB%8C%D8%A7%D8%AF%DA%AF%DB%8C%D8%B1%DB%8C_%D9%86%DB%8C%D9%85%D9%87%E2%80%8C%D9%86%D8%B8%D8%A7%D8%B1%D8%AA%DB%8C" hreflang="fa" lang="fa" title="\xdb\x8c\xd8\xa7\xd8\xaf\xda\xaf\xdb\x8c\xd8\xb1\xdb\x8c \xd9\x86\xdb\x8c\xd9\x85\xd9\x87\xe2\x80\x8c\xd9\x86\xd8\xb8\xd8\xa7\xd8\xb1\xd8\xaa\xdb\x8c \xe2\x80\x93 Persian">\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Apprentissage_semi-supervis%C3%A9" hreflang="fr" lang="fr" title="Apprentissage semi-supervis\xc3\xa9 \xe2\x80\x93 French">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EC%A4%80_%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5" hreflang="ko" lang="ko" title="\xec\xa4\x80 \xec\xa7\x80\xeb\x8f\x84 \xed\x95\x99\xec\x8a\xb5 \xe2\x80\x93 Korean">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%87%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D1%8B%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F" hreflang="ru" lang="ru" title="\xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x81 \xd1\x87\xd0\xb0\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd1\x8b\xd0\xbc \xd0\xbf\xd1\x80\xd0\xb8\xd0\xb2\xd0\xbb\xd0\xb5\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5\xd0\xbc \xd1\x83\xd1\x87\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8f \xe2\x80\x93 Russian">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%BF%D1%96%D0%B2%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%BD%D0%B5_%D0%BD%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F" hreflang="uk" lang="uk" title="\xd0\x9d\xd0\xb0\xd0\xbf\xd1\x96\xd0\xb2\xd0\xb0\xd0\xb2\xd1\x82\xd0\xbe\xd0\xbc\xd0\xb0\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd0\xb5 \xd0\xbd\xd0\xb0\xd0\xb2\xd1\x87\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8f \xe2\x80\x93 Ukrainian">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-vi"><a class="interlanguage-link-target" href="https://vi.wikipedia.org/wiki/H%E1%BB%8Dc_n%E1%BB%ADa_gi%C3%A1m_s%C3%A1t" hreflang="vi" lang="vi" title="H\xe1\xbb\x8dc n\xe1\xbb\xada gi\xc3\xa1m s\xc3\xa1t \xe2\x80\x93 Vietnamese">Ti\xe1\xba\xbfng Vi\xe1\xbb\x87t</a></li></ul>\n<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>\n</div>\n</nav>\n</div>\n</div>\n<footer class="mw-footer" id="footer" role="contentinfo">\n<ul id="footer-info">\n<li id="footer-info-lastmod"> This page was last edited on 18 October 2020, at 01:05<span class="anonymous-show">\xc2\xa0(UTC)</span>.</li>\n<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id="footer-places">\n<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>\n<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>\n<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>\n<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n</ul>\n<ul class="noprint" id="footer-icons">\n<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" loading="lazy" src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88"/></a></li>\n<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" loading="lazy" src="/static/images/footer/poweredby_mediawiki_88x31.png" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>\n</ul>\n<div style="clear: both;"></div>\n</footer>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.504","walltime":"0.774","ppvisitednodes":{"value":1510,"limit":1000000},"postexpandincludesize":{"value":64359,"limit":2097152},"templateargumentsize":{"value":1321,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":1,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":61218,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  443.213      1 -total"," 48.41%  214.573      1 Template:Reflist"," 29.43%  130.431      8 Template:Cite_journal"," 21.01%   93.134      1 Template:Machine_learning_bar"," 20.16%   89.351      1 Template:Sidebar_with_collapsible_lists"," 13.37%   59.278      2 Template:Sfn"," 11.41%   50.557      1 Template:Disputed_inline","  9.80%   43.456      1 Template:Fix","  9.47%   41.972      1 Template:Longitem","  8.62%   38.217      1 Template:Nobold"]},"scribunto":{"limitreport-timeusage":{"value":"0.228","limit":"10.000"},"limitreport-memusage":{"value":6254417,"limit":52428800},"limitreport-logs":"anchor_id_list = table#1 {\\n  [\\"CITEREFChapelleSch\xc3\xb6lkopfZien2006\\"] = 1,\\n  [\\"CITEREFDidaciFumeraRoli2012\\"] = 1,\\n  [\\"CITEREFFabioIra2006\\"] = 1,\\n  [\\"CITEREFFazakisKarlosKotsiantisSgarbas2015\\"] = 1,\\n  [\\"CITEREFGweon,_H.,_Tenenbaum_J.B.,_and_Schulz_L.E2010\\"] = 1,\\n  [\\"CITEREFM._BelkinP._Niyogi2004\\"] = 1,\\n  [\\"CITEREFRatsabyVenkatesh\\"] = 1,\\n  [\\"CITEREFScudder1965\\"] = 1,\\n  [\\"CITEREFStevens,_Kenneth_N.,_1924-1998\\"] = 1,\\n  [\\"CITEREFTrigueroGarc\xc3\xadaHerrera2013\\"] = 1,\\n  [\\"CITEREFVapnikChervonenkis1974\\"] = 1,\\n  [\\"CITEREFXu,_F.Tenenbaum,_J._B.2007\\"] = 1,\\n  [\\"CITEREFYounger_B._A.Fearing_D._D.1999\\"] = 1,\\n  [\\"CITEREFZhu2008\\"] = 1,\\n  [\\"CITEREFZhu2009\\"] = 1,\\n}\\ntemplate_list = table#1 {\\n  [\\"Citation\\"] = 1,\\n  [\\"Cite book\\"] = 6,\\n  [\\"Cite journal\\"] = 8,\\n  [\\"Cite web\\"] = 2,\\n  [\\"Disputed inline\\"] = 1,\\n  [\\"Harvnb\\"] = 3,\\n  [\\"Machine learning bar\\"] = 1,\\n  [\\"Reflist\\"] = 1,\\n  [\\"Sfn\\"] = 2,\\n}\\narticle_whitelist = table#1 {\\n}\\n"},"cachereport":{"origin":"mw2275","timestamp":"20201025051932","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Semi-supervised learning","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Semi-supervised_learning","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q1041418","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q1041418","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2005-10-04T04:19:02Z","dateModified":"2020-10-18T01:05:03Z","image":"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/d\\/d0\\/Example_of_unlabeled_data_in_semisupervised_learning.png","headline":"class of machine learning techniques"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":152,"wgHostname":"mw1332"});});</script>\n</body></html>'