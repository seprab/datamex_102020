b'<!DOCTYPE html>\n\n<html class="client-nojs" dir="ltr" lang="en">\n<head>\n<meta charset="utf8"/>\n<title>Hidden Markov model - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"4f405b0c-75dd-42e0-9c03-e841f662ef0f","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Hidden_Markov_model","wgTitle":"Hidden Markov model","wgCurRevisionId":983183862,"wgRevisionId":983183862,"wgArticleId":98770,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Pages containing links to subscription-only content","Articles with short description","Short description matches Wikidata","Good articles","Commons category link is on Wikidata","Wikipedia articles with GND identifiers","Articles with example Python (programming language) code",\n"Bioinformatics","Hidden Markov models","Markov models"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Hidden_Markov_model","wgRelevantArticleId":98770,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q176769"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready",\n"ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.math.styles":"ready","ext.cite.styles":"ready","ext.pygments":"ready","skins.vector.styles.legacy":"ready","jquery.makeCollapsible.styles":"ready","mediawiki.toc.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.math.scripts","ext.cite.ux-enhancements","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns",\n"ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.pygments%2CwikimediaBadges%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cjquery.makeCollapsible.styles%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta content="" name="ResourceLoaderDynamicStyles"/>\n<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<meta content="MediaWiki 1.36.0-wmf.14" name="generator"/>\n<meta content="origin" name="referrer"/>\n<meta content="origin-when-crossorigin" name="referrer"/>\n<meta content="origin-when-cross-origin" name="referrer"/>\n<link href="//en.m.wikipedia.org/wiki/Hidden_Markov_model" media="only screen and (max-width: 720px)" rel="alternate"/>\n<link href="/w/index.php?title=Hidden_Markov_model&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>\n<link href="/w/index.php?title=Hidden_Markov_model&amp;action=edit" rel="edit" title="Edit this page"/>\n<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>\n<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>\n<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>\n<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>\n<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>\n<link href="https://en.wikipedia.org/wiki/Hidden_Markov_model" rel="canonical"/>\n<link href="//login.wikimedia.org" rel="dns-prefetch"/>\n<link href="//meta.wikimedia.org" rel="dns-prefetch"/>\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Hidden_Markov_model rootpage-Hidden_Markov_model skin-vector action-view skin-vector-legacy"><div class="noprint" id="mw-page-base"></div>\n<div class="noprint" id="mw-head-base"></div>\n<div class="mw-body" id="content" role="main">\n<a id="top"></a>\n<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>\n<div class="mw-indicators mw-body-content">\n<div class="mw-indicator" id="mw-indicator-good-star"><a href="/wiki/Wikipedia:Good_articles" title="This is a good article. Click here for more information."><img alt="This is a good article. Click here for more information." data-file-height="185" data-file-width="180" decoding="async" height="20" src="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/29px-Symbol_support_vote.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/39px-Symbol_support_vote.svg.png 2x" width="19"/></a></div>\n</div>\n<h1 class="firstHeading" id="firstHeading" lang="en">Hidden Markov model</h1>\n<div class="mw-body-content" id="bodyContent">\n<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>\n<div id="contentSub"></div>\n<div id="contentSub2"></div>\n<div id="jump-to-nav"></div>\n<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n<a class="mw-jump-link" href="#searchInput">Jump to search</a>\n<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Statistical Markov model</div>\n<p class="mw-empty-elt">\n</p><p><b>Hidden Markov Model</b> (<b>HMM</b>) is a <a href="/wiki/Statistical_model" title="Statistical model">statistical</a> <a href="/wiki/Markov_model" title="Markov model">Markov model</a> in which the system being <a href="/wiki/Mathematical_model" title="Mathematical model">modeled</a> is assumed to be a <a class="mw-redirect" href="/wiki/Markov_process" title="Markov process">Markov process</a>\xc2\xa0\xe2\x80\x93 call it <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n</semantics>\n</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span>\xc2\xa0\xe2\x80\x93 with unobservable ("<i>hidden</i>") states. HMM assumes that there is another process <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n</semantics>\n</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span> whose behavior "depends" on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n</semantics>\n</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span>. The goal is to learn about <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n</semantics>\n</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span> by observing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n</semantics>\n</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span>. HMM stipulates that, for each time instance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle n_{0}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>0</mn>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle n_{0}}</annotation>\n</semantics>\n</math></span><img alt="n_{0}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/63584d203ecb012a7bcb90f422408bbfe4018956" style="vertical-align: -0.671ex; width:2.449ex; height:2.009ex;"/></span>, the conditional probability distribution of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y_{n_{0}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<msub>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>0</mn>\n</mrow>\n</msub>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y_{n_{0}}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle Y_{n_{0}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b69c2d4c965cd340f01808598451199264ff34e5" style="vertical-align: -1.005ex; width:3.401ex; height:2.843ex;"/></span> given the history <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\{X_{n}=x_{n}\\}_{n\\leq n_{0}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">{</mo>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<msub>\n<mo fence="false" stretchy="false">}</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n<mo>\xe2\x89\xa4<!-- \xe2\x89\xa4 --></mo>\n<msub>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>0</mn>\n</mrow>\n</msub>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\{X_{n}=x_{n}\\}_{n\\leq n_{0}}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\{X_{n}=x_{n}\\}_{n\\leq n_{0}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b94ad2cc4f993cbcbbd9c7f38e3315e0bc09dfc1" style="vertical-align: -1.005ex; width:15.429ex; height:3.009ex;"/></span> must <b>not</b> depend on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\{x_{n}\\}_{n&lt;n_{0}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">{</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<msub>\n<mo fence="false" stretchy="false">}</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n<mo>&lt;</mo>\n<msub>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>0</mn>\n</mrow>\n</msub>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\{x_{n}\\}_{n&lt;n_{0}}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\{x_{n}\\}_{n&lt;n_{0}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9607d13599131b695b17bf3d2d70579577700142" style="vertical-align: -1.005ex; width:9.188ex; height:3.009ex;"/></span>.\n</p><p>Hidden Markov models are known for their applications to <a href="/wiki/Thermodynamics" title="Thermodynamics">thermodynamics</a>, <a href="/wiki/Statistical_mechanics" title="Statistical mechanics">statistical mechanics</a>, <a href="/wiki/Physics" title="Physics">physics</a>, <a href="/wiki/Chemistry" title="Chemistry">chemistry</a>, <a href="/wiki/Economics" title="Economics">economics</a>, <a href="/wiki/Finance" title="Finance">finance</a>, <a href="/wiki/Signal_processing" title="Signal processing">signal processing</a>, <a href="/wiki/Information_theory" title="Information theory">information theory</a>, <a href="/wiki/Pattern_recognition" title="Pattern recognition">pattern recognition</a> - such as <a href="/wiki/Speech_recognition" title="Speech recognition">speech</a>, <a href="/wiki/Handwriting_recognition" title="Handwriting recognition">handwriting</a>, <a href="/wiki/Gesture_recognition" title="Gesture recognition">gesture recognition</a>,<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> <a href="/wiki/Part-of-speech_tagging" title="Part-of-speech tagging">part-of-speech tagging</a>, musical score following,<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> <a href="/wiki/Partial_discharge" title="Partial discharge">partial discharges</a><sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> and <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a>.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>\n</p>\n<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Definition"><span class="tocnumber">1</span> <span class="toctext">Definition</span></a>\n<ul>\n<li class="toclevel-2 tocsection-2"><a href="#Terminology"><span class="tocnumber">1.1</span> <span class="toctext">Terminology</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-3"><a href="#Examples"><span class="tocnumber">2</span> <span class="toctext">Examples</span></a>\n<ul>\n<li class="toclevel-2 tocsection-4"><a href="#Drawing_balls_from_hidden_urns"><span class="tocnumber">2.1</span> <span class="toctext">Drawing balls from hidden urns</span></a></li>\n<li class="toclevel-2 tocsection-5"><a href="#Weather_guessing_game"><span class="tocnumber">2.2</span> <span class="toctext">Weather guessing game</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-6"><a href="#Structural_architecture"><span class="tocnumber">3</span> <span class="toctext">Structural architecture</span></a></li>\n<li class="toclevel-1 tocsection-7"><a href="#Inference"><span class="tocnumber">4</span> <span class="toctext">Inference</span></a>\n<ul>\n<li class="toclevel-2 tocsection-8"><a href="#Probability_of_an_observed_sequence"><span class="tocnumber">4.1</span> <span class="toctext">Probability of an observed sequence</span></a></li>\n<li class="toclevel-2 tocsection-9"><a href="#Probability_of_the_latent_variables"><span class="tocnumber">4.2</span> <span class="toctext">Probability of the latent variables</span></a>\n<ul>\n<li class="toclevel-3 tocsection-10"><a href="#Filtering"><span class="tocnumber">4.2.1</span> <span class="toctext">Filtering</span></a></li>\n<li class="toclevel-3 tocsection-11"><a href="#Smoothing"><span class="tocnumber">4.2.2</span> <span class="toctext">Smoothing</span></a></li>\n<li class="toclevel-3 tocsection-12"><a href="#Most_likely_explanation"><span class="tocnumber">4.2.3</span> <span class="toctext">Most likely explanation</span></a></li>\n</ul>\n</li>\n<li class="toclevel-2 tocsection-13"><a href="#Statistical_significance"><span class="tocnumber">4.3</span> <span class="toctext">Statistical significance</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-14"><a href="#Learning"><span class="tocnumber">5</span> <span class="toctext">Learning</span></a></li>\n<li class="toclevel-1 tocsection-15"><a href="#Applications"><span class="tocnumber">6</span> <span class="toctext">Applications</span></a></li>\n<li class="toclevel-1 tocsection-16"><a href="#History"><span class="tocnumber">7</span> <span class="toctext">History</span></a></li>\n<li class="toclevel-1 tocsection-17"><a href="#Extensions"><span class="tocnumber">8</span> <span class="toctext">Extensions</span></a></li>\n<li class="toclevel-1 tocsection-18"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-19"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>\n<li class="toclevel-1 tocsection-20"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a>\n<ul>\n<li class="toclevel-2 tocsection-21"><a href="#Concepts"><span class="tocnumber">11.1</span> <span class="toctext">Concepts</span></a></li>\n</ul>\n</li>\n</ul>\n</div>\n<h2><span class="mw-headline" id="Definition">Definition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=1" title="Edit section: Definition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X_{n}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X_{n}}</annotation>\n</semantics>\n</math></span><img alt="X_{n}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/72a8564cedc659cf2f95ae68bc5de2f5207a3285" style="vertical-align: -0.671ex; width:3.143ex; height:2.509ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y_{n}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y_{n}}</annotation>\n</semantics>\n</math></span><img alt="Y_{n}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f19a1b3bf39298aacb7e2daeab9320130a986fb0" style="vertical-align: -0.671ex; width:2.569ex; height:2.509ex;"/></span> be discrete-time <a href="/wiki/Stochastic_process" title="Stochastic process">stochastic processes</a> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle n\\geq 1}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>n</mi>\n<mo>\xe2\x89\xa5<!-- \xe2\x89\xa5 --></mo>\n<mn>1</mn>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle n\\geq 1}</annotation>\n</semantics>\n</math></span><img alt="n\\geq 1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d8ce9ce38d06f6bf5a3fe063118c09c2b6202bfe" style="vertical-align: -0.505ex; width:5.656ex; height:2.343ex;"/></span>. The pair <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle (X_{n},Y_{n})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo stretchy="false">(</mo>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>,</mo>\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle (X_{n},Y_{n})}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle (X_{n},Y_{n})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d52ed98685e48f1bab92be87c5cdd638e058116b" style="vertical-align: -0.838ex; width:8.555ex; height:2.843ex;"/></span> is a <i>hidden markov model</i> if\n</p>\n<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X_{n}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X_{n}}</annotation>\n</semantics>\n</math></span><img alt="X_{n}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/72a8564cedc659cf2f95ae68bc5de2f5207a3285" style="vertical-align: -0.671ex; width:3.143ex; height:2.509ex;"/></span> is a <a class="mw-redirect" href="/wiki/Markov_process" title="Markov process">Markov process</a> and is not directly observable ("hidden");</li>\n<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{1}=x_{1},\\ldots ,X_{n}=x_{n}{\\bigr )}=\\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )},}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">P</mi>\n</mrow>\n</mrow>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">(</mo>\n</mrow>\n</mrow>\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n<mtext>\xc2\xa0</mtext>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">|</mo>\n</mrow>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>=</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-CLOSE">\n<mo maxsize="1.2em" minsize="1.2em">)</mo>\n</mrow>\n</mrow>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">P</mi>\n</mrow>\n</mrow>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">(</mo>\n</mrow>\n</mrow>\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n<mtext>\xc2\xa0</mtext>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">|</mo>\n</mrow>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-CLOSE">\n<mo maxsize="1.2em" minsize="1.2em">)</mo>\n</mrow>\n</mrow>\n<mo>,</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{1}=x_{1},\\ldots ,X_{n}=x_{n}{\\bigr )}=\\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )},}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{1}=x_{1},\\ldots ,X_{n}=x_{n}{\\bigr )}=\\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )},}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9e059b412dd575786c2565eb0b89ea602e37298d" style="vertical-align: -1.005ex; width:61.572ex; height:3.176ex;"/></span></li></ul>\n<p>for every <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle n\\geq 1,}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>n</mi>\n<mo>\xe2\x89\xa5<!-- \xe2\x89\xa5 --></mo>\n<mn>1</mn>\n<mo>,</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle n\\geq 1,}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle n\\geq 1,}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cc38ec6af7dd11fdc9baa67365f23906d76da4bb" style="vertical-align: -0.671ex; width:6.302ex; height:2.509ex;"/></span> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle x_{1},\\ldots ,x_{n},}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>,</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle x_{1},\\ldots ,x_{n},}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle x_{1},\\ldots ,x_{n},}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8fb4ea72660b223c376e371c2301215a39e53a55" style="vertical-align: -0.671ex; width:10.757ex; height:2.009ex;"/></span> and an arbitrary (<a href="/wiki/Measurable_space" title="Measurable space">measurable</a>) set <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle A}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>A</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle A}</annotation>\n</semantics>\n</math></span><img alt="A" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;"/></span>.\n</p>\n<h3><span class="mw-headline" id="Terminology">Terminology</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=2" title="Edit section: Terminology">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The states of the process <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X_{n}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X_{n}}</annotation>\n</semantics>\n</math></span><img alt="X_{n}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/72a8564cedc659cf2f95ae68bc5de2f5207a3285" style="vertical-align: -0.671ex; width:3.143ex; height:2.509ex;"/></span> are called <i>hidden states</i>, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-OP MJX-fixedlimits">\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="bold">P</mi>\n</mrow>\n</mrow>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">(</mo>\n</mrow>\n</mrow>\n<msub>\n<mi>Y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n<mtext>\xc2\xa0</mtext>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-OPEN">\n<mo maxsize="1.2em" minsize="1.2em">|</mo>\n</mrow>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<msub>\n<mi>X</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<msub>\n<mi>x</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-CLOSE">\n<mo maxsize="1.2em" minsize="1.2em">)</mo>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\operatorname {\\mathbf {P} } {\\bigl (}Y_{n}\\in A\\ {\\bigl |}\\ X_{n}=x_{n}{\\bigr )}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a80f12d136089433153fe171fbb63b39c3f521d0" style="vertical-align: -1.005ex; width:22.094ex; height:3.176ex;"/></span> is called <i>emission probability</i> or <i>output probability</i>.\n</p>\n<h2><span class="mw-headline" id="Examples">Examples</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=3" title="Edit section: Examples">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<h3><span class="mw-headline" id="Drawing_balls_from_hidden_urns">Drawing balls from hidden urns</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=4" title="Edit section: Drawing balls from hidden urns">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a class="image" href="/wiki/File:HiddenMarkovModel.svg"><img alt="" class="thumbimage" data-file-height="600" data-file-width="750" decoding="async" height="240" src="//upload.wikimedia.org/wikipedia/commons/thumb/8/8a/HiddenMarkovModel.svg/300px-HiddenMarkovModel.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/8a/HiddenMarkovModel.svg/450px-HiddenMarkovModel.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8a/HiddenMarkovModel.svg/600px-HiddenMarkovModel.svg.png 2x" width="300"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:HiddenMarkovModel.svg" title="Enlarge"></a></div>Figure 1. Probabilistic parameters of a hidden Markov model (example)<br/> <i>X</i> \xe2\x80\x94 states<br/> <i>y</i> \xe2\x80\x94 possible observations<br/> <i>a</i> \xe2\x80\x94 state transition probabilities<br/> <i>b</i> \xe2\x80\x94 output probabilities</div></div></div>\n<p>In its discrete form, a hidden Markov process can be visualized as a generalization of the <a href="/wiki/Urn_problem" title="Urn problem">urn problem</a> with replacement (where each item from the urn is returned to the original urn before the next step).<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> Consider this example: in a room that is not visible to an observer there is a genie. The room contains urns X1, X2, X3, ... each of which contains a known mix of balls, each ball labeled y1, y2, y3, ... .  The genie chooses an urn in that room and randomly draws a ball from that urn.  It then puts the ball onto a conveyor belt, where the observer can observe the sequence of the balls but not the sequence of urns from which they were drawn. The genie has some procedure to choose urns; the choice of the urn for the <i>n</i>-th ball depends only upon a random number and the choice of the urn for the (<i>n</i>\xc2\xa0\xe2\x88\x92\xc2\xa01)-th ball.  The choice of urn does not directly depend on the urns chosen before this single previous urn; therefore, this is called a <a class="mw-redirect" href="/wiki/Markov_process" title="Markov process">Markov process</a>. It can be described by the upper part of Figure 1.\n</p><p>The Markov process itself cannot be observed, only the sequence of labeled balls, thus this arrangement is called a "hidden Markov process". This is illustrated by the lower part of the diagram shown in Figure 1, where one can see that balls y1, y2, y3, y4 can be drawn at each state. Even if the observer knows the composition of the urns and has just observed a sequence of three balls, <i>e.g.</i> y1, y2 and y3 on the conveyor belt, the observer still cannot be <i>sure</i> which urn (<i>i.e.</i>, at which state) the genie has drawn the third ball from. However, the observer can work out other information, such as the likelihood that the third ball came from each of the urns.\n</p>\n<h3><span class="mw-headline" id="Weather_guessing_game">Weather guessing game</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=5" title="Edit section: Weather guessing game">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Consider two friends, Alice and Bob, who live far apart from each other and who talk together daily over the telephone about what they did that day. Bob is only interested in three activities: walking in the park, shopping, and cleaning his apartment. The choice of what to do is determined exclusively by the weather on a given day. Alice has no definite information about the weather, but she knows general trends. Based on what Bob tells her he did each day, Alice tries to guess what the weather must have been like.\n</p><p>Alice believes that the weather operates as a discrete <a href="/wiki/Markov_chain" title="Markov chain">Markov chain</a>. There are two states, "Rainy" and "Sunny", but she cannot observe them directly, that is, they are <i>hidden</i> from her. On each day, there is a certain chance that Bob will perform one of the following activities, depending on the weather: "walk", "shop", or "clean". Since Bob tells Alice about his activities, those are the <i>observations</i>. The entire system is that of a hidden Markov model (HMM).\n</p><p>Alice knows the general weather trends in the area, and what Bob likes to do on average. In other words, the parameters of the HMM are known. They can be represented as follows in <a class="mw-redirect" href="/wiki/Python_programming_language" title="Python programming language">Python</a>:\n</p>\n<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="n">states</span> <span class="o">=</span> <span class="p">(</span><span class="s1">\'Rainy\'</span><span class="p">,</span> <span class="s1">\'Sunny\'</span><span class="p">)</span>\n \n<span class="n">observations</span> <span class="o">=</span> <span class="p">(</span><span class="s1">\'walk\'</span><span class="p">,</span> <span class="s1">\'shop\'</span><span class="p">,</span> <span class="s1">\'clean\'</span><span class="p">)</span>\n \n<span class="n">start_probability</span> <span class="o">=</span> <span class="p">{</span><span class="s1">\'Rainy\'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span> <span class="s1">\'Sunny\'</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">}</span>\n \n<span class="n">transition_probability</span> <span class="o">=</span> <span class="p">{</span>\n   <span class="s1">\'Rainy\'</span> <span class="p">:</span> <span class="p">{</span><span class="s1">\'Rainy\'</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s1">\'Sunny\'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>\n   <span class="s1">\'Sunny\'</span> <span class="p">:</span> <span class="p">{</span><span class="s1">\'Rainy\'</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s1">\'Sunny\'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">},</span>\n   <span class="p">}</span>\n \n<span class="n">emission_probability</span> <span class="o">=</span> <span class="p">{</span>\n   <span class="s1">\'Rainy\'</span> <span class="p">:</span> <span class="p">{</span><span class="s1">\'walk\'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">\'shop\'</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s1">\'clean\'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>\n   <span class="s1">\'Sunny\'</span> <span class="p">:</span> <span class="p">{</span><span class="s1">\'walk\'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span> <span class="s1">\'shop\'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s1">\'clean\'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span>\n   <span class="p">}</span>\n</pre></div>\n<p>In this piece of code, <code>start_probability</code> represents Alice\'s belief about which state the HMM is in when Bob first calls her (all she knows is that it tends to be rainy on average). The particular probability distribution used here is not the equilibrium one, which is (given the transition probabilities) approximately <code>{\'Rainy\': 0.57, \'Sunny\': 0.43}</code>. The <code>transition_probability</code> represents the change of the weather in the underlying Markov chain. In this example, there is only a 30% chance that tomorrow will be sunny if today is rainy. The <code>emission_probability</code> represents how likely Bob is to perform a certain activity on each day. If it is rainy, there is a 50% chance that he is cleaning his apartment; if it is sunny, there is a 60% chance that he is outside for a walk.\n</p>\n<div class="center"><div class="floatnone"><a class="image" href="/wiki/File:HMMGraph.svg" title="Graphical representation of the given HMM"><img alt="Graphical representation of the given HMM" class="thumbborder" data-file-height="546" data-file-width="708" decoding="async" height="308" src="//upload.wikimedia.org/wikipedia/commons/thumb/4/43/HMMGraph.svg/400px-HMMGraph.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/43/HMMGraph.svg/600px-HMMGraph.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/43/HMMGraph.svg/800px-HMMGraph.svg.png 2x" width="400"/></a></div></div>\n<p><i>A similar example is further elaborated in the <a href="/wiki/Viterbi_algorithm#Example" title="Viterbi algorithm">Viterbi algorithm</a> page.</i>\n</p>\n<h2><span class="mw-headline" id="Structural_architecture">Structural architecture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=6" title="Edit section: Structural architecture">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The diagram below shows the general architecture of an instantiated HMM. Each oval shape represents a random variable that can adopt any of a number of values. The random variable <i>x</i>(<i>t</i>) is the hidden state at time <span class="texhtml mvar" style="font-style:italic;">t</span> (with the model from the above diagram, <i>x</i>(<i>t</i>)\xc2\xa0\xe2\x88\x88\xc2\xa0{\xc2\xa0<i>x</i><sub>1</sub>,\xc2\xa0<i>x</i><sub>2</sub>,\xc2\xa0<i>x</i><sub>3</sub>\xc2\xa0}). The random variable <i>y</i>(<i>t</i>) is the observation at time <span class="texhtml mvar" style="font-style:italic;">t</span> (with <i>y</i>(<i>t</i>)\xc2\xa0\xe2\x88\x88\xc2\xa0{\xc2\xa0<i>y</i><sub>1</sub>,\xc2\xa0<i>y</i><sub>2</sub>,\xc2\xa0<i>y</i><sub>3</sub>,\xc2\xa0<i>y</i><sub>4</sub>\xc2\xa0}). The arrows in the diagram (often called a <a href="/wiki/Trellis_(graph)" title="Trellis (graph)">trellis diagram</a>) denote conditional dependencies.\n</p><p>From the diagram, it is clear that the <a href="/wiki/Conditional_probability_distribution" title="Conditional probability distribution">conditional probability distribution</a> of the hidden variable <i>x</i>(<i>t</i>) at time <span class="texhtml mvar" style="font-style:italic;">t</span>, given the values of the hidden variable <span class="texhtml mvar" style="font-style:italic;">x</span> at all times, depends <i>only</i> on the value of the hidden variable <i>x</i>(<i>t</i>\xc2\xa0\xe2\x88\x92\xc2\xa01); the values at time <i>t</i>\xc2\xa0\xe2\x88\x92\xc2\xa02 and before have no influence. This is called the <a href="/wiki/Markov_property" title="Markov property">Markov property</a>. Similarly, the value of the observed variable <i>y</i>(<i>t</i>) only depends on the value of the hidden variable <i>x</i>(<i>t</i>) (both at time <span class="texhtml mvar" style="font-style:italic;">t</span>).\n</p><p>In the standard type of hidden Markov model considered here, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a <a href="/wiki/Categorical_distribution" title="Categorical distribution">categorical distribution</a>) or continuous (typically from a <a class="mw-redirect" href="/wiki/Gaussian_distribution" title="Gaussian distribution">Gaussian distribution</a>).  The parameters of a hidden Markov model are of two types, <i>transition probabilities</i> and <i>emission probabilities</i> (also known as <i>output probabilities</i>).  The transition probabilities control the way the hidden state at time <span class="texhtml mvar" style="font-style:italic;">t</span> is chosen given the hidden state at time <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle t-1}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>t</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle t-1}</annotation>\n</semantics>\n</math></span><img alt="t-1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a215d9553945bb84b3b5a79cc796fb7d6e0629f0" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;"/></span>.\n</p><p>The hidden state space is assumed to consist of one of <span class="texhtml mvar" style="font-style:italic;">N</span> possible values, modelled as a categorical distribution. (See the section below on extensions for other possibilities.) This means that for each of the <span class="texhtml mvar" style="font-style:italic;">N</span> possible states that a hidden variable at time <span class="texhtml mvar" style="font-style:italic;">t</span> can be in, there is a transition probability from this state to each of the <span class="texhtml mvar" style="font-style:italic;">N</span> possible states of the hidden variable at time <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle t+1}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>t</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle t+1}</annotation>\n</semantics>\n</math></span><img alt="t+1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ab2785d8415d6902b0c93efe1419c4bc3ce4643d" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;"/></span>, for a total of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mi>N</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N^{2}}</annotation>\n</semantics>\n</math></span><img alt="N^{2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fe131b76af8a2bc86e01b14a7ba843db69c1a164" style="vertical-align: -0.338ex; width:3.177ex; height:2.676ex;"/></span> transition probabilities. Note that the set of transition probabilities for transitions from any given state must sum to 1. Thus, the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N\\times N}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>N</mi>\n<mo>\xc3\x97<!-- \xc3\x97 --></mo>\n<mi>N</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N\\times N}</annotation>\n</semantics>\n</math></span><img alt="N\\times N" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/99a86c5231bb3cbb863d9d428ebe9ac8db8d4ffb" style="vertical-align: -0.338ex; width:6.968ex; height:2.176ex;"/></span> matrix of transition probabilities is a <a href="/wiki/Stochastic_matrix" title="Stochastic matrix">Markov matrix</a>. Because any one transition probability can be determined once the others are known, there are a total of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N(N-1)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>N</mi>\n<mo stretchy="false">(</mo>\n<mi>N</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N(N-1)}</annotation>\n</semantics>\n</math></span><img alt="N(N-1)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f1fee54b95983b9c3f7403047c1cfc4af3d43c5" style="vertical-align: -0.838ex; width:9.939ex; height:2.843ex;"/></span> transition parameters.\n</p><p>In addition, for each of the <span class="texhtml mvar" style="font-style:italic;">N</span> possible states, there is a set of emission probabilities governing the distribution of the observed variable at a particular time given the state of the hidden variable at that time.  The size of this set depends on the nature of the observed variable.  For example, if the observed variable is discrete with <span class="texhtml mvar" style="font-style:italic;">M</span> possible values, governed by a <a href="/wiki/Categorical_distribution" title="Categorical distribution">categorical distribution</a>, there will be <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle M-1}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>M</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle M-1}</annotation>\n</semantics>\n</math></span><img alt="M-1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0ff0c82e48914e34b3c3bd227cf4d09a2fb5eb7" style="vertical-align: -0.505ex; width:6.445ex; height:2.343ex;"/></span> separate parameters, for a total of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N(M-1)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>N</mi>\n<mo stretchy="false">(</mo>\n<mi>M</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N(M-1)}</annotation>\n</semantics>\n</math></span><img alt="N(M-1)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/53e1437b1c4092d3415c638d73fbcecc74a4df3d" style="vertical-align: -0.838ex; width:10.318ex; height:2.843ex;"/></span> emission parameters over all hidden states.  On the other hand, if the observed variable is an <span class="texhtml mvar" style="font-style:italic;">M</span>-dimensional vector distributed according to an arbitrary <a class="mw-redirect" href="/wiki/Multivariate_Gaussian_distribution" title="Multivariate Gaussian distribution">multivariate Gaussian distribution</a>, there will be <span class="texhtml mvar" style="font-style:italic;">M</span> parameters controlling the <a href="/wiki/Mean" title="Mean">means</a> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\frac {M(M+1)}{2}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mrow>\n<mi>M</mi>\n<mo stretchy="false">(</mo>\n<mi>M</mi>\n<mo>+</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n</mrow>\n<mn>2</mn>\n</mfrac>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\frac {M(M+1)}{2}}}</annotation>\n</semantics>\n</math></span><img alt="{\\frac {M(M+1)}{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/18dcc1b051fcb4bfe62daa4696df064d873905dd" style="vertical-align: -1.838ex; width:11.533ex; height:5.676ex;"/></span> parameters controlling the <a href="/wiki/Covariance_matrix" title="Covariance matrix">covariance matrix</a>, for a total of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N\\left(M+{\\frac {M(M+1)}{2}}\\right)={\\frac {NM(M+3)}{2}}=O(NM^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>N</mi>\n<mrow>\n<mo>(</mo>\n<mrow>\n<mi>M</mi>\n<mo>+</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mrow>\n<mi>M</mi>\n<mo stretchy="false">(</mo>\n<mi>M</mi>\n<mo>+</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n</mrow>\n<mn>2</mn>\n</mfrac>\n</mrow>\n</mrow>\n<mo>)</mo>\n</mrow>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mrow>\n<mi>N</mi>\n<mi>M</mi>\n<mo stretchy="false">(</mo>\n<mi>M</mi>\n<mo>+</mo>\n<mn>3</mn>\n<mo stretchy="false">)</mo>\n</mrow>\n<mn>2</mn>\n</mfrac>\n</mrow>\n<mo>=</mo>\n<mi>O</mi>\n<mo stretchy="false">(</mo>\n<mi>N</mi>\n<msup>\n<mi>M</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N\\left(M+{\\frac {M(M+1)}{2}}\\right)={\\frac {NM(M+3)}{2}}=O(NM^{2})}</annotation>\n</semantics>\n</math></span><img alt="N\\left(M+{\\frac {M(M+1)}{2}}\\right)={\\frac {NM(M+3)}{2}}=O(NM^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fea9b108de1b00ed6a13b5dee407a894798ea7c0" style="vertical-align: -2.505ex; width:51.68ex; height:6.343ex;"/></span> emission parameters. (In such a case, unless the value of <span class="texhtml mvar" style="font-style:italic;">M</span> is small, it may be more practical to restrict the nature of the covariances between individual elements of the observation vector, e.g. by assuming that the elements are independent of each other, or less restrictively, are independent of all but a fixed number of adjacent elements.)\n</p>\n<div class="center"><div class="floatnone"><a class="image" href="/wiki/File:Hmm_temporal_bayesian_net.svg" title="Temporal evolution of a hidden Markov model"><img alt="Temporal evolution of a hidden Markov model" data-file-height="214" data-file-width="833" decoding="async" height="128" src="//upload.wikimedia.org/wikipedia/commons/thumb/8/83/Hmm_temporal_bayesian_net.svg/500px-Hmm_temporal_bayesian_net.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/83/Hmm_temporal_bayesian_net.svg/750px-Hmm_temporal_bayesian_net.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/83/Hmm_temporal_bayesian_net.svg/1000px-Hmm_temporal_bayesian_net.svg.png 2x" width="500"/></a></div></div>\n<h2><span class="mw-headline" id="Inference">Inference</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=7" title="Edit section: Inference">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="thumb tright"><div class="thumbinner" style="width:402px;"><a class="image" href="/wiki/File:HMMsequence.svg"><img alt="" class="thumbimage" data-file-height="753" data-file-width="727" decoding="async" height="414" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/13/HMMsequence.svg/400px-HMMsequence.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/13/HMMsequence.svg/600px-HMMsequence.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/13/HMMsequence.svg/800px-HMMsequence.svg.png 2x" width="400"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:HMMsequence.svg" title="Enlarge"></a></div>The state transition and output probabilities of an HMM are indicated by the line opacity in the upper part of the diagram. Given that we have observed the output sequence in the lower part of the diagram, we may be interested in the most likely sequence of states that could have produced it. Based on the arrows that are present in the diagram, the following state sequences are candidates:<br/> 5 3 2 5 3 2<br/> 4 3 2 5 3 2<br/> 3 1 2 5 3 2<br/> We can find the most likely sequence by evaluating the joint probability of both the state sequence and the observations for each case (simply by multiplying the probability values, which here correspond to the opacities of the arrows involved). In general, this type of problem (i.e. finding the most likely explanation for an observation sequence) can be solved efficiently using the <a href="/wiki/Viterbi_algorithm" title="Viterbi algorithm">Viterbi algorithm</a>.</div></div></div>\n<p>Several <a href="/wiki/Inference" title="Inference">inference</a> problems are associated with hidden Markov models, as outlined below.\n</p>\n<h3><span class="mw-headline" id="Probability_of_an_observed_sequence">Probability of an observed sequence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=8" title="Edit section: Probability of an observed sequence">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The task is to compute in a best way, given the parameters of the model, the probability of a particular output sequence.  This requires summation over all possible state sequences:\n</p><p>The probability of observing a sequence\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y=y(0),y(1),\\dots ,y(L-1)\\,}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n<mo>=</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mn>0</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mi>L</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mspace width="thinmathspace"></mspace>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y=y(0),y(1),\\dots ,y(L-1)\\,}</annotation>\n</semantics>\n</math></span><img alt="Y=y(0),y(1),\\dots ,y(L-1)\\," aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a4b513af58f26432a7d7a0356e4ec571270c2873" style="vertical-align: -0.838ex; width:28.276ex; height:2.843ex;"/></span></dd></dl>\n<p>of length <i>L</i> is given by\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle P(Y)=\\sum _{X}P(Y\\mid X)P(X),\\,}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>P</mi>\n<mo stretchy="false">(</mo>\n<mi>Y</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>X</mi>\n</mrow>\n</munder>\n<mi>P</mi>\n<mo stretchy="false">(</mo>\n<mi>Y</mi>\n<mo>\xe2\x88\xa3<!-- \xe2\x88\xa3 --></mo>\n<mi>X</mi>\n<mo stretchy="false">)</mo>\n<mi>P</mi>\n<mo stretchy="false">(</mo>\n<mi>X</mi>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mspace width="thinmathspace"></mspace>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle P(Y)=\\sum _{X}P(Y\\mid X)P(X),\\,}</annotation>\n</semantics>\n</math></span><img alt="P(Y)=\\sum _{X}P(Y\\mid X)P(X),\\," aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62433038e2fa335317993d8deb20c0be53b416c4" style="vertical-align: -3.005ex; width:27.982ex; height:5.509ex;"/></span></dd></dl>\n<p>where the sum runs over all possible hidden-node sequences\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X=x(0),x(1),\\dots ,x(L-1).\\,}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n<mo>=</mo>\n<mi>x</mi>\n<mo stretchy="false">(</mo>\n<mn>0</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>x</mi>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mi>x</mi>\n<mo stretchy="false">(</mo>\n<mi>L</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>.</mo>\n<mspace width="thinmathspace"></mspace>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X=x(0),x(1),\\dots ,x(L-1).\\,}</annotation>\n</semantics>\n</math></span><img alt="X=x(0),x(1),\\dots ,x(L-1).\\," aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/04ddfb5ccab85138570048a2b8ad576cfbd2d4d8" style="vertical-align: -0.838ex; width:29.652ex; height:2.843ex;"/></span></dd></dl>\n<p>Applying the principle of <a href="/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming</a>, this problem, too, can be handled efficiently using the <a href="/wiki/Forward_algorithm" title="Forward algorithm">forward algorithm</a>.\n</p>\n<h3><span class="mw-headline" id="Probability_of_the_latent_variables">Probability of the latent variables</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=9" title="Edit section: Probability of the latent variables">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>A number of related tasks ask about the probability of one or more of the latent variables, given the model\'s parameters and a sequence of observations <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y(1),\\dots ,y(t).}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mi>t</mi>\n<mo stretchy="false">)</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y(1),\\dots ,y(t).}</annotation>\n</semantics>\n</math></span><img alt="y(1),\\dots ,y(t)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a535986e8c88ca6726fd000c129a7b5b83f946bb" style="vertical-align: -0.838ex; width:13.757ex; height:2.843ex;"/></span>\n</p>\n<h4><span class="mw-headline" id="Filtering">Filtering</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=10" title="Edit section: Filtering">edit</a><span class="mw-editsection-bracket">]</span></span></h4>\n<p>The task is to compute, given the model\'s parameters and a sequence of observations, the distribution over hidden states of the last latent variable at the end of the sequence, i.e. to compute <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle P(x(t)\\ |\\ y(1),\\dots ,y(t))}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>P</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">(</mo>\n<mi>t</mi>\n<mo stretchy="false">)</mo>\n<mtext>\xc2\xa0</mtext>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mi>t</mi>\n<mo stretchy="false">)</mo>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle P(x(t)\\ |\\ y(1),\\dots ,y(t))}</annotation>\n</semantics>\n</math></span><img alt="P(x(t)\\ |\\ y(1),\\dots ,y(t))" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/84c378ce7388d8acfb81dedc1d76763fd8a8a06a" style="vertical-align: -0.838ex; width:22.451ex; height:2.843ex;"/></span>.  This task is normally used when the sequence of latent variables is thought of as the underlying states that a process moves through at a sequence of points of time, with corresponding observations at each point in time.  Then, it is natural to ask about the state of the process at the end.\n</p><p>This problem can be handled efficiently using the <a href="/wiki/Forward_algorithm" title="Forward algorithm">forward algorithm</a>.\n</p>\n<h4><span class="mw-headline" id="Smoothing">Smoothing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=11" title="Edit section: Smoothing">edit</a><span class="mw-editsection-bracket">]</span></span></h4>\n<p>This is similar to filtering but asks about the distribution of a latent variable somewhere in the middle of a sequence, i.e. to compute <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle P(x(k)\\ |\\ y(1),\\dots ,y(t))}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>P</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo stretchy="false">(</mo>\n<mi>k</mi>\n<mo stretchy="false">)</mo>\n<mtext>\xc2\xa0</mtext>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mtext>\xc2\xa0</mtext>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mn>1</mn>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">(</mo>\n<mi>t</mi>\n<mo stretchy="false">)</mo>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle P(x(k)\\ |\\ y(1),\\dots ,y(t))}</annotation>\n</semantics>\n</math></span><img alt="P(x(k)\\ |\\ y(1),\\dots ,y(t))" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4861e645dc5e7cbca8e87e703ab7ff35e93a37aa" style="vertical-align: -0.838ex; width:22.823ex; height:2.843ex;"/></span> for some <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle k&lt;t}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>k</mi>\n<mo>&lt;</mo>\n<mi>t</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle k&lt;t}</annotation>\n</semantics>\n</math></span><img alt="k&lt;t" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7ca1a3ea2d76668acdda69e481b958420402d408" style="vertical-align: -0.338ex; width:5.149ex; height:2.176ex;"/></span>.  From the perspective described above, this can be thought of as the probability distribution over hidden states for a point in time <i>k</i> in the past, relative to time <i>t</i>.\n</p><p>The <a class="mw-redirect" href="/wiki/Forward-backward_algorithm" title="Forward-backward algorithm">forward-backward algorithm</a> is a good method for computing the smoothed values for all hidden state variables.\n</p>\n<h4><span class="mw-headline" id="Most_likely_explanation">Most likely explanation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=12" title="Edit section: Most likely explanation">edit</a><span class="mw-editsection-bracket">]</span></span></h4>\n<p>The task, unlike the previous two, asks about the <a class="mw-redirect" href="/wiki/Joint_probability" title="Joint probability">joint probability</a> of the <i>entire</i> sequence of hidden states that generated a particular sequence of observations (see illustration on the right).  This task is generally applicable when HMM\'s are applied to different sorts of problems from those for which the tasks of filtering and smoothing are applicable.  An example is <a href="/wiki/Part-of-speech_tagging" title="Part-of-speech tagging">part-of-speech tagging</a>, where the hidden states represent the underlying <a href="/wiki/Part_of_speech" title="Part of speech">parts of speech</a> corresponding to an observed sequence of words.  In this case, what is of interest is the entire sequence of parts of speech, rather than simply the part of speech for a single word, as filtering or smoothing would compute.\n</p><p>This task requires finding a maximum over all possible state sequences, and can be solved efficiently by the <a href="/wiki/Viterbi_algorithm" title="Viterbi algorithm">Viterbi algorithm</a>.\n</p>\n<h3><span class="mw-headline" id="Statistical_significance">Statistical significance</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=13" title="Edit section: Statistical significance">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>For some of the above problems, it may also be interesting to ask about <a href="/wiki/Statistical_significance" title="Statistical significance">statistical significance</a>.  What is the probability that a sequence drawn from some <a href="/wiki/Null_distribution" title="Null distribution">null distribution</a> will have an HMM probability (in the case of the forward algorithm) or a maximum state sequence probability (in the case of the Viterbi algorithm) at least as large as that of a particular output sequence?<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>  When an HMM is used to evaluate the relevance of a hypothesis for a particular output sequence, the statistical significance indicates the <a href="/wiki/False_positive_rate" title="False positive rate">false positive rate</a> associated with failing to reject the hypothesis for the output sequence.\n</p>\n<h2><span class="mw-headline" id="Learning">Learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=14" title="Edit section: Learning">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The parameter learning task in HMMs is to find, given an output sequence or a set of such sequences, the best set of state transition and emission probabilities. The task is usually to derive the <a class="mw-redirect" href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> estimate of the parameters of the HMM given the set of output sequences. No tractable algorithm is known for solving this problem exactly, but a local maximum likelihood can be derived efficiently using the <a href="/wiki/Baum%E2%80%93Welch_algorithm" title="Baum\xe2\x80\x93Welch algorithm">Baum\xe2\x80\x93Welch algorithm</a> or the Baldi\xe2\x80\x93Chauvin algorithm.  The <a href="/wiki/Baum%E2%80%93Welch_algorithm" title="Baum\xe2\x80\x93Welch algorithm">Baum\xe2\x80\x93Welch algorithm</a> is a special case of the <a class="mw-redirect" href="/wiki/Expectation-maximization_algorithm" title="Expectation-maximization algorithm">expectation-maximization algorithm</a>. If the HMMs are used for time series prediction, more sophisticated Bayesian inference methods, like <a href="/wiki/Markov_chain_Monte_Carlo" title="Markov chain Monte Carlo">Markov chain Monte Carlo</a> (MCMC) sampling are proven to be favorable over finding a single maximum likelihood model both in terms of accuracy and stability.<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> Since MCMC imposes significant computational burden, in cases where computational scalability is also of interest, one may alternatively resort to variational approximations to Bayesian inference, e.g.<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup> Indeed, approximate variational inference offers computational efficiency comparable to expectation-maximization, while yielding an accuracy profile only slightly inferior to exact MCMC-type Bayesian inference.\n</p>\n<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=15" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a class="image" href="/wiki/File:A_profile_HMM_modelling_a_multiple_sequence_alignment.png"><img alt="" class="thumbimage" data-file-height="421" data-file-width="800" decoding="async" height="116" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/71/A_profile_HMM_modelling_a_multiple_sequence_alignment.png/220px-A_profile_HMM_modelling_a_multiple_sequence_alignment.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/71/A_profile_HMM_modelling_a_multiple_sequence_alignment.png/330px-A_profile_HMM_modelling_a_multiple_sequence_alignment.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/71/A_profile_HMM_modelling_a_multiple_sequence_alignment.png/440px-A_profile_HMM_modelling_a_multiple_sequence_alignment.png 2x" width="220"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:A_profile_HMM_modelling_a_multiple_sequence_alignment.png" title="Enlarge"></a></div>A profile HMM modelling a multiple sequence alignment</div></div></div>\n<p>HMMs can be applied in many fields where the goal is to recover a data sequence that is not immediately observable (but other data that depend on the sequence are). Applications include:\n</p>\n<ul><li><a href="/wiki/Computational_finance" title="Computational finance">Computational finance</a><sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup><sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup></li>\n<li><a href="/wiki/Single-molecule_experiment" title="Single-molecule experiment">Single-molecule kinetic analysis</a><sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup></li>\n<li><a href="/wiki/Cryptanalysis" title="Cryptanalysis">Cryptanalysis</a></li>\n<li><a href="/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a>, including <a href="/wiki/Siri" title="Siri">Siri</a><sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup></li>\n<li><a href="/wiki/Speech_synthesis" title="Speech synthesis">Speech synthesis</a></li>\n<li><a href="/wiki/Part-of-speech_tagging" title="Part-of-speech tagging">Part-of-speech tagging</a></li>\n<li>Document separation in scanning solutions</li>\n<li><a href="/wiki/Machine_translation" title="Machine translation">Machine translation</a></li>\n<li><a href="/wiki/Partial_discharge" title="Partial discharge">Partial discharge</a></li>\n<li><a href="/wiki/Gene_prediction" title="Gene prediction">Gene prediction</a></li>\n<li><a href="/wiki/Handwriting_recognition" title="Handwriting recognition">Handwriting recognition</a></li>\n<li><a href="/wiki/Sequence_alignment" title="Sequence alignment">Alignment of bio-sequences</a></li>\n<li><a href="/wiki/Time_series" title="Time series">Time series analysis</a></li>\n<li><a href="/wiki/Activity_recognition" title="Activity recognition">Activity recognition</a></li>\n<li><a href="/wiki/Protein_folding" title="Protein folding">Protein folding</a><sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup></li>\n<li>Sequence classification<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup></li>\n<li><a class="new" href="/w/index.php?title=Metamorphic_virus_detection&amp;action=edit&amp;redlink=1" title="Metamorphic virus detection (page does not exist)">Metamorphic virus detection</a><sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup></li>\n<li><a href="/wiki/Sequence_motif" title="Sequence motif">DNA motif discovery</a><sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup></li>\n<li>DNA hybridization kinetics<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup></li>\n<li><a href="/wiki/Chromatin" title="Chromatin">Chromatin</a> state discovery<sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup></li>\n<li><a href="/wiki/Transportation_forecasting" title="Transportation forecasting">Transportation forecasting</a><sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup></li>\n<li>Solar irradiance variability <sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup><sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup><sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup></li></ul>\n<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=16" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The <a href="/wiki/Forward%E2%80%93backward_algorithm" title="Forward\xe2\x80\x93backward algorithm">Forward\xe2\x80\x93backward algorithm</a> used in HMM was first described by <a class="mw-redirect" href="/wiki/Ruslan_L._Stratonovich" title="Ruslan L. Stratonovich">Ruslan L. Stratonovich</a> in 1960<sup class="reference" id="cite_ref-Stratonovich1960_24-0"><a href="#cite_note-Stratonovich1960-24">[24]</a></sup> (pages 160\xe2\x80\x94162) and in the late 1950s in his papers in Russian.\nThe Hidden Markov Models were later described in a series of statistical papers by <a href="/wiki/Leonard_E._Baum" title="Leonard E. Baum">Leonard E. Baum</a> and other authors in the second half of the 1960s.<sup class="reference" id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup><sup class="reference" id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup><sup class="reference" id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup><sup class="reference" id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup><sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup> One of the first applications of HMMs was <a href="/wiki/Speech_recognition" title="Speech recognition">speech recognition</a>, starting in the mid-1970s.<sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup><sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup><sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup><sup class="reference" id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup>\n</p><p>In the second half of the 1980s, HMMs began to be applied to the analysis of biological sequences,<sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[34]</a></sup> in particular <a href="/wiki/DNA" title="DNA">DNA</a>. Since then, they have become ubiquitous in the field of <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a>.<sup class="reference" id="cite_ref-durbin_35-0"><a href="#cite_note-durbin-35">[35]</a></sup>\n</p>\n<h2><span class="mw-headline" id="Extensions">Extensions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=17" title="Edit section: Extensions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>In the hidden Markov models considered above, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a <a href="/wiki/Categorical_distribution" title="Categorical distribution">categorical distribution</a>) or continuous (typically from a <a class="mw-redirect" href="/wiki/Gaussian_distribution" title="Gaussian distribution">Gaussian distribution</a>). Hidden Markov models can also be generalized to allow continuous state spaces. Examples of such models are those where the Markov process over hidden variables is a <a href="/wiki/Linear_dynamical_system" title="Linear dynamical system">linear dynamical system</a>, with a linear relationship among related variables and where all hidden and observed variables follow a <a class="mw-redirect" href="/wiki/Gaussian_distribution" title="Gaussian distribution">Gaussian distribution</a>. In simple cases, such as the linear dynamical system just mentioned, exact inference is tractable (in this case, using the <a href="/wiki/Kalman_filter" title="Kalman filter">Kalman filter</a>); however, in general, exact inference in HMMs with continuous latent variables is infeasible, and approximate methods must be used, such as the <a href="/wiki/Extended_Kalman_filter" title="Extended Kalman filter">extended Kalman filter</a> or the <a href="/wiki/Particle_filter" title="Particle filter">particle filter</a>.\n</p><p>Hidden Markov models are <a href="/wiki/Generative_model" title="Generative model">generative models</a>, in which the <a class="mw-redirect" href="/wiki/Joint_distribution" title="Joint distribution">joint distribution</a> of observations and hidden states, or equivalently both the <a class="mw-redirect" href="/wiki/Prior_distribution" title="Prior distribution">prior distribution</a> of hidden states (the <i>transition probabilities</i>) and <a class="mw-redirect" href="/wiki/Conditional_distribution" title="Conditional distribution">conditional distribution</a> of observations given states (the <i>emission probabilities</i>), is modeled.  The above algorithms implicitly assume a <a class="mw-redirect" href="/wiki/Uniform_distribution_(continuous)" title="Uniform distribution (continuous)">uniform</a> prior distribution over the transition probabilities. However, it is also possible to create hidden Markov models with other types of prior distributions. An obvious candidate, given the categorical distribution of the transition probabilities, is the <a href="/wiki/Dirichlet_distribution" title="Dirichlet distribution">Dirichlet distribution</a>, which is the <a href="/wiki/Conjugate_prior" title="Conjugate prior">conjugate prior</a> distribution of the categorical distribution.  Typically, a symmetric Dirichlet distribution is chosen, reflecting ignorance about which states are inherently more likely than others.  The single parameter of this distribution (termed the <i>concentration parameter</i>) controls the relative density or sparseness of the resulting transition matrix.  A choice of 1 yields a uniform distribution.  Values greater than 1 produce a dense matrix, in which the transition probabilities between pairs of states are likely to be nearly equal.  Values less than 1 result in a sparse matrix in which, for each given source state, only a small number of destination states have non-negligible transition probabilities.  It is also possible to use a two-level prior Dirichlet distribution, in which one Dirichlet distribution (the upper distribution) governs the parameters of another Dirichlet distribution (the lower distribution), which in turn governs the transition probabilities.  The upper distribution governs the overall distribution of states, determining how likely each state is to occur; its concentration parameter determines the density or sparseness of states.  Such a two-level prior distribution, where both concentration parameters are set to produce sparse distributions, might be useful for example in <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised</a> <a href="/wiki/Part-of-speech_tagging" title="Part-of-speech tagging">part-of-speech tagging</a>, where some parts of speech occur much more commonly than others; learning algorithms that assume a uniform prior distribution generally perform poorly on this task.  The parameters of models of this sort, with non-uniform prior distributions, can be learned using <a href="/wiki/Gibbs_sampling" title="Gibbs sampling">Gibbs sampling</a> or extended versions of the <a class="mw-redirect" href="/wiki/Expectation-maximization_algorithm" title="Expectation-maximization algorithm">expectation-maximization algorithm</a>.\n</p><p>An extension of the previously described hidden Markov models with <a href="/wiki/Dirichlet_distribution" title="Dirichlet distribution">Dirichlet</a> priors uses a <a href="/wiki/Dirichlet_process" title="Dirichlet process">Dirichlet process</a> in place of a Dirichlet distribution.  This type of model allows for an unknown and potentially infinite number of states.  It is common to use a two-level Dirichlet process, similar to the previously described model with two levels of Dirichlet distributions.  Such a model is called a <i>hierarchical Dirichlet process hidden Markov model</i>, or <i>HDP-HMM</i> for short. It was originally described under the name "Infinite Hidden Markov Model"<sup class="reference plainlinks nourlexpansion" id="ref_Beal,_Matthew_J.,_Zoubin_Ghahramani,_and_Carl_Edward_Rasmussen."><a class="external autonumber" href="https://en.wikipedia.org/wiki/Hidden_Markov_model#endnote_Beal,_Matthew_J.,_Zoubin_Ghahramani,_and_Carl_Edward_Rasmussen._%22The_infinite_hidden_Markov_model.%22_Advances_in_neural_information_processing_systems_14_(2002):_577-584.">[3]</a></sup> and was further formalized in<sup class="reference plainlinks nourlexpansion" id="ref_Teh,_Yee_Whye,_et_al."><a class="external autonumber" href="https://en.wikipedia.org/wiki/Hidden_Markov_model#endnote_Teh,_Yee_Whye,_et_al._%22Hierarchical_dirichlet_processes.%22_Journal_of_the_American_Statistical_Association_101.476_(2006).">[4]</a></sup>.\n</p><p>A different type of extension uses a <a href="/wiki/Discriminative_model" title="Discriminative model">discriminative model</a> in place of the <a href="/wiki/Generative_model" title="Generative model">generative model</a> of standard HMMs.  This type of model directly models the conditional distribution of the hidden states given the observations, rather than modeling the joint distribution.  An example of this model is the so-called <i><a class="mw-redirect" href="/wiki/Maximum_entropy_Markov_model" title="Maximum entropy Markov model">maximum entropy Markov model</a></i> (MEMM), which models the conditional distribution of the states using <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a> (also known as a "<a href="/wiki/Maximum_entropy_probability_distribution" title="Maximum entropy probability distribution">maximum entropy</a> model").  The advantage of this type of model is that arbitrary features (i.e. functions) of the observations can be modeled, allowing domain-specific knowledge of the problem at hand to be injected into the model.  Models of this sort are not limited to modeling direct dependencies between a hidden state and its associated observation; rather, features of nearby observations, of combinations of the associated observation and nearby observations, or in fact of arbitrary observations at any distance from a given hidden state can be included in the process used to determine the value of a hidden state.  Furthermore, there is no need for these features to be <a class="mw-redirect" href="/wiki/Statistically_independent" title="Statistically independent">statistically independent</a> of each other, as would be the case if such features were used in a generative model.  Finally, arbitrary features over pairs of adjacent hidden states can be used rather than simple transition probabilities.  The disadvantages of such models are: (1) The types of prior distributions that can be placed on hidden states are severely limited; (2) It is not possible to predict the probability of seeing an arbitrary observation.  This second limitation is often not an issue in practice, since many common usages of HMM\'s do not require such predictive probabilities.\n</p><p>A variant of the previously described discriminative model is the linear-chain <a href="/wiki/Conditional_random_field" title="Conditional random field">conditional random field</a>.  This uses an undirected graphical model (aka <a href="/wiki/Markov_random_field" title="Markov random field">Markov random field</a>) rather than the directed graphical models of MEMM\'s and similar models.  The advantage of this type of model is that it does not suffer from the so-called <i>label bias</i> problem of MEMM\'s, and thus may make more accurate predictions.  The disadvantage is that training can be slower than for MEMM\'s.\n</p><p>Yet another variant is the <i>factorial hidden Markov model</i>, which allows for a single observation to be conditioned on the corresponding hidden variables of a set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle K}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>K</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle K}</annotation>\n</semantics>\n</math></span><img alt="K" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b76fce82a62ed5461908f0dc8f037de4e3686b0" style="vertical-align: -0.338ex; width:2.066ex; height:2.176ex;"/></span> independent Markov chains, rather than a single Markov chain. It is equivalent to a single HMM, with <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N^{K}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msup>\n<mi>N</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>K</mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N^{K}}</annotation>\n</semantics>\n</math></span><img alt="N^{K}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4cda0a35f9eb8276d799071a218a515391019a42" style="vertical-align: -0.338ex; width:3.816ex; height:2.676ex;"/></span> states (assuming there are <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle N}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>N</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle N}</annotation>\n</semantics>\n</math></span><img alt="N" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5e3890c981ae85503089652feb48b191b57aae3" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;"/></span> states for each chain), and therefore, learning in such a model is difficult: for a sequence of length <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle T}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>T</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle T}</annotation>\n</semantics>\n</math></span><img alt="T" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ec7200acd984a1d3a3d7dc455e262fbe54f7f6e0" style="vertical-align: -0.338ex; width:1.636ex; height:2.176ex;"/></span>, a straightforward Viterbi algorithm has complexity <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle O(N^{2K}\\,T)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>O</mi>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>N</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n<mi>K</mi>\n</mrow>\n</msup>\n<mspace width="thinmathspace"></mspace>\n<mi>T</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle O(N^{2K}\\,T)}</annotation>\n</semantics>\n</math></span><img alt="O(N^{2K}\\,T)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b874841ca8bf26f386805f273a4d87d43c1cc867" style="vertical-align: -0.838ex; width:10.244ex; height:3.176ex;"/></span>. To find an exact solution, a junction tree algorithm could be used, but it results in an <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle O(N^{K+1}\\,K\\,T)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>O</mi>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>N</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>K</mi>\n<mo>+</mo>\n<mn>1</mn>\n</mrow>\n</msup>\n<mspace width="thinmathspace"></mspace>\n<mi>K</mi>\n<mspace width="thinmathspace"></mspace>\n<mi>T</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle O(N^{K+1}\\,K\\,T)}</annotation>\n</semantics>\n</math></span><img alt="O(N^{K+1}\\,K\\,T)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/830574b6e885441d00387d772cbaea341d85c3cd" style="vertical-align: -0.838ex; width:13.976ex; height:3.176ex;"/></span> complexity. In practice, approximate techniques, such as variational approaches, could be used.<sup class="reference" id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup>\n</p><p>All of the above models can be extended to allow for more distant dependencies among hidden states, e.g. allowing for a given state to be dependent on the previous two or three states rather than a single previous state; i.e. the transition probabilities are extended to encompass sets of three or four adjacent states (or in general <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle K}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>K</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle K}</annotation>\n</semantics>\n</math></span><img alt="K" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b76fce82a62ed5461908f0dc8f037de4e3686b0" style="vertical-align: -0.338ex; width:2.066ex; height:2.176ex;"/></span> adjacent states).  The disadvantage of such models is that dynamic-programming algorithms for training them have an <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle O(N^{K}\\,T)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>O</mi>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>N</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>K</mi>\n</mrow>\n</msup>\n<mspace width="thinmathspace"></mspace>\n<mi>T</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle O(N^{K}\\,T)}</annotation>\n</semantics>\n</math></span><img alt="O(N^{K}\\,T)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/60f4bf98121cb8c500aad219064d7e98930c8282" style="vertical-align: -0.838ex; width:9.422ex; height:3.176ex;"/></span> running time, for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle K}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>K</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle K}</annotation>\n</semantics>\n</math></span><img alt="K" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b76fce82a62ed5461908f0dc8f037de4e3686b0" style="vertical-align: -0.338ex; width:2.066ex; height:2.176ex;"/></span> adjacent states and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle T}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>T</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle T}</annotation>\n</semantics>\n</math></span><img alt="T" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ec7200acd984a1d3a3d7dc455e262fbe54f7f6e0" style="vertical-align: -0.338ex; width:1.636ex; height:2.176ex;"/></span> total observations (i.e. a length-<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle T}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>T</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle T}</annotation>\n</semantics>\n</math></span><img alt="T" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ec7200acd984a1d3a3d7dc455e262fbe54f7f6e0" style="vertical-align: -0.338ex; width:1.636ex; height:2.176ex;"/></span> Markov chain).\n</p><p>Another recent extension is the <i>triplet Markov model</i>,<sup class="reference" id="cite_ref-TMM_37-0"><a href="#cite_note-TMM-37">[37]</a></sup> in which an auxiliary underlying process is added to model some data specificities. Many variants of this model have been proposed. One should also mention the interesting link that has been established between the <i>theory of evidence</i> and the <i>triplet Markov models</i><sup class="reference" id="cite_ref-TMMEV_38-0"><a href="#cite_note-TMMEV-38">[38]</a></sup> and which allows to fuse data in Markovian context<sup class="reference" id="cite_ref-JASP_39-0"><a href="#cite_note-JASP-39">[39]</a></sup> and to model nonstationary data.<sup class="reference" id="cite_ref-TSP_40-0"><a href="#cite_note-TSP-40">[40]</a></sup><sup class="reference" id="cite_ref-SPL_41-0"><a href="#cite_note-SPL-41">[41]</a></sup> Note that alternative multi-stream data fusion strategies have also been proposed in the recent literature, e.g.<sup class="reference" id="cite_ref-42"><a href="#cite_note-42">[42]</a></sup>\n</p><p>Finally, a different rationale towards addressing the problem of modeling nonstationary data by means of hidden Markov models was suggested in 2012.<sup class="reference" id="cite_ref-Reservoir-HMM_43-0"><a href="#cite_note-Reservoir-HMM-43">[43]</a></sup> It consists in employing a small recurrent neural network (RNN), specifically a reservoir network,<sup class="reference" id="cite_ref-44"><a href="#cite_note-44">[44]</a></sup> to capture the evolution of the temporal dynamics in the observed data. This information, encoded in the form of a high-dimensional vector, is used as a conditioning variable of the HMM state transition probabilities. Under such a setup, we eventually obtain a nonstationary HMM the transition probabilities of which evolve over time in a manner that is inferred from the data itself, as opposed to some unrealistic ad-hoc model of temporal evolution.\n</p><p>The model suitable in the context of longitudinal data is named\xc2\xa0latent Markov model.<sup class="reference" id="cite_ref-45"><a href="#cite_note-45">[45]</a></sup> The basic version of this model has been extended to include individual covariates, random effects and to model more complex data structures such as multilevel data. A complete overview of the latent Markov models, with special attention to the model assumptions and  to their practical use is provided in<sup class="reference" id="cite_ref-46"><a href="#cite_note-46">[46]</a></sup>\n</p>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=18" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="div-col columns column-width" style="-moz-column-width: 22em; -webkit-column-width: 22em; column-width: 22em;">\n<ul><li><a href="/wiki/Andrey_Markov" title="Andrey Markov">Andrey Markov</a></li>\n<li><a href="/wiki/Baum%E2%80%93Welch_algorithm" title="Baum\xe2\x80\x93Welch algorithm">Baum\xe2\x80\x93Welch algorithm</a></li>\n<li><a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a></li>\n<li><a href="/wiki/Bayesian_programming" title="Bayesian programming">Bayesian programming</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Estimation_theory" title="Estimation theory">Estimation theory</a></li>\n<li><a class="mw-redirect" href="/wiki/HHpred_/_HHsearch" title="HHpred / HHsearch">HHpred / HHsearch</a> free server and software for protein sequence searching</li>\n<li><a href="/wiki/HMMER" title="HMMER">HMMER</a>, a free hidden Markov model program for protein sequence analysis</li>\n<li><a class="mw-redirect" href="/wiki/Hidden_Bernoulli_model" title="Hidden Bernoulli model">Hidden Bernoulli model</a></li>\n<li><a href="/wiki/Hidden_semi-Markov_model" title="Hidden semi-Markov model">Hidden semi-Markov model</a></li>\n<li><a href="/wiki/Hierarchical_hidden_Markov_model" title="Hierarchical hidden Markov model">Hierarchical hidden Markov model</a></li>\n<li><a href="/wiki/Layered_hidden_Markov_model" title="Layered hidden Markov model">Layered hidden Markov model</a></li>\n<li><a href="/wiki/Sequential_dynamical_system" title="Sequential dynamical system">Sequential dynamical system</a></li>\n<li><a class="mw-redirect" href="/wiki/Stochastic_context-free_grammar" title="Stochastic context-free grammar">Stochastic context-free grammar</a></li>\n<li><a class="mw-redirect" href="/wiki/Time_Series" title="Time Series">Time Series</a> Analysis</li>\n<li><a href="/wiki/Variable-order_Markov_model" title="Variable-order Markov model">Variable-order Markov model</a></li>\n<li><a href="/wiki/Viterbi_algorithm" title="Viterbi algorithm">Viterbi algorithm</a></li></ul>\n</div>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=19" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">\n<ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Thad Starner, Alex Pentland. <a class="external text" href="http://www.cc.gatech.edu/~thad/p/031_10_SL/real-time-asl-recognition-from%20video-using-hmm-ISCV95.pdf" rel="nofollow">Real-Time American Sign Language Visual Recognition From Video Using Hidden Markov Models</a>. Master\'s Thesis, MIT, Feb 1995, Program in Media Arts</span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text">B. Pardo and W. Birmingham. <a class="external text" href="http://www.cs.northwestern.edu/~pardo/publications/pardo-birmingham-aaai-05.pdf" rel="nofollow">Modeling Form for On-line Following of Musical Performances</a>. AAAI-05 Proc., July 2005.</span>\n</li>\n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Satish L, Gururaj BI (April 2003). "<a class="external text" href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=212242" rel="nofollow">Use of hidden Markov models for partial discharge pattern classification</a>". <i>IEEE Transactions on Dielectrics and Electrical Insulation</i>.</span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFLiStephens2003">Li, N; Stephens, M (December 2003). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC1462870" rel="nofollow">"Modeling linkage disequilibrium and identifying recombination hotspots using single-nucleotide polymorphism data"</a>. <i>Genetics</i>. <b>165</b> (4): 2213\xe2\x80\x9333. <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC1462870" rel="nofollow">1462870</a></span>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/14704198" rel="nofollow">14704198</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Genetics&amp;rft.atitle=Modeling+linkage+disequilibrium+and+identifying+recombination+hotspots+using+single-nucleotide+polymorphism+data.&amp;rft.volume=165&amp;rft.issue=4&amp;rft.pages=2213-33&amp;rft.date=2003-12&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1462870&amp;rft_id=info%3Apmid%2F14704198&amp;rft.aulast=Li&amp;rft.aufirst=N&amp;rft.au=Stephens%2C+M&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1462870&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><style data-mw-deduplicate="TemplateStyles:r982806391">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFLawrence_R._Rabiner1989"><a href="/wiki/Lawrence_Rabiner" title="Lawrence Rabiner">Lawrence R. Rabiner</a> (February 1989). <a class="external text" href="http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf" rel="nofollow">"A tutorial on Hidden Markov Models and selected applications in speech recognition"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the IEEE</i>. <b>77</b> (2): 257\xe2\x80\x93286. <a class="mw-redirect" href="/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.381.3454" rel="nofollow">10.1.1.381.3454</a></span>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2F5.18626" rel="nofollow">10.1109/5.18626</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE&amp;rft.atitle=A+tutorial+on+Hidden+Markov+Models+and+selected+applications+in+speech+recognition&amp;rft.volume=77&amp;rft.issue=2&amp;rft.pages=257-286&amp;rft.date=1989-02&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.381.3454&amp;rft_id=info%3Adoi%2F10.1109%2F5.18626&amp;rft.au=Lawrence+R.+Rabiner&amp;rft_id=http%3A%2F%2Fwww.ece.ucsb.edu%2FFaculty%2FRabiner%2Fece259%2FReprints%2Ftutorial%2520on%2520hmm%2520and%2520applications.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> <a class="external autonumber" href="http://www.cs.cornell.edu/courses/cs481/2004fa/rabiner.pdf" rel="nofollow">[1]</a></span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFNewberg2009">Newberg, L. (2009). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2722652" rel="nofollow">"Error statistics of hidden Markov model and hidden Boltzmann model results"</a>. <i>BMC Bioinformatics</i>. <b>10</b>: 212. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1186%2F1471-2105-10-212" rel="nofollow">10.1186/1471-2105-10-212</a>. <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2722652" rel="nofollow">2722652</a></span>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/19589158" rel="nofollow">19589158</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=BMC+Bioinformatics&amp;rft.atitle=Error+statistics+of+hidden+Markov+model+and+hidden+Boltzmann+model+results&amp;rft.volume=10&amp;rft.pages=212&amp;rft.date=2009&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2722652&amp;rft_id=info%3Apmid%2F19589158&amp;rft_id=info%3Adoi%2F10.1186%2F1471-2105-10-212&amp;rft.aulast=Newberg&amp;rft.aufirst=L.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2722652&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> <span style="position:relative; top: -2px;"><a href="/wiki/Open_access" title="open access publication \xe2\x80\x93 free to read"><img alt="open access" data-file-height="1000" data-file-width="640" decoding="async" height="14" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/77/Open_Access_logo_PLoS_transparent.svg/9px-Open_Access_logo_PLoS_transparent.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/77/Open_Access_logo_PLoS_transparent.svg/14px-Open_Access_logo_PLoS_transparent.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/77/Open_Access_logo_PLoS_transparent.svg/18px-Open_Access_logo_PLoS_transparent.svg.png 2x" width="9"/></a></span></span>\n</li>\n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Sipos, I. R\xc3\xb3bert. <i>Parallel stratified MCMC sampling of AR-HMMs for stochastic time series prediction</i>. In: Proceedings, 4th Stochastic Modeling Techniques and Data Analysis International Conference with Demographics Workshop (SMTDA2016), pp. 295-306. Valletta, 2016. <a class="external text" href="http://1drv.ms/b/s!ApL_0Av0YGDLglwEOv1aYAGbmQeL" rel="nofollow">PDF</a></span>\n</li>\n<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFChatzisKosmopoulos2011">Chatzis, Sotirios P.; Kosmopoulos, Dimitrios I. (2011). <a class="external text" href="http://users.iit.demokritos.gr/~dkosmo/downloads/patrec10/vbb10.pdf" rel="nofollow">"A variational Bayesian methodology for hidden Markov models utilizing Student\'s-t mixtures"</a> <span class="cs1-format">(PDF)</span>. <i>Pattern Recognition</i>. <b>44</b> (2): 295\xe2\x80\x93306. <a class="mw-redirect" href="/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.629.6275" rel="nofollow">10.1.1.629.6275</a></span>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.patcog.2010.09.001" rel="nofollow">10.1016/j.patcog.2010.09.001</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=A+variational+Bayesian+methodology+for+hidden+Markov+models+utilizing+Student%27s-t+mixtures&amp;rft.volume=44&amp;rft.issue=2&amp;rft.pages=295-306&amp;rft.date=2011&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.629.6275&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patcog.2010.09.001&amp;rft.aulast=Chatzis&amp;rft.aufirst=Sotirios+P.&amp;rft.au=Kosmopoulos%2C+Dimitrios+I.&amp;rft_id=http%3A%2F%2Fusers.iit.demokritos.gr%2F~dkosmo%2Fdownloads%2Fpatrec10%2Fvbb10.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFSiposCefferLevendovszky2016">Sipos, I. R\xc3\xb3bert; Ceffer, Attila; Levendovszky, J\xc3\xa1nos (2016). "Parallel Optimization of Sparse Portfolios with AR-HMMs". <i>Computational Economics</i>. <b>49</b> (4): 563\xe2\x80\x93578. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs10614-016-9579-y" rel="nofollow">10.1007/s10614-016-9579-y</a>. <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>\xc2\xa0<a class="external text" href="https://api.semanticscholar.org/CorpusID:61882456" rel="nofollow">61882456</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Economics&amp;rft.atitle=Parallel+Optimization+of+Sparse+Portfolios+with+AR-HMMs&amp;rft.volume=49&amp;rft.issue=4&amp;rft.pages=563-578&amp;rft.date=2016&amp;rft_id=info%3Adoi%2F10.1007%2Fs10614-016-9579-y&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A61882456&amp;rft.aulast=Sipos&amp;rft.aufirst=I.+R%C3%B3bert&amp;rft.au=Ceffer%2C+Attila&amp;rft.au=Levendovszky%2C+J%C3%A1nos&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFPetropoulosChatzisXanthopoulos2016">Petropoulos, Anastasios; Chatzis, Sotirios P.; Xanthopoulos, Stylianos (2016). "A novel corporate credit rating system based on Student\'s-t hidden Markov models". <i>Expert Systems with Applications</i>. <b>53</b>: 87\xe2\x80\x93105. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.eswa.2016.01.015" rel="nofollow">10.1016/j.eswa.2016.01.015</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Expert+Systems+with+Applications&amp;rft.atitle=A+novel+corporate+credit+rating+system+based+on+Student%27s-t+hidden+Markov+models&amp;rft.volume=53&amp;rft.pages=87-105&amp;rft.date=2016&amp;rft_id=info%3Adoi%2F10.1016%2Fj.eswa.2016.01.015&amp;rft.aulast=Petropoulos&amp;rft.aufirst=Anastasios&amp;rft.au=Chatzis%2C+Sotirios+P.&amp;rft.au=Xanthopoulos%2C+Stylianos&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFNICOLAI2013">NICOLAI, CHRISTOPHER (2013). "SOLVING ION CHANNEL KINETICS WITH THE QuB SOFTWARE". <i>Biophysical Reviews and Letters</i>. <b>8</b> (3n04): 191\xe2\x80\x93211. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1142%2FS1793048013300053" rel="nofollow">10.1142/S1793048013300053</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Biophysical+Reviews+and+Letters&amp;rft.atitle=SOLVING+ION+CHANNEL+KINETICS+WITH+THE+QuB+SOFTWARE&amp;rft.volume=8&amp;rft.issue=3n04&amp;rft.pages=191-211&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1142%2FS1793048013300053&amp;rft.aulast=NICOLAI&amp;rft.aufirst=CHRISTOPHER&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFDomingos2015">Domingos, Pedro (2015). <span class="cs1-lock-registration" title="Free registration required"><a class="external text" href="https://archive.org/details/masteralgorithmh0000domi" rel="nofollow"><i>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</i></a></span>. Basic Books. p.\xc2\xa0<a class="external text" href="https://archive.org/details/masteralgorithmh0000domi/page/37" rel="nofollow">37</a>. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/9780465061921" title="Special:BookSources/9780465061921"><bdi>9780465061921</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Master+Algorithm%3A+How+the+Quest+for+the+Ultimate+Learning+Machine+Will+Remake+Our+World&amp;rft.pages=37&amp;rft.pub=Basic+Books&amp;rft.date=2015&amp;rft.isbn=9780465061921&amp;rft.aulast=Domingos&amp;rft.aufirst=Pedro&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fmasteralgorithmh0000domi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFStiglerZieglerGiesekeGebhardt2011">Stigler, J.; Ziegler, F.; Gieseke, A.; Gebhardt, J. C. M.; Rief, M. (2011). "The Complex Folding Network of Single Calmodulin Molecules". <i><a href="/wiki/Science_(journal)" title="Science (journal)">Science</a></i>. <b>334</b> (6055): 512\xe2\x80\x93516. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2011Sci...334..512S" rel="nofollow">2011Sci...334..512S</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1126%2Fscience.1207598" rel="nofollow">10.1126/science.1207598</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/22034433" rel="nofollow">22034433</a>. <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>\xc2\xa0<a class="external text" href="https://api.semanticscholar.org/CorpusID:5502662" rel="nofollow">5502662</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Science&amp;rft.atitle=The+Complex+Folding+Network+of+Single+Calmodulin+Molecules&amp;rft.volume=334&amp;rft.issue=6055&amp;rft.pages=512-516&amp;rft.date=2011&amp;rft_id=info%3Adoi%2F10.1126%2Fscience.1207598&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A5502662&amp;rft_id=info%3Apmid%2F22034433&amp;rft_id=info%3Abibcode%2F2011Sci...334..512S&amp;rft.aulast=Stigler&amp;rft.aufirst=J.&amp;rft.au=Ziegler%2C+F.&amp;rft.au=Gieseke%2C+A.&amp;rft.au=Gebhardt%2C+J.+C.+M.&amp;rft.au=Rief%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBlasiakRangwala2011">Blasiak, S.; Rangwala, H. (2011). "A Hidden Markov Model Variant for Sequence Classification". <i>IJCAI Proceedings-International Joint Conference on Artificial Intelligence</i>. <b>22</b>: 1192.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IJCAI+Proceedings-International+Joint+Conference+on+Artificial+Intelligence&amp;rft.atitle=A+Hidden+Markov+Model+Variant+for+Sequence+Classification&amp;rft.volume=22&amp;rft.pages=1192&amp;rft.date=2011&amp;rft.aulast=Blasiak&amp;rft.aufirst=S.&amp;rft.au=Rangwala%2C+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFWongStamp2006">Wong, W.; Stamp, M. (2006). "Hunting for metamorphic engines". <i>Journal in Computer Virology</i>. <b>2</b> (3): 211\xe2\x80\x93229. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs11416-006-0028-7" rel="nofollow">10.1007/s11416-006-0028-7</a>. <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>\xc2\xa0<a class="external text" href="https://api.semanticscholar.org/CorpusID:8116065" rel="nofollow">8116065</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+in+Computer+Virology&amp;rft.atitle=Hunting+for+metamorphic+engines&amp;rft.volume=2&amp;rft.issue=3&amp;rft.pages=211-229&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1007%2Fs11416-006-0028-7&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8116065&amp;rft.aulast=Wong&amp;rft.aufirst=W.&amp;rft.au=Stamp%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFWongChanPengLi2013">Wong, K. -C.; Chan, T. -M.; Peng, C.; Li, Y.; Zhang, Z. (2013). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC3763557" rel="nofollow">"DNA motif elucidation using belief propagation"</a>. <i>Nucleic Acids Research</i>. <b>41</b> (16): e153. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fnar%2Fgkt574" rel="nofollow">10.1093/nar/gkt574</a>. <a class="mw-redirect" href="/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>\xc2\xa0<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC3763557" rel="nofollow">3763557</a></span>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/23814189" rel="nofollow">23814189</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nucleic+Acids+Research&amp;rft.atitle=DNA+motif+elucidation+using+belief+propagation&amp;rft.volume=41&amp;rft.issue=16&amp;rft.pages=e153&amp;rft.date=2013&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3763557&amp;rft_id=info%3Apmid%2F23814189&amp;rft_id=info%3Adoi%2F10.1093%2Fnar%2Fgkt574&amp;rft.aulast=Wong&amp;rft.aufirst=K.+-C.&amp;rft.au=Chan%2C+T.+-M.&amp;rft.au=Peng%2C+C.&amp;rft.au=Li%2C+Y.&amp;rft.au=Zhang%2C+Z.&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3763557&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFShahDubeyReif2019">Shah, Shalin; Dubey, Abhishek K.; Reif, John (2019-05-17). "Improved Optical Multiplexing with Temporal DNA Barcodes". <i>ACS Synthetic Biology</i>. <b>8</b> (5): 1100\xe2\x80\x931111. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1021%2Facssynbio.9b00010" rel="nofollow">10.1021/acssynbio.9b00010</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/30951289" rel="nofollow">30951289</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACS+Synthetic+Biology&amp;rft.atitle=Improved+Optical+Multiplexing+with+Temporal+DNA+Barcodes&amp;rft.volume=8&amp;rft.issue=5&amp;rft.pages=1100-1111&amp;rft.date=2019-05-17&amp;rft_id=info%3Adoi%2F10.1021%2Facssynbio.9b00010&amp;rft_id=info%3Apmid%2F30951289&amp;rft.aulast=Shah&amp;rft.aufirst=Shalin&amp;rft.au=Dubey%2C+Abhishek+K.&amp;rft.au=Reif%2C+John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFShahDubeyReif2019">Shah, Shalin; Dubey, Abhishek K.; Reif, John (2019-04-10). "Programming Temporal DNA Barcodes for Single-Molecule Fingerprinting". <i>Nano Letters</i>. <b>19</b> (4): 2668\xe2\x80\x932673. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1021%2Facs.nanolett.9b00590" rel="nofollow">10.1021/acs.nanolett.9b00590</a>. <a class="mw-redirect" href="/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/issn/1530-6984" rel="nofollow">1530-6984</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/30896178" rel="nofollow">30896178</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nano+Letters&amp;rft.atitle=Programming+Temporal+DNA+Barcodes+for+Single-Molecule+Fingerprinting&amp;rft.volume=19&amp;rft.issue=4&amp;rft.pages=2668-2673&amp;rft.date=2019-04-10&amp;rft.issn=1530-6984&amp;rft_id=info%3Apmid%2F30896178&amp;rft_id=info%3Adoi%2F10.1021%2Facs.nanolett.9b00590&amp;rft.aulast=Shah&amp;rft.aufirst=Shalin&amp;rft.au=Dubey%2C+Abhishek+K.&amp;rft.au=Reif%2C+John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a class="external text" href="http://compbio.mit.edu/ChromHMM/" rel="nofollow">"ChromHMM: Chromatin state discovery and characterization"</a>. <i>compbio.mit.edu</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2018-08-01</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=compbio.mit.edu&amp;rft.atitle=ChromHMM%3A+Chromatin+state+discovery+and+characterization&amp;rft_id=http%3A%2F%2Fcompbio.mit.edu%2FChromHMM%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><cite class="citation arxiv cs1" id="CITEREFEl_Zarwi2011">El Zarwi, Feraz (May 2011). "Modeling and Forecasting the Evolution of Preferences over Time: A Hidden Markov Model of Travel Behavior". <a class="mw-redirect" href="/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1707.09133" rel="nofollow">1707.09133</a></span> [<a class="external text" href="//arxiv.org/archive/stat.AP" rel="nofollow">stat.AP</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Modeling+and+Forecasting+the+Evolution+of+Preferences+over+Time%3A+A+Hidden+Markov+Model+of+Travel+Behavior&amp;rft.date=2011-05&amp;rft_id=info%3Aarxiv%2F1707.09133&amp;rft.aulast=El+Zarwi&amp;rft.aufirst=Feraz&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFMorf1998">Morf, H. (Feb 1998). "The stochastic two-state solar irradiance model (STSIM)". <i>Solar Energy</i>. <b>62</b> (2): 101\xe2\x80\x93112. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/1998SoEn...62..101M" rel="nofollow">1998SoEn...62..101M</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2FS0038-092X%2898%2900004-8" rel="nofollow">10.1016/S0038-092X(98)00004-8</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Solar+Energy&amp;rft.atitle=The+stochastic+two-state+solar+irradiance+model+%28STSIM%29&amp;rft.volume=62&amp;rft.issue=2&amp;rft.pages=101-112&amp;rft.date=1998-02&amp;rft_id=info%3Adoi%2F10.1016%2FS0038-092X%2898%2900004-8&amp;rft_id=info%3Abibcode%2F1998SoEn...62..101M&amp;rft.aulast=Morf&amp;rft.aufirst=H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFMunkhammarWid\xc3\xa9n2018">Munkhammar, J.; Wid\xc3\xa9n, J. (Aug 2018). "A Markov-chain probability distribution mixture approach to the clear-sky index". <i>Solar Energy</i>. <b>170</b>: 174\xe2\x80\x93183. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018SoEn..170..174M" rel="nofollow">2018SoEn..170..174M</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.solener.2018.05.055" rel="nofollow">10.1016/j.solener.2018.05.055</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Solar+Energy&amp;rft.atitle=A+Markov-chain+probability+distribution+mixture+approach+to+the+clear-sky+index&amp;rft.volume=170&amp;rft.pages=174-183&amp;rft.date=2018-08&amp;rft_id=info%3Adoi%2F10.1016%2Fj.solener.2018.05.055&amp;rft_id=info%3Abibcode%2F2018SoEn..170..174M&amp;rft.aulast=Munkhammar&amp;rft.aufirst=J.&amp;rft.au=Wid%C3%A9n%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFMunkhammarWid\xc3\xa9n2018">Munkhammar, J.; Wid\xc3\xa9n, J. (Oct 2018). "An N-state Markov-chain mixture distribution model of the clear-sky index". <i>Solar Energy</i>. <b>173</b>: 487\xe2\x80\x93495. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018SoEn..173..487M" rel="nofollow">2018SoEn..173..487M</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.solener.2018.07.056" rel="nofollow">10.1016/j.solener.2018.07.056</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Solar+Energy&amp;rft.atitle=An+N-state+Markov-chain+mixture+distribution+model+of+the+clear-sky+index&amp;rft.volume=173&amp;rft.pages=487-495&amp;rft.date=2018-10&amp;rft_id=info%3Adoi%2F10.1016%2Fj.solener.2018.07.056&amp;rft_id=info%3Abibcode%2F2018SoEn..173..487M&amp;rft.aulast=Munkhammar&amp;rft.aufirst=J.&amp;rft.au=Wid%C3%A9n%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-Stratonovich1960-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-Stratonovich1960_24-0">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFStratonovich,_R.L.1960">Stratonovich, R.L. (1960). "Conditional Markov Processes". <i>Theory of Probability and Its Applications</i>. <b>5</b> (2): 156\xe2\x80\x93178. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1137%2F1105015" rel="nofollow">10.1137/1105015</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Theory+of+Probability+and+Its+Applications&amp;rft.atitle=Conditional+Markov+Processes&amp;rft.volume=5&amp;rft.issue=2&amp;rft.pages=156-178&amp;rft.date=1960&amp;rft_id=info%3Adoi%2F10.1137%2F1105015&amp;rft.au=Stratonovich%2C+R.L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaumPetrie,_T.1966">Baum, L. E.; Petrie, T. (1966). <a class="external text" href="http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?handle=euclid.aoms/1177699147&amp;view=body&amp;content-type=pdf_1" rel="nofollow">"Statistical Inference for Probabilistic Functions of Finite State Markov Chains"</a>. <i>The Annals of Mathematical Statistics</i>. <b>37</b> (6): 1554\xe2\x80\x931563. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1214%2Faoms%2F1177699147" rel="nofollow">10.1214/aoms/1177699147</a></span><span class="reference-accessdate">. Retrieved <span class="nowrap">28 November</span> 2011</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Annals+of+Mathematical+Statistics&amp;rft.atitle=Statistical+Inference+for+Probabilistic+Functions+of+Finite+State+Markov+Chains&amp;rft.volume=37&amp;rft.issue=6&amp;rft.pages=1554-1563&amp;rft.date=1966&amp;rft_id=info%3Adoi%2F10.1214%2Faoms%2F1177699147&amp;rft.aulast=Baum&amp;rft.aufirst=L.+E.&amp;rft.au=Petrie%2C+T.&amp;rft_id=http%3A%2F%2Fprojecteuclid.org%2FDPubS%2FRepository%2F1.0%2FDisseminate%3Fhandle%3Deuclid.aoms%2F1177699147%26view%3Dbody%26content-type%3Dpdf_1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaumEagon1967">Baum, L. E.; Eagon, J. A. (1967). <a class="external text" href="http://projecteuclid.org/euclid.bams/1183528841" rel="nofollow">"An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"</a>. <i><a href="/wiki/Bulletin_of_the_American_Mathematical_Society" title="Bulletin of the American Mathematical Society">Bulletin of the American Mathematical Society</a></i>. <b>73</b> (3): 360. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1090%2FS0002-9904-1967-11751-8" rel="nofollow">10.1090/S0002-9904-1967-11751-8</a></span>. <a class="mw-redirect" href="/wiki/Zbl_(identifier)" title="Zbl (identifier)">Zbl</a>\xc2\xa0<a class="external text" href="//zbmath.org/?format=complete&amp;q=an:0157.11101" rel="nofollow">0157.11101</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bulletin+of+the+American+Mathematical+Society&amp;rft.atitle=An+inequality+with+applications+to+statistical+estimation+for+probabilistic+functions+of+Markov+processes+and+to+a+model+for+ecology&amp;rft.volume=73&amp;rft.issue=3&amp;rft.pages=360&amp;rft.date=1967&amp;rft_id=%2F%2Fzbmath.org%2F%3Fformat%3Dcomplete%26q%3Dan%3A0157.11101&amp;rft_id=info%3Adoi%2F10.1090%2FS0002-9904-1967-11751-8&amp;rft.aulast=Baum&amp;rft.aufirst=L.+E.&amp;rft.au=Eagon%2C+J.+A.&amp;rft_id=http%3A%2F%2Fprojecteuclid.org%2Feuclid.bams%2F1183528841&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaumSell,_G._R.1968">Baum, L. E.; Sell, G. R. (1968). <a class="external text" href="https://www.scribd.com/doc/6369908/Growth-Functions-for-Transformations-on-Manifolds" rel="nofollow">"Growth transformations for functions on manifolds"</a>. <i>Pacific Journal of Mathematics</i>. <b>27</b> (2): 211\xe2\x80\x93227. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.2140%2Fpjm.1968.27.211" rel="nofollow">10.2140/pjm.1968.27.211</a></span><span class="reference-accessdate">. Retrieved <span class="nowrap">28 November</span> 2011</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pacific+Journal+of+Mathematics&amp;rft.atitle=Growth+transformations+for+functions+on+manifolds&amp;rft.volume=27&amp;rft.issue=2&amp;rft.pages=211-227&amp;rft.date=1968&amp;rft_id=info%3Adoi%2F10.2140%2Fpjm.1968.27.211&amp;rft.aulast=Baum&amp;rft.aufirst=L.+E.&amp;rft.au=Sell%2C+G.+R.&amp;rft_id=https%3A%2F%2Fwww.scribd.com%2Fdoc%2F6369908%2FGrowth-Functions-for-Transformations-on-Manifolds&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaumPetrieSoulesWeiss1970"><a href="/wiki/Leonard_E._Baum" title="Leonard E. Baum">Baum, L. E.</a>; Petrie, T.; Soules, G.; Weiss, N. (1970). <a class="external text" href="https://doi.org/10.1214%2Faoms%2F1177697196" rel="nofollow">"A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"</a>. <i><a class="mw-redirect" href="/wiki/The_Annals_of_Mathematical_Statistics" title="The Annals of Mathematical Statistics">The Annals of Mathematical Statistics</a></i>. <b>41</b> (1): 164\xe2\x80\x93171. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1214%2Faoms%2F1177697196" rel="nofollow">10.1214/aoms/1177697196</a></span>. <a class="mw-redirect" href="/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>\xc2\xa0<a class="external text" href="//www.jstor.org/stable/2239727" rel="nofollow">2239727</a>. <a class="mw-redirect" href="/wiki/MR_(identifier)" title="MR (identifier)">MR</a>\xc2\xa0<a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0287613" rel="nofollow">0287613</a>. <a class="mw-redirect" href="/wiki/Zbl_(identifier)" title="Zbl (identifier)">Zbl</a>\xc2\xa0<a class="external text" href="//zbmath.org/?format=complete&amp;q=an:0188.49603" rel="nofollow">0188.49603</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Annals+of+Mathematical+Statistics&amp;rft.atitle=A+Maximization+Technique+Occurring+in+the+Statistical+Analysis+of+Probabilistic+Functions+of+Markov+Chains&amp;rft.volume=41&amp;rft.issue=1&amp;rft.pages=164-171&amp;rft.date=1970&amp;rft_id=%2F%2Fzbmath.org%2F%3Fformat%3Dcomplete%26q%3Dan%3A0188.49603&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D287613&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2239727&amp;rft_id=info%3Adoi%2F10.1214%2Faoms%2F1177697196&amp;rft.aulast=Baum&amp;rft.aufirst=L.+E.&amp;rft.au=Petrie%2C+T.&amp;rft.au=Soules%2C+G.&amp;rft.au=Weiss%2C+N.&amp;rft_id=%2F%2Fdoi.org%2F10.1214%252Faoms%252F1177697196&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaum1972">Baum, L.E. (1972). "An Inequality and Associated Maximization Technique in Statistical Estimation of Probabilistic Functions of a Markov Process". <i>Inequalities</i>. <b>3</b>: 1\xe2\x80\x938.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Inequalities&amp;rft.atitle=An+Inequality+and+Associated+Maximization+Technique+in+Statistical+Estimation+of+Probabilistic+Functions+of+a+Markov+Process&amp;rft.volume=3&amp;rft.pages=1-8&amp;rft.date=1972&amp;rft.aulast=Baum&amp;rft.aufirst=L.E.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFBaker1975"><a href="/wiki/James_K._Baker" title="James K. Baker">Baker, J.</a> (1975). "The DRAGON system\xe2\x80\x94An overview". <i>IEEE Transactions on Acoustics, Speech, and Signal Processing</i>. <b>23</b>: 24\xe2\x80\x9329. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTASSP.1975.1162650" rel="nofollow">10.1109/TASSP.1975.1162650</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Acoustics%2C+Speech%2C+and+Signal+Processing&amp;rft.atitle=The+DRAGON+system%E2%80%94An+overview&amp;rft.volume=23&amp;rft.pages=24-29&amp;rft.date=1975&amp;rft_id=info%3Adoi%2F10.1109%2FTASSP.1975.1162650&amp;rft.aulast=Baker&amp;rft.aufirst=J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFJelinekBahlMercer1975">Jelinek, F.; Bahl, L.; Mercer, R. (1975). "Design of a linguistic statistical decoder for the recognition of continuous speech". <i><a href="/wiki/IEEE_Transactions_on_Information_Theory" title="IEEE Transactions on Information Theory">IEEE Transactions on Information Theory</a></i>. <b>21</b> (3): 250. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTIT.1975.1055384" rel="nofollow">10.1109/TIT.1975.1055384</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Information+Theory&amp;rft.atitle=Design+of+a+linguistic+statistical+decoder+for+the+recognition+of+continuous+speech&amp;rft.volume=21&amp;rft.issue=3&amp;rft.pages=250&amp;rft.date=1975&amp;rft_id=info%3Adoi%2F10.1109%2FTIT.1975.1055384&amp;rft.aulast=Jelinek&amp;rft.aufirst=F.&amp;rft.au=Bahl%2C+L.&amp;rft.au=Mercer%2C+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFXuedong_HuangM._JackY._Ariki1990"><a href="/wiki/Xuedong_Huang" title="Xuedong Huang">Xuedong Huang</a>; M. Jack; Y. Ariki (1990). <i>Hidden Markov Models for Speech Recognition</i>. Edinburgh University Press. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-7486-0162-2" title="Special:BookSources/978-0-7486-0162-2"><bdi>978-0-7486-0162-2</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Hidden+Markov+Models+for+Speech+Recognition&amp;rft.pub=Edinburgh+University+Press&amp;rft.date=1990&amp;rft.isbn=978-0-7486-0162-2&amp;rft.au=Xuedong+Huang&amp;rft.au=M.+Jack&amp;rft.au=Y.+Ariki&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFXuedong_HuangAlex_AceroHsiao-Wuen_Hon2001"><a href="/wiki/Xuedong_Huang" title="Xuedong Huang">Xuedong Huang</a>; Alex Acero; Hsiao-Wuen Hon (2001). <i>Spoken Language Processing</i>. Prentice Hall. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-13-022616-7" title="Special:BookSources/978-0-13-022616-7"><bdi>978-0-13-022616-7</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Spoken+Language+Processing&amp;rft.pub=Prentice+Hall&amp;rft.date=2001&amp;rft.isbn=978-0-13-022616-7&amp;rft.au=Xuedong+Huang&amp;rft.au=Alex+Acero&amp;rft.au=Hsiao-Wuen+Hon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFM._Bishop_and_E._Thompson1986">M. Bishop and E. Thompson (1986). "Maximum Likelihood Alignment of DNA Sequences". <i><a href="/wiki/Journal_of_Molecular_Biology" title="Journal of Molecular Biology">Journal of Molecular Biology</a></i>. <b>190</b> (2): 159\xe2\x80\x93165. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2F0022-2836%2886%2990289-5" rel="nofollow">10.1016/0022-2836(86)90289-5</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/3641921" rel="nofollow">3641921</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Molecular+Biology&amp;rft.atitle=Maximum+Likelihood+Alignment+of+DNA+Sequences&amp;rft.volume=190&amp;rft.issue=2&amp;rft.pages=159-165&amp;rft.date=1986&amp;rft_id=info%3Adoi%2F10.1016%2F0022-2836%2886%2990289-5&amp;rft_id=info%3Apmid%2F3641921&amp;rft.au=M.+Bishop+and+E.+Thompson&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> <span style="font-size:0.95em; font-size:90%; color:#555">(subscription required)</span> <span style="position:relative; top: -2px;"><a href="/wiki/Paywall" title="closed access publication \xe2\x80\x93 behind paywall"><img alt="closed access" data-file-height="1000" data-file-width="640" decoding="async" height="14" src="//upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Closed_Access_logo_transparent.svg/9px-Closed_Access_logo_transparent.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Closed_Access_logo_transparent.svg/14px-Closed_Access_logo_transparent.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Closed_Access_logo_transparent.svg/18px-Closed_Access_logo_transparent.svg.png 2x" width="9"/></a></span></span>\n</li>\n<li id="cite_note-durbin-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-durbin_35-0">^</a></b></span> <span class="reference-text"><cite class="citation cs2" id="CITEREFDurbinEddyKroghMitchison1998"><a href="/wiki/Richard_M._Durbin" title="Richard M. Durbin">Durbin, Richard M.</a>; <a href="/wiki/Sean_Eddy" title="Sean Eddy">Eddy, Sean R.</a>; <a href="/wiki/Anders_Krogh" title="Anders Krogh">Krogh, Anders</a>; Mitchison, Graeme (1998), <a class="external text" href="http://www.cambridge.org/gb/knowledge/isbn/item1158701" rel="nofollow"><i>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids</i></a> (1st ed.), Cambridge, New York: <a href="/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>, <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.2277%2F0521629713" rel="nofollow">10.2277/0521629713</a>, <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/0-521-62971-3" title="Special:BookSources/0-521-62971-3"><bdi>0-521-62971-3</bdi></a>, <a class="mw-redirect" href="/wiki/OCLC_(identifier)" title="OCLC (identifier)">OCLC</a>\xc2\xa0<a class="external text" href="//www.worldcat.org/oclc/593254083" rel="nofollow">593254083</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Biological+Sequence+Analysis%3A+Probabilistic+Models+of+Proteins+and+Nucleic+Acids&amp;rft.place=Cambridge%2C+New+York&amp;rft.edition=1st&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1998&amp;rft_id=info%3Aoclcnum%2F593254083&amp;rft_id=info%3Adoi%2F10.2277%2F0521629713&amp;rft.isbn=0-521-62971-3&amp;rft.aulast=Durbin&amp;rft.aufirst=Richard+M.&amp;rft.au=Eddy%2C+Sean+R.&amp;rft.au=Krogh%2C+Anders&amp;rft.au=Mitchison%2C+Graeme&amp;rft_id=http%3A%2F%2Fwww.cambridge.org%2Fgb%2Fknowledge%2Fisbn%2Fitem1158701&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFGhahramaniJordan1997"><a href="/wiki/Zoubin_Ghahramani" title="Zoubin Ghahramani">Ghahramani, Zoubin</a>; <a href="/wiki/Michael_I._Jordan" title="Michael I. Jordan">Jordan, Michael I.</a> (1997). <a class="external text" href="https://doi.org/10.1023%2FA%3A1007425814087" rel="nofollow">"Factorial Hidden Markov Models"</a>. <i><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">Machine Learning</a></i>. <b>29</b> (2/3): 245\xe2\x80\x93273. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1023%2FA%3A1007425814087" rel="nofollow">10.1023/A:1007425814087</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Factorial+Hidden+Markov+Models&amp;rft.volume=29&amp;rft.issue=2%2F3&amp;rft.pages=245-273&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1007425814087&amp;rft.aulast=Ghahramani&amp;rft.aufirst=Zoubin&amp;rft.au=Jordan%2C+Michael+I.&amp;rft_id=%2F%2Fdoi.org%2F10.1023%252FA%253A1007425814087&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-TMM-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-TMM_37-0">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFPieczynski2002">Pieczynski, Wojciech (2002). "Cha\xc4\xb1\xcc\x82nes de Markov Triplet". <i>Comptes Rendus Math\xc3\xa9matique</i>. <b>335</b> (3): 275\xe2\x80\x93278. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2FS1631-073X%2802%2902462-7" rel="nofollow">10.1016/S1631-073X(02)02462-7</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comptes+Rendus+Math%C3%A9matique&amp;rft.atitle=Cha%C4%B1%CC%82nes+de+Markov+Triplet&amp;rft.volume=335&amp;rft.issue=3&amp;rft.pages=275-278&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1016%2FS1631-073X%2802%2902462-7&amp;rft.aulast=Pieczynski&amp;rft.aufirst=Wojciech&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-TMMEV-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-TMMEV_38-0">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFPieczynski2007">Pieczynski, Wojciech (2007). <a class="external text" href="https://doi.org/10.1016%2Fj.ijar.2006.05.001" rel="nofollow">"Multisensor triplet Markov chains and theory of evidence"</a>. <i>International Journal of Approximate Reasoning</i>. <b>45</b>: 1\xe2\x80\x9316. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1016%2Fj.ijar.2006.05.001" rel="nofollow">10.1016/j.ijar.2006.05.001</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Approximate+Reasoning&amp;rft.atitle=Multisensor+triplet+Markov+chains+and+theory+of+evidence&amp;rft.volume=45&amp;rft.pages=1-16&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1016%2Fj.ijar.2006.05.001&amp;rft.aulast=Pieczynski&amp;rft.aufirst=Wojciech&amp;rft_id=%2F%2Fdoi.org%2F10.1016%252Fj.ijar.2006.05.001&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-JASP-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-JASP_39-0">^</a></b></span> <span class="reference-text"><a class="external text" href="http://asp.eurasipjournals.com/content/pdf/1687-6180-2012-134.pdf" rel="nofollow">Boudaren et al.</a>, M. Y. Boudaren, E. Monfrini, W. Pieczynski, and A. Aissani, Dempster-Shafer fusion of multisensor signals in nonstationary Markovian context, EURASIP Journal on Advances in Signal Processing, No. 134, 2012.</span>\n</li>\n<li id="cite_note-TSP-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-TSP_40-0">^</a></b></span> <span class="reference-text"><a class="external text" href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=1468502&amp;contentType=Journals+%26+Magazines&amp;searchField%3DSearch_All%26queryText%3Dlanchantin+pieczynski" rel="nofollow">Lanchantin et al.</a>, P. Lanchantin and W. Pieczynski, Unsupervised restoration of hidden non stationary Markov chain using evidential priors, IEEE Transactions on Signal Processing, Vol. 53, No. 8, pp. 3091-3098, 2005.</span>\n</li>\n<li id="cite_note-SPL-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-SPL_41-0">^</a></b></span> <span class="reference-text"><a class="external text" href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=6244854&amp;contentType=Journals+%26+Magazines&amp;searchField%3DSearch_All%26queryText%3Dboudaren" rel="nofollow">Boudaren et al.</a>, M. Y. Boudaren, E. Monfrini, and W. Pieczynski, Unsupervised segmentation of random discrete data hidden with switching noise distributions, IEEE Signal Processing Letters, Vol. 19, No. 10, pp. 619-622, October 2012.</span>\n</li>\n<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text">Sotirios P. Chatzis, Dimitrios Kosmopoulos, "Visual Workflow Recognition Using a Variational Bayesian Treatment of Multistream Fused Hidden Markov Models," IEEE Transactions on Circuits and Systems for Video Technology, vol. 22, no. 7, pp. 1076-1086, July 2012. <a class="external autonumber" href="https://ieeexplore.ieee.org/document/6164251/" rel="nofollow">[2]</a></span>\n</li>\n<li id="cite_note-Reservoir-HMM-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-Reservoir-HMM_43-0">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFChatzisDemiris2012">Chatzis, Sotirios P.; Demiris, Yiannis (2012). "A Reservoir-Driven Non-Stationary Hidden Markov Model". <i>Pattern Recognition</i>. <b>45</b> (11): 3985\xe2\x80\x933996. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.patcog.2012.04.018" rel="nofollow">10.1016/j.patcog.2012.04.018</a>. <a class="mw-redirect" href="/wiki/Hdl_(identifier)" title="Hdl (identifier)">hdl</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//hdl.handle.net/10044%2F1%2F12611" rel="nofollow">10044/1/12611</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Recognition&amp;rft.atitle=A+Reservoir-Driven+Non-Stationary+Hidden+Markov+Model&amp;rft.volume=45&amp;rft.issue=11&amp;rft.pages=3985-3996&amp;rft.date=2012&amp;rft_id=info%3Ahdl%2F10044%2F1%2F12611&amp;rft_id=info%3Adoi%2F10.1016%2Fj.patcog.2012.04.018&amp;rft.aulast=Chatzis&amp;rft.aufirst=Sotirios+P.&amp;rft.au=Demiris%2C+Yiannis&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text">M. Lukosevicius, H. Jaeger (2009) Reservoir computing approaches to recurrent neural network training, Computer Science Review <b>3</b>: 127\xe2\x80\x93149.</span>\n</li>\n<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFWiggins1973">Wiggins, L. M. (1973). <i>Panel Analysis: Latent Probability Models for Attitude and Behaviour Processes</i>. Amsterdam: Elsevier.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Panel+Analysis%3A+Latent+Probability+Models+for+Attitude+and+Behaviour+Processes&amp;rft.place=Amsterdam&amp;rft.pub=Elsevier&amp;rft.date=1973&amp;rft.aulast=Wiggins&amp;rft.aufirst=L.+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFBartolucciFarcomeniPennoni2013">Bartolucci, F.; Farcomeni, A.; Pennoni, F. (2013). <a class="external text" href="https://sites.google.com/site/latentmarkovbook/home" rel="nofollow"><i>Latent Markov models for longitudinal data</i></a>. Boca Raton: Chapman and Hall/CRC. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-14-3981-708-7" title="Special:BookSources/978-14-3981-708-7"><bdi>978-14-3981-708-7</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Latent+Markov+models+for+longitudinal+data&amp;rft.place=Boca+Raton&amp;rft.pub=Chapman+and+Hall%2FCRC&amp;rft.date=2013&amp;rft.isbn=978-14-3981-708-7&amp;rft.aulast=Bartolucci&amp;rft.aufirst=F.&amp;rft.au=Farcomeni%2C+A.&amp;rft.au=Pennoni%2C+F.&amp;rft_id=https%3A%2F%2Fsites.google.com%2Fsite%2Flatentmarkovbook%2Fhome&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n</ol></div>\n<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=20" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<table class="mbox-small plainlinks sistersitebox" role="presentation" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">\n<tbody><tr>\n<td class="mbox-image"><img alt="" class="noviewer" data-file-height="1376" data-file-width="1024" decoding="async" height="40" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x" width="30"/></td>\n<td class="mbox-text plainlist">Wikimedia Commons has media related to <i><b><a class="extiw" href="https://commons.wikimedia.org/wiki/Category:Hidden_Markov_Model" title="commons:Category:Hidden Markov Model"><span style="">Hidden Markov Model</span></a></b></i>.</td></tr>\n</tbody></table>\n<h3><span class="mw-headline" id="Concepts">Concepts</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hidden_Markov_model&amp;action=edit&amp;section=21" title="Edit section: Concepts">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<ul><li><cite class="citation journal cs1" id="CITEREFTeifRippe2010">Teif, V. B.; Rippe, K. (2010). "Statistical\xe2\x80\x93mechanical lattice models for protein\xe2\x80\x93DNA binding in chromatin". <i>J. Phys.: Condens. Matter</i>. <b>22</b> (41): 414105. <a class="mw-redirect" href="/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1004.5514" rel="nofollow">1004.5514</a></span>. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2010JPCM...22O4105T" rel="nofollow">2010JPCM...22O4105T</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1088%2F0953-8984%2F22%2F41%2F414105" rel="nofollow">10.1088/0953-8984/22/41/414105</a>. <a class="mw-redirect" href="/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>\xc2\xa0<a class="external text" href="//pubmed.ncbi.nlm.nih.gov/21386588" rel="nofollow">21386588</a>. <a class="mw-redirect" href="/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>\xc2\xa0<a class="external text" href="https://api.semanticscholar.org/CorpusID:103345" rel="nofollow">103345</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J.+Phys.%3A+Condens.+Matter&amp;rft.atitle=Statistical%E2%80%93mechanical+lattice+models+for+protein%E2%80%93DNA+binding+in+chromatin&amp;rft.volume=22&amp;rft.issue=41&amp;rft.pages=414105&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A103345&amp;rft_id=info%3Abibcode%2F2010JPCM...22O4105T&amp;rft_id=info%3Aarxiv%2F1004.5514&amp;rft_id=info%3Apmid%2F21386588&amp;rft_id=info%3Adoi%2F10.1088%2F0953-8984%2F22%2F41%2F414105&amp;rft.aulast=Teif&amp;rft.aufirst=V.+B.&amp;rft.au=Rippe%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHidden+Markov+model"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></li>\n<li><a class="external text" href="http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf" rel="nofollow">A Revealing Introduction to Hidden Markov Models</a> by Mark Stamp, San Jose State University.</li>\n<li><a class="external text" href="https://web.archive.org/web/20120415032315/http://www.ee.washington.edu/research/guptalab/publications/EMbookChenGupta2010.pdf" rel="nofollow">Fitting HMM\'s with expectation-maximization \xe2\x80\x93 complete derivation</a></li>\n<li><a class="external text" href="http://www.comp.leeds.ac.uk/roger/HiddenMarkovModels/html_dev/main.html" rel="nofollow">A step-by-step tutorial on HMMs</a> <i>(University of Leeds)</i></li>\n<li><a class="external text" href="http://www.cs.brown.edu/research/ai/dynamics/tutorial/Documents/HiddenMarkovModels.html" rel="nofollow">Hidden Markov Models</a> <i>(an exposition using basic mathematics)</i></li>\n<li><a class="external text" href="http://jedlik.phy.bme.hu/~gerjanos/HMM/node2.html" rel="nofollow">Hidden Markov Models</a> <i>(by Narada Warakagoda)</i></li>\n<li>Hidden Markov Models: Fundamentals and Applications <a class="external text" href="http://www.eecis.udel.edu/~lliao/cis841s06/hmmtutorialpart1.pdf" rel="nofollow">Part 1</a>, <a class="external text" href="http://www.eecis.udel.edu/~lliao/cis841s06/hmmtutorialpart2.pdf" rel="nofollow">Part 2</a> <i>(by V. Petrushin)</i></li>\n<li>Lecture on a Spreadsheet by Jason Eisner, <a class="external text" href="http://videolectures.net/hltss2010_eisner_plm/video/2/" rel="nofollow">Video</a> and <a class="external text" href="http://www.cs.jhu.edu/~jason/papers/eisner.hmm.xls" rel="nofollow">interactive spreadsheet</a></li></ul>\n<div aria-labelledby="Stochastic_processes" class="navbox" role="navigation" style="padding:3px"><table class="nowraplinks mw-collapsible uncollapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th class="navbox-title" colspan="2" scope="col"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Stochastic_processes" title="Template:Stochastic processes"><abbr style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;" title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Stochastic_processes" title="Template talk:Stochastic processes"><abbr style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;" title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Stochastic_processes&amp;action=edit"><abbr style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;" title="Edit this template">e</abbr></a></li></ul></div><div id="Stochastic_processes" style="font-size:114%;margin:0 4em"><a href="/wiki/Stochastic_process" title="Stochastic process">Stochastic processes</a></div></th></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a class="mw-redirect" href="/wiki/Discrete-time_stochastic_process" title="Discrete-time stochastic process">Discrete time</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Bernoulli_process" title="Bernoulli process">Bernoulli process</a></li>\n<li><a href="/wiki/Branching_process" title="Branching process">Branching process</a></li>\n<li><a href="/wiki/Chinese_restaurant_process" title="Chinese restaurant process">Chinese restaurant process</a></li>\n<li><a href="/wiki/Galton%E2%80%93Watson_process" title="Galton\xe2\x80\x93Watson process">Galton\xe2\x80\x93Watson process</a></li>\n<li><a href="/wiki/Independent_and_identically_distributed_random_variables" title="Independent and identically distributed random variables">Independent and identically distributed random variables</a></li>\n<li><a href="/wiki/Markov_chain" title="Markov chain">Markov chain</a></li>\n<li><a href="/wiki/Moran_process" title="Moran process">Moran process</a></li>\n<li><a href="/wiki/Random_walk" title="Random walk">Random walk</a>\n<ul><li><a href="/wiki/Loop-erased_random_walk" title="Loop-erased random walk">Loop-erased</a></li>\n<li><a href="/wiki/Self-avoiding_walk" title="Self-avoiding walk">Self-avoiding</a></li>\n<li><a href="/wiki/Biased_random_walk_on_a_graph" title="Biased random walk on a graph"> Biased</a></li>\n<li><a class="mw-redirect" href="/wiki/Maximal_Entropy_Random_Walk" title="Maximal Entropy Random Walk">Maximal entropy</a></li></ul></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a href="/wiki/Continuous-time_stochastic_process" title="Continuous-time stochastic process">Continuous time</a></th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Additive_process" title="Additive process">Additive process</a></li>\n<li><a href="/wiki/Bessel_process" title="Bessel process">Bessel process</a></li>\n<li><a href="/wiki/Birth%E2%80%93death_process" title="Birth\xe2\x80\x93death process">Birth\xe2\x80\x93death process</a>\n<ul><li><a href="/wiki/Birth_process" title="Birth process">pure birth</a></li></ul></li>\n<li><a href="/wiki/Wiener_process" title="Wiener process">Brownian motion</a>\n<ul><li><a href="/wiki/Brownian_bridge" title="Brownian bridge">Bridge</a></li>\n<li><a href="/wiki/Brownian_excursion" title="Brownian excursion">Excursion</a></li>\n<li><a href="/wiki/Fractional_Brownian_motion" title="Fractional Brownian motion">Fractional</a></li>\n<li><a href="/wiki/Geometric_Brownian_motion" title="Geometric Brownian motion">Geometric</a></li>\n<li><a href="/wiki/Brownian_meander" title="Brownian meander">Meander</a></li></ul></li>\n<li><a href="/wiki/Cauchy_process" title="Cauchy process">Cauchy process</a></li>\n<li><a href="/wiki/Contact_process_(mathematics)" title="Contact process (mathematics)">Contact process</a></li>\n<li><a href="/wiki/Continuous-time_random_walk" title="Continuous-time random walk">Continuous-time random walk</a></li>\n<li><a href="/wiki/Cox_process" title="Cox process">Cox process</a></li>\n<li><a href="/wiki/Diffusion_process" title="Diffusion process">Diffusion process</a></li>\n<li><a href="/wiki/Empirical_process" title="Empirical process">Empirical process</a></li>\n<li><a href="/wiki/Feller_process" title="Feller process">Feller process</a></li>\n<li><a href="/wiki/Fleming%E2%80%93Viot_process" title="Fleming\xe2\x80\x93Viot process">Fleming\xe2\x80\x93Viot process</a></li>\n<li><a href="/wiki/Gamma_process" title="Gamma process">Gamma process</a></li>\n<li><a href="/wiki/Geometric_process" title="Geometric process">Geometric process</a></li>\n<li><a href="/wiki/Hunt_process" title="Hunt process">Hunt process</a></li>\n<li><a href="/wiki/Interacting_particle_system" title="Interacting particle system">Interacting particle systems</a></li>\n<li><a href="/wiki/It%C3%B4_diffusion" title="It\xc3\xb4 diffusion">It\xc3\xb4 diffusion</a></li>\n<li><a class="mw-redirect" href="/wiki/It%C3%B4_process" title="It\xc3\xb4 process">It\xc3\xb4 process</a></li>\n<li><a href="/wiki/Jump_diffusion" title="Jump diffusion">Jump diffusion</a></li>\n<li><a href="/wiki/Jump_process" title="Jump process">Jump process</a></li>\n<li><a href="/wiki/L%C3%A9vy_process" title="L\xc3\xa9vy process">L\xc3\xa9vy process</a></li>\n<li><a href="/wiki/Local_time_(mathematics)" title="Local time (mathematics)">Local time</a></li>\n<li><a href="/wiki/Markov_additive_process" title="Markov additive process">Markov additive process</a></li>\n<li><a href="/wiki/McKean%E2%80%93Vlasov_process" title="McKean\xe2\x80\x93Vlasov process">McKean\xe2\x80\x93Vlasov process</a></li>\n<li><a href="/wiki/Ornstein%E2%80%93Uhlenbeck_process" title="Ornstein\xe2\x80\x93Uhlenbeck process">Ornstein\xe2\x80\x93Uhlenbeck process</a></li>\n<li><a href="/wiki/Poisson_point_process" title="Poisson point process">Poisson process</a>\n<ul><li><a href="/wiki/Compound_Poisson_process" title="Compound Poisson process">Compound</a></li>\n<li><a class="mw-redirect" href="/wiki/Non-homogeneous_Poisson_process" title="Non-homogeneous Poisson process">Non-homogeneous</a></li></ul></li>\n<li><a href="/wiki/Schramm%E2%80%93Loewner_evolution" title="Schramm\xe2\x80\x93Loewner evolution">Schramm\xe2\x80\x93Loewner evolution</a></li>\n<li><a href="/wiki/Semimartingale" title="Semimartingale">Semimartingale</a></li>\n<li><a href="/wiki/Sigma-martingale" title="Sigma-martingale">Sigma-martingale</a></li>\n<li><a href="/wiki/Stable_process" title="Stable process">Stable process</a></li>\n<li><a href="/wiki/Superprocess" title="Superprocess">Superprocess</a></li>\n<li><a href="/wiki/Telegraph_process" title="Telegraph process">Telegraph process</a></li>\n<li><a href="/wiki/Variance_gamma_process" title="Variance gamma process">Variance gamma process</a></li>\n<li><a href="/wiki/Wiener_process" title="Wiener process">Wiener process</a></li>\n<li><a href="/wiki/Wiener_sausage" title="Wiener sausage">Wiener sausage</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Both</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Branching_process" title="Branching process">Branching process</a></li>\n<li><a href="/wiki/Galves%E2%80%93L%C3%B6cherbach_model" title="Galves\xe2\x80\x93L\xc3\xb6cherbach model">Galves\xe2\x80\x93L\xc3\xb6cherbach model</a></li>\n<li><a href="/wiki/Gaussian_process" title="Gaussian process">Gaussian process</a></li>\n<li><a class="mw-selflink selflink">Hidden Markov model (HMM)</a></li>\n<li><a class="mw-redirect" href="/wiki/Markov_process" title="Markov process">Markov process</a></li>\n<li><a href="/wiki/Martingale_(probability_theory)" title="Martingale (probability theory)">Martingale</a>\n<ul><li><a href="/wiki/Martingale_difference_sequence" title="Martingale difference sequence">Differences</a></li>\n<li><a href="/wiki/Local_martingale" title="Local martingale">Local</a></li>\n<li><a class="mw-redirect" href="/wiki/Submartingale" title="Submartingale">Sub-</a></li>\n<li><a class="mw-redirect" href="/wiki/Supermartingale" title="Supermartingale">Super-</a></li></ul></li>\n<li><a href="/wiki/Random_dynamical_system" title="Random dynamical system">Random dynamical system</a></li>\n<li><a href="/wiki/Regenerative_process" title="Regenerative process">Regenerative process</a></li>\n<li><a class="mw-redirect" href="/wiki/Renewal_process" title="Renewal process">Renewal process</a></li>\n<li><a href="/wiki/Stochastic_chains_with_memory_of_variable_length" title="Stochastic chains with memory of variable length">Stochastic chains with memory of variable length</a></li>\n<li><a href="/wiki/White_noise" title="White noise">White noise</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Fields and other</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Dirichlet_process" title="Dirichlet process">Dirichlet process</a></li>\n<li><a href="/wiki/Gaussian_random_field" title="Gaussian random field">Gaussian random field</a></li>\n<li><a href="/wiki/Gibbs_measure" title="Gibbs measure">Gibbs measure</a></li>\n<li><a class="mw-redirect" href="/wiki/Hopfield_model" title="Hopfield model">Hopfield model</a></li>\n<li><a href="/wiki/Ising_model" title="Ising model">Ising model</a>\n<ul><li><a href="/wiki/Potts_model" title="Potts model">Potts model</a></li>\n<li><a href="/wiki/Boolean_network" title="Boolean network">Boolean network</a></li></ul></li>\n<li><a href="/wiki/Markov_random_field" title="Markov random field">Markov random field</a></li>\n<li><a href="/wiki/Percolation_theory" title="Percolation theory">Percolation</a></li>\n<li><a href="/wiki/Pitman%E2%80%93Yor_process" title="Pitman\xe2\x80\x93Yor process">Pitman\xe2\x80\x93Yor process</a></li>\n<li><a href="/wiki/Point_process" title="Point process">Point process</a>\n<ul><li><a href="/wiki/Point_process#Cox_point_process" title="Point process">Cox</a></li>\n<li><a href="/wiki/Poisson_point_process" title="Poisson point process">Poisson</a></li></ul></li>\n<li><a href="/wiki/Random_field" title="Random field">Random field</a></li>\n<li><a href="/wiki/Random_graph" title="Random graph">Random graph</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a href="/wiki/Time_series" title="Time series">Time series models</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Autoregressive_conditional_heteroskedasticity" title="Autoregressive conditional heteroskedasticity">Autoregressive conditional heteroskedasticity (ARCH) model</a></li>\n<li><a href="/wiki/Autoregressive_integrated_moving_average" title="Autoregressive integrated moving average">Autoregressive integrated moving average (ARIMA) model</a></li>\n<li><a href="/wiki/Autoregressive_model" title="Autoregressive model">Autoregressive (AR) model</a></li>\n<li><a href="/wiki/Autoregressive%E2%80%93moving-average_model" title="Autoregressive\xe2\x80\x93moving-average model">Autoregressive\xe2\x80\x93moving-average (ARMA) model</a></li>\n<li><a href="/wiki/Autoregressive_conditional_heteroskedasticity" title="Autoregressive conditional heteroskedasticity">Generalized autoregressive conditional heteroskedasticity (GARCH) model</a></li>\n<li><a href="/wiki/Moving-average_model" title="Moving-average model">Moving-average (MA) model</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Financial models</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Black%E2%80%93Derman%E2%80%93Toy_model" title="Black\xe2\x80\x93Derman\xe2\x80\x93Toy model">Black\xe2\x80\x93Derman\xe2\x80\x93Toy</a></li>\n<li><a href="/wiki/Black%E2%80%93Karasinski_model" title="Black\xe2\x80\x93Karasinski model">Black\xe2\x80\x93Karasinski</a></li>\n<li><a href="/wiki/Black%E2%80%93Scholes_model" title="Black\xe2\x80\x93Scholes model">Black\xe2\x80\x93Scholes</a></li>\n<li><a href="/wiki/Chen_model" title="Chen model">Chen</a></li>\n<li><a href="/wiki/Constant_elasticity_of_variance_model" title="Constant elasticity of variance model">Constant elasticity of variance (CEV)</a></li>\n<li><a href="/wiki/Cox%E2%80%93Ingersoll%E2%80%93Ross_model" title="Cox\xe2\x80\x93Ingersoll\xe2\x80\x93Ross model">Cox\xe2\x80\x93Ingersoll\xe2\x80\x93Ross (CIR)</a></li>\n<li><a class="mw-redirect" href="/wiki/Garman%E2%80%93Kohlhagen_model" title="Garman\xe2\x80\x93Kohlhagen model">Garman\xe2\x80\x93Kohlhagen</a></li>\n<li><a href="/wiki/Heath%E2%80%93Jarrow%E2%80%93Morton_framework" title="Heath\xe2\x80\x93Jarrow\xe2\x80\x93Morton framework">Heath\xe2\x80\x93Jarrow\xe2\x80\x93Morton (HJM)</a></li>\n<li><a href="/wiki/Heston_model" title="Heston model">Heston</a></li>\n<li><a href="/wiki/Ho%E2%80%93Lee_model" title="Ho\xe2\x80\x93Lee model">Ho\xe2\x80\x93Lee</a></li>\n<li><a href="/wiki/Hull%E2%80%93White_model" title="Hull\xe2\x80\x93White model">Hull\xe2\x80\x93White</a></li>\n<li><a href="/wiki/LIBOR_market_model" title="LIBOR market model">LIBOR market</a></li>\n<li><a href="/wiki/Rendleman%E2%80%93Bartter_model" title="Rendleman\xe2\x80\x93Bartter model">Rendleman\xe2\x80\x93Bartter</a></li>\n<li><a href="/wiki/SABR_volatility_model" title="SABR volatility model">SABR volatility</a></li>\n<li><a href="/wiki/Vasicek_model" title="Vasicek model">Va\xc5\xa1\xc3\xad\xc4\x8dek</a></li>\n<li><a href="/wiki/Wilkie_investment_model" title="Wilkie investment model">Wilkie</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a class="mw-redirect" href="/wiki/Actuarial_mathematics" title="Actuarial mathematics">Actuarial models</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/B%C3%BChlmann_model" title="B\xc3\xbchlmann model">B\xc3\xbchlmann</a></li>\n<li><a class="mw-redirect" href="/wiki/Cram%C3%A9r%E2%80%93Lundberg_model" title="Cram\xc3\xa9r\xe2\x80\x93Lundberg model">Cram\xc3\xa9r\xe2\x80\x93Lundberg</a></li>\n<li><a class="mw-redirect" href="/wiki/Risk_process" title="Risk process">Risk process</a></li>\n<li><a class="mw-redirect" href="/wiki/Sparre%E2%80%93Anderson_model" title="Sparre\xe2\x80\x93Anderson model">Sparre\xe2\x80\x93Anderson</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a class="mw-redirect" href="/wiki/Queueing_model" title="Queueing model">Queueing models</a></th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Bulk_queue" title="Bulk queue">Bulk</a></li>\n<li><a href="/wiki/Fluid_queue" title="Fluid queue">Fluid</a></li>\n<li><a href="/wiki/G-network" title="G-network">Generalized queueing network</a></li>\n<li><a href="/wiki/M/G/1_queue" title="M/G/1 queue">M/G/1</a></li>\n<li><a href="/wiki/M/M/1_queue" title="M/M/1 queue">M/M/1</a></li>\n<li><a href="/wiki/M/M/c_queue" title="M/M/c queue">M/M/c</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Properties</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/C%C3%A0dl%C3%A0g" title="C\xc3\xa0dl\xc3\xa0g">C\xc3\xa0dl\xc3\xa0g paths</a></li>\n<li><a href="/wiki/Continuous_stochastic_process" title="Continuous stochastic process">Continuous</a></li>\n<li><a href="/wiki/Sample-continuous_process" title="Sample-continuous process">Continuous paths</a></li>\n<li><a href="/wiki/Ergodicity" title="Ergodicity">Ergodic</a></li>\n<li><a href="/wiki/Exchangeable_random_variables" title="Exchangeable random variables">Exchangeable</a></li>\n<li><a href="/wiki/Feller-continuous_process" title="Feller-continuous process">Feller-continuous</a></li>\n<li><a href="/wiki/Gauss%E2%80%93Markov_process" title="Gauss\xe2\x80\x93Markov process">Gauss\xe2\x80\x93Markov</a></li>\n<li><a href="/wiki/Markov_property" title="Markov property">Markov</a></li>\n<li><a href="/wiki/Mixing_(mathematics)" title="Mixing (mathematics)">Mixing</a></li>\n<li><a class="mw-redirect" href="/wiki/Piecewise_deterministic_Markov_process" title="Piecewise deterministic Markov process">Piecewise deterministic</a></li>\n<li><a href="/wiki/Predictable_process" title="Predictable process">Predictable</a></li>\n<li><a href="/wiki/Progressively_measurable_process" title="Progressively measurable process">Progressively measurable</a></li>\n<li><a href="/wiki/Self-similar_process" title="Self-similar process">Self-similar</a></li>\n<li><a href="/wiki/Stationary_process" title="Stationary process">Stationary</a></li>\n<li><a href="/wiki/Time_reversibility" title="Time reversibility">Time-reversible</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Limit theorems</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a href="/wiki/Central_limit_theorem" title="Central limit theorem">Central limit theorem</a></li>\n<li><a href="/wiki/Donsker%27s_theorem" title="Donsker\'s theorem">Donsker\'s theorem</a></li>\n<li><a href="/wiki/Doob%27s_martingale_convergence_theorems" title="Doob\'s martingale convergence theorems">Doob\'s martingale convergence theorems</a></li>\n<li><a class="mw-redirect" href="/wiki/Ergodic_theorem" title="Ergodic theorem">Ergodic theorem</a></li>\n<li><a href="/wiki/Fisher%E2%80%93Tippett%E2%80%93Gnedenko_theorem" title="Fisher\xe2\x80\x93Tippett\xe2\x80\x93Gnedenko theorem">Fisher\xe2\x80\x93Tippett\xe2\x80\x93Gnedenko theorem</a></li>\n<li><a class="mw-redirect" href="/wiki/Large_deviation_principle" title="Large deviation principle">Large deviation principle</a></li>\n<li><a href="/wiki/Law_of_large_numbers" title="Law of large numbers">Law of large numbers (weak/strong)</a></li>\n<li><a href="/wiki/Law_of_the_iterated_logarithm" title="Law of the iterated logarithm">Law of the iterated logarithm</a></li>\n<li><a href="/wiki/Maximal_ergodic_theorem" title="Maximal ergodic theorem">Maximal ergodic theorem</a></li>\n<li><a href="/wiki/Sanov%27s_theorem" title="Sanov\'s theorem">Sanov\'s theorem</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%"><a href="/wiki/List_of_inequalities#Probability_theory_and_statistics" title="List of inequalities">Inequalities</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a class="mw-redirect" href="/wiki/Burkholder%E2%80%93Davis%E2%80%93Gundy_inequalities" title="Burkholder\xe2\x80\x93Davis\xe2\x80\x93Gundy inequalities">Burkholder\xe2\x80\x93Davis\xe2\x80\x93Gundy</a></li>\n<li><a href="/wiki/Doob%27s_martingale_inequality" title="Doob\'s martingale inequality">Doob\'s martingale</a></li>\n<li><a href="/wiki/Kunita%E2%80%93Watanabe_inequality" title="Kunita\xe2\x80\x93Watanabe inequality">Kunita\xe2\x80\x93Watanabe</a></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Tools</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a class="mw-redirect" href="/wiki/Cameron%E2%80%93Martin_formula" title="Cameron\xe2\x80\x93Martin formula">Cameron\xe2\x80\x93Martin formula</a></li>\n<li><a href="/wiki/Convergence_of_random_variables" title="Convergence of random variables">Convergence of random variables</a></li>\n<li><a href="/wiki/Dol%C3%A9ans-Dade_exponential" title="Dol\xc3\xa9ans-Dade exponential">Dol\xc3\xa9ans-Dade exponential</a></li>\n<li><a href="/wiki/Doob_decomposition_theorem" title="Doob decomposition theorem">Doob decomposition theorem</a></li>\n<li><a href="/wiki/Doob%E2%80%93Meyer_decomposition_theorem" title="Doob\xe2\x80\x93Meyer decomposition theorem">Doob\xe2\x80\x93Meyer decomposition theorem</a></li>\n<li><a class="mw-redirect" href="/wiki/Doob%27s_optional_stopping_theorem" title="Doob\'s optional stopping theorem">Doob\'s optional stopping theorem</a></li>\n<li><a href="/wiki/Dynkin%27s_formula" title="Dynkin\'s formula">Dynkin\'s formula</a></li>\n<li><a href="/wiki/Feynman%E2%80%93Kac_formula" title="Feynman\xe2\x80\x93Kac formula">Feynman\xe2\x80\x93Kac formula</a></li>\n<li><a href="/wiki/Filtration_(probability_theory)" title="Filtration (probability theory)">Filtration</a></li>\n<li><a href="/wiki/Girsanov_theorem" title="Girsanov theorem">Girsanov theorem</a></li>\n<li><a href="/wiki/Infinitesimal_generator_(stochastic_processes)" title="Infinitesimal generator (stochastic processes)">Infinitesimal generator</a></li>\n<li><a class="mw-redirect" href="/wiki/It%C3%B4_integral" title="It\xc3\xb4 integral">It\xc3\xb4 integral</a></li>\n<li><a href="/wiki/It%C3%B4%27s_lemma" title="It\xc3\xb4\'s lemma">It\xc3\xb4\'s lemma</a></li>\n<li><a href="/wiki/Karhunen%E2%80%93Lo%C3%A8ve_theorem" title="Karhunen\xe2\x80\x93Lo\xc3\xa8ve theorem">Karhunen\xe2\x80\x93Lo\xc3\xa8ve_theorem</a></li>\n<li><a href="/wiki/Kolmogorov_continuity_theorem" title="Kolmogorov continuity theorem">Kolmogorov continuity theorem</a></li>\n<li><a href="/wiki/Kolmogorov_extension_theorem" title="Kolmogorov extension theorem">Kolmogorov extension theorem</a></li>\n<li><a href="/wiki/L%C3%A9vy%E2%80%93Prokhorov_metric" title="L\xc3\xa9vy\xe2\x80\x93Prokhorov metric">L\xc3\xa9vy\xe2\x80\x93Prokhorov metric</a></li>\n<li><a href="/wiki/Malliavin_calculus" title="Malliavin calculus">Malliavin calculus</a></li>\n<li><a href="/wiki/Martingale_representation_theorem" title="Martingale representation theorem">Martingale representation theorem</a></li>\n<li><a href="/wiki/Optional_stopping_theorem" title="Optional stopping theorem">Optional stopping theorem</a></li>\n<li><a href="/wiki/Prokhorov%27s_theorem" title="Prokhorov\'s theorem">Prokhorov\'s theorem</a></li>\n<li><a href="/wiki/Quadratic_variation" title="Quadratic variation">Quadratic variation</a></li>\n<li><a href="/wiki/Reflection_principle_(Wiener_process)" title="Reflection principle (Wiener process)">Reflection principle</a></li>\n<li><a href="/wiki/Skorokhod_integral" title="Skorokhod integral">Skorokhod integral</a></li>\n<li><a href="/wiki/Skorokhod%27s_representation_theorem" title="Skorokhod\'s representation theorem">Skorokhod\'s representation theorem</a></li>\n<li><a class="mw-redirect" href="/wiki/Skorokhod_space" title="Skorokhod space">Skorokhod space</a></li>\n<li><a href="/wiki/Snell_envelope" title="Snell envelope">Snell envelope</a></li>\n<li><a href="/wiki/Stochastic_differential_equation" title="Stochastic differential equation">Stochastic differential equation</a>\n<ul><li><a href="/wiki/Tanaka_equation" title="Tanaka equation">Tanaka</a></li></ul></li>\n<li><a href="/wiki/Stopping_time" title="Stopping time">Stopping time</a></li>\n<li><a href="/wiki/Stratonovich_integral" title="Stratonovich integral">Stratonovich integral</a></li>\n<li><a href="/wiki/Uniform_integrability" title="Uniform integrability">Uniform integrability</a></li>\n<li><a class="mw-redirect" href="/wiki/Usual_hypotheses" title="Usual hypotheses">Usual hypotheses</a></li>\n<li><a class="mw-redirect" href="/wiki/Wiener_space" title="Wiener space">Wiener space</a>\n<ul><li><a href="/wiki/Classical_Wiener_space" title="Classical Wiener space">Classical</a></li>\n<li><a href="/wiki/Abstract_Wiener_space" title="Abstract Wiener space">Abstract</a></li></ul></li></ul>\n</div></td></tr><tr><th class="navbox-group" scope="row" style="width:1%">Disciplines</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><a class="mw-redirect" href="/wiki/Actuarial_mathematics" title="Actuarial mathematics">Actuarial mathematics</a></li>\n<li><a href="/wiki/Stochastic_control" title="Stochastic control">Control theory</a></li>\n<li><a href="/wiki/Econometrics" title="Econometrics">Econometrics</a></li>\n<li><a href="/wiki/Ergodic_theory" title="Ergodic theory">Ergodic theory</a></li>\n<li><a href="/wiki/Extreme_value_theory" title="Extreme value theory">Extreme value theory (EVT)</a></li>\n<li><a href="/wiki/Large_deviations_theory" title="Large deviations theory">Large deviations theory</a></li>\n<li><a href="/wiki/Mathematical_finance" title="Mathematical finance">Mathematical finance</a></li>\n<li><a href="/wiki/Mathematical_statistics" title="Mathematical statistics">Mathematical statistics</a></li>\n<li><a href="/wiki/Probability_theory" title="Probability theory">Probability theory</a></li>\n<li><a href="/wiki/Queueing_theory" title="Queueing theory">Queueing theory</a></li>\n<li><a href="/wiki/Renewal_theory" title="Renewal theory">Renewal theory</a></li>\n<li><a href="/wiki/Ruin_theory" title="Ruin theory">Ruin theory</a></li>\n<li><a href="/wiki/Signal_processing" title="Signal processing">Signal processing</a></li>\n<li><a href="/wiki/Statistics" title="Statistics">Statistics</a></li>\n<li><a href="/wiki/System_on_a_chip" title="System on a chip">System on Chip</a> design</li>\n<li><a class="mw-redirect" href="/wiki/Stochastic_analysis" title="Stochastic analysis">Stochastic analysis</a></li>\n<li><a class="mw-redirect" href="/wiki/Time_series_analysis" title="Time series analysis">Time series analysis</a></li>\n<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li></ul>\n</div></td></tr><tr><td class="navbox-abovebelow hlist" colspan="2"><div>\n<ul><li><a href="/wiki/List_of_stochastic_processes_topics" title="List of stochastic processes topics">List of topics</a></li>\n<li><a href="/wiki/Category:Stochastic_processes" title="Category:Stochastic processes">Category</a></li></ul>\n</div></td></tr></tbody></table></div>\n<div aria-labelledby="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q176769#identifiers&amp;#124;Edit_this_at_Wikidata" class="navbox authority-control" role="navigation" style="padding:3px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th class="navbox-group" id="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q176769#identifiers&amp;#124;Edit_this_at_Wikidata" scope="row" style="width:1%"><a href="/wiki/Help:Authority_control" title="Help:Authority control">Authority control</a> <a href="https://www.wikidata.org/wiki/Q176769#identifiers" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" data-file-height="20" data-file-width="20" decoding="async" height="10" src="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x" style="vertical-align: text-top" width="10"/></a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">\n<ul><li><span class="nowrap"><a class="mw-redirect" href="/wiki/GND_(identifier)" title="GND (identifier)">GND</a>: <span class="uid"><a class="external text" href="https://d-nb.info/gnd/4352479-5" rel="nofollow">4352479-5</a></span></span></li></ul>\n</div></td></tr></tbody></table></div>\n<!-- \nNewPP limit report\nParsed by mw1413\nCached time: 20201030000615\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.600 seconds\nReal time usage: 0.911 seconds\nPreprocessor visited node count: 3022/1000000\nPost\xe2\x80\x90expand include size: 127871/2097152 bytes\nTemplate argument size: 1832/2097152 bytes\nHighest expansion depth: 13/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 140068/5000000 bytes\nLua time usage: 0.263/10.000 seconds\nLua memory usage: 5.35 MB/50 MB\nNumber of Wikibase entities loaded: 1/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  583.613      1 -total\n 53.08%  309.776      1 Template:Reflist\n 36.58%  213.499     30 Template:Cite_journal\n 10.86%   63.380      1 Template:Short_description\n  8.86%   51.715      5 Template:Main_other\n  8.52%   49.698      1 Template:Commons_category\n  7.82%   45.626      1 Template:Sister_project\n  6.41%   37.438      1 Template:Good_article\n  5.93%   34.607      1 Template:Pagetype\n  5.85%   34.127      1 Template:Side_box\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:98770-0!canonical!math=5 and timestamp 20201030000614 and revision id 983183862\n -->\n</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript>\n<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Hidden_Markov_model&amp;oldid=983183862">https://en.wikipedia.org/w/index.php?title=Hidden_Markov_model&amp;oldid=983183862</a>"</div></div>\n<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Bioinformatics" title="Category:Bioinformatics">Bioinformatics</a></li><li><a href="/wiki/Category:Hidden_Markov_models" title="Category:Hidden Markov models">Hidden Markov models</a></li><li><a href="/wiki/Category:Markov_models" title="Category:Markov models">Markov models</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:Pages_containing_links_to_subscription-only_content" title="Category:Pages containing links to subscription-only content">Pages containing links to subscription-only content</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_matches_Wikidata" title="Category:Short description matches Wikidata">Short description matches Wikidata</a></li><li><a href="/wiki/Category:Good_articles" title="Category:Good articles">Good articles</a></li><li><a href="/wiki/Category:Commons_category_link_is_on_Wikidata" title="Category:Commons category link is on Wikidata">Commons category link is on Wikidata</a></li><li><a href="/wiki/Category:Wikipedia_articles_with_GND_identifiers" title="Category:Wikipedia articles with GND identifiers">Wikipedia articles with GND identifiers</a></li><li><a href="/wiki/Category:Articles_with_example_Python_(programming_language)_code" title="Category:Articles with example Python (programming language) code">Articles with example Python (programming language) code</a></li></ul></div></div>\n</div>\n</div>\n<div id="mw-data-after-content">\n<div class="read-more-container"></div>\n</div>\n<div id="mw-navigation">\n<h2>Navigation menu</h2>\n<div id="mw-head">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-personal-label" class="mw-portlet mw-portlet-personal vector-menu" id="p-personal" role="navigation">\n<h3 id="p-personal-label">\n<span>Personal tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Hidden+Markov+model" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Hidden+Markov+model" title="You\'re encouraged to log in; however, it\'s not mandatory. [o]">Log in</a></li></ul>\n</div>\n</nav>\n<div id="left-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-namespaces-label" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" id="p-namespaces" role="navigation">\n<h3 id="p-namespaces-label">\n<span>Namespaces</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Hidden_Markov_model" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Hidden_Markov_model" rel="discussion" title="Discuss improvements to the content page [t]">Talk</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-variants-label" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" id="p-variants" role="navigation">\n<input aria-labelledby="p-variants-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-variants-label">\n<span>Variants</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n</div>\n<div id="right-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-views-label" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" id="p-views" role="navigation">\n<h3 id="p-views-label">\n<span>Views</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-view"><a href="/wiki/Hidden_Markov_model">Read</a></li><li id="ca-edit"><a accesskey="e" href="/w/index.php?title=Hidden_Markov_model&amp;action=edit" title="Edit this page [e]">Edit</a></li><li id="ca-history"><a accesskey="h" href="/w/index.php?title=Hidden_Markov_model&amp;action=history" title="Past revisions of this page [h]">View history</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-cactions-label" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" id="p-cactions" role="navigation">\n<input aria-labelledby="p-cactions-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-cactions-label">\n<span>More</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n<div id="p-search" role="search">\n<h3>\n<label for="searchInput">Search</label>\n</h3>\n<form action="/w/index.php" id="searchform">\n<div data-search-loc="header-navigation" id="simpleSearch">\n<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>\n<input name="title" type="hidden" value="Special:Search"/>\n<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search">\n<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>\n</input></div>\n</form>\n</div>\n</div>\n</div>\n<div id="mw-panel">\n<div id="p-logo" role="banner">\n<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>\n</div>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-navigation-label" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal portal-first" id="p-navigation" role="navigation">\n<h3 id="p-navigation-label">\n<span>Navigation</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Visit a randomly selected article [x]">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-interaction-label" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" id="p-interaction" role="navigation">\n<h3 id="p-interaction-label">\n<span>Contribute</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-tb-label" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" id="p-tb" role="navigation">\n<h3 id="p-tb-label">\n<span>Tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Hidden_Markov_model" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Hidden_Markov_model" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Hidden_Markov_model&amp;oldid=983183862" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Hidden_Markov_model&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Hidden_Markov_model&amp;id=983183862&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q176769" title="Structured data on this page hosted by Wikidata [g]">Wikidata item</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-coll-print_export-label" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" id="p-coll-print_export" role="navigation">\n<h3 id="p-coll-print_export-label">\n<span>Print/export</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Hidden_Markov_model&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Hidden_Markov_model&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-wikibase-otherprojects-label" class="mw-portlet mw-portlet-wikibase-otherprojects vector-menu vector-menu-portal portal" id="p-wikibase-otherprojects" role="navigation">\n<h3 id="p-wikibase-otherprojects-label">\n<span>In other projects</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Hidden_Markov_Model" hreflang="en">Wikimedia Commons</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-lang-label" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" id="p-lang" role="navigation">\n<h3 id="p-lang-label">\n<span>Languages</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-af"><a class="interlanguage-link-target" href="https://af.wikipedia.org/wiki/Verborge_Markovmodel" hreflang="af" lang="af" title="Verborge Markovmodel \xe2\x80\x93 Afrikaans">Afrikaans</a></li><li class="interlanguage-link interwiki-ar"><a class="interlanguage-link-target" href="https://ar.wikipedia.org/wiki/%D9%86%D8%B8%D8%B1%D9%8A%D8%A9_%D9%85%D8%A7%D8%B1%D9%83%D9%88%D9%81_%D8%A7%D9%84%D9%85%D8%AE%D9%81%D9%8A%D8%A9" hreflang="ar" lang="ar" title="\xd9\x86\xd8\xb8\xd8\xb1\xd9\x8a\xd8\xa9 \xd9\x85\xd8\xa7\xd8\xb1\xd9\x83\xd9\x88\xd9\x81 \xd8\xa7\xd9\x84\xd9\x85\xd8\xae\xd9\x81\xd9\x8a\xd8\xa9 \xe2\x80\x93 Arabic">\xd8\xa7\xd9\x84\xd8\xb9\xd8\xb1\xd8\xa8\xd9\x8a\xd8\xa9</a></li><li class="interlanguage-link interwiki-bg"><a class="interlanguage-link-target" href="https://bg.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D0%B8%D1%82_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB_%D0%BD%D0%B0_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2" hreflang="bg" lang="bg" title="\xd0\xa1\xd0\xba\xd1\x80\xd0\xb8\xd1\x82 \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb \xd0\xbd\xd0\xb0 \xd0\x9c\xd0\xb0\xd1\x80\xd0\xba\xd0\xbe\xd0\xb2 \xe2\x80\x93 Bulgarian">\xd0\x91\xd1\x8a\xd0\xbb\xd0\xb3\xd0\xb0\xd1\x80\xd1\x81\xd0\xba\xd0\xb8</a></li><li class="interlanguage-link interwiki-ca"><a class="interlanguage-link-target" href="https://ca.wikipedia.org/wiki/Model_ocult_de_M%C3%A0rkov" hreflang="ca" lang="ca" title="Model ocult de M\xc3\xa0rkov \xe2\x80\x93 Catalan">Catal\xc3\xa0</a></li><li class="interlanguage-link interwiki-cs"><a class="interlanguage-link-target" href="https://cs.wikipedia.org/wiki/Skryt%C3%BD_Markov%C5%AFv_model" hreflang="cs" lang="cs" title="Skryt\xc3\xbd Markov\xc5\xafv model \xe2\x80\x93 Czech">\xc4\x8ce\xc5\xa1tina</a></li><li class="interlanguage-link interwiki-de"><a class="interlanguage-link-target" href="https://de.wikipedia.org/wiki/Hidden_Markov_Model" hreflang="de" lang="de" title="Hidden Markov Model \xe2\x80\x93 German">Deutsch</a></li><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Modelo_oculto_de_M%C3%A1rkov" hreflang="es" lang="es" title="Modelo oculto de M\xc3\xa1rkov \xe2\x80\x93 Spanish">Espa\xc3\xb1ol</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%D9%85%D8%AF%D9%84_%D9%BE%D9%86%D9%87%D8%A7%D9%86_%D9%85%D8%A7%D8%B1%DA%A9%D9%88%D9%81" hreflang="fa" lang="fa" title="\xd9\x85\xd8\xaf\xd9\x84 \xd9\xbe\xd9\x86\xd9\x87\xd8\xa7\xd9\x86 \xd9\x85\xd8\xa7\xd8\xb1\xda\xa9\xd9\x88\xd9\x81 \xe2\x80\x93 Persian">\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Mod%C3%A8le_de_Markov_cach%C3%A9" hreflang="fr" lang="fr" title="Mod\xc3\xa8le de Markov cach\xc3\xa9 \xe2\x80\x93 French">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EC%9D%80%EB%8B%89_%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84_%EB%AA%A8%ED%98%95" hreflang="ko" lang="ko" title="\xec\x9d\x80\xeb\x8b\x89 \xeb\xa7\x88\xeb\xa5\xb4\xec\xbd\x94\xed\x94\x84 \xeb\xaa\xa8\xed\x98\x95 \xe2\x80\x93 Korean">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-id"><a class="interlanguage-link-target" href="https://id.wikipedia.org/wiki/Model_Markov_tersembunyi" hreflang="id" lang="id" title="Model Markov tersembunyi \xe2\x80\x93 Indonesian">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a class="interlanguage-link-target" href="https://it.wikipedia.org/wiki/Modello_di_Markov_nascosto" hreflang="it" lang="it" title="Modello di Markov nascosto \xe2\x80\x93 Italian">Italiano</a></li><li class="interlanguage-link interwiki-he"><a class="interlanguage-link-target" href="https://he.wikipedia.org/wiki/%D7%9E%D7%95%D7%93%D7%9C_%D7%9E%D7%A8%D7%A7%D7%95%D7%91_%D7%97%D7%91%D7%95%D7%99" hreflang="he" lang="he" title="\xd7\x9e\xd7\x95\xd7\x93\xd7\x9c \xd7\x9e\xd7\xa8\xd7\xa7\xd7\x95\xd7\x91 \xd7\x97\xd7\x91\xd7\x95\xd7\x99 \xe2\x80\x93 Hebrew">\xd7\xa2\xd7\x91\xd7\xa8\xd7\x99\xd7\xaa</a></li><li class="interlanguage-link interwiki-nl"><a class="interlanguage-link-target" href="https://nl.wikipedia.org/wiki/Hidden_Markov_model" hreflang="nl" lang="nl" title="Hidden Markov model \xe2\x80\x93 Dutch">Nederlands</a></li><li class="interlanguage-link interwiki-ja"><a class="interlanguage-link-target" href="https://ja.wikipedia.org/wiki/%E9%9A%A0%E3%82%8C%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E3%83%A2%E3%83%87%E3%83%AB" hreflang="ja" lang="ja" title="\xe9\x9a\xa0\xe3\x82\x8c\xe3\x83\x9e\xe3\x83\xab\xe3\x82\xb3\xe3\x83\x95\xe3\x83\xa2\xe3\x83\x87\xe3\x83\xab \xe2\x80\x93 Japanese">\xe6\x97\xa5\xe6\x9c\xac\xe8\xaa\x9e</a></li><li class="interlanguage-link interwiki-pt"><a class="interlanguage-link-target" href="https://pt.wikipedia.org/wiki/Modelo_oculto_de_Markov" hreflang="pt" lang="pt" title="Modelo oculto de Markov \xe2\x80\x93 Portuguese">Portugu\xc3\xaas</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" hreflang="ru" lang="ru" title="\xd0\xa1\xd0\xba\xd1\x80\xd1\x8b\xd1\x82\xd0\xb0\xd1\x8f \xd0\xbc\xd0\xb0\xd1\x80\xd0\xba\xd0\xbe\xd0\xb2\xd1\x81\xd0\xba\xd0\xb0\xd1\x8f \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c \xe2\x80\x93 Russian">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-sl"><a class="interlanguage-link-target" href="https://sl.wikipedia.org/wiki/Skriti_model_Markova" hreflang="sl" lang="sl" title="Skriti model Markova \xe2\x80\x93 Slovenian">Sloven\xc5\xa1\xc4\x8dina</a></li><li class="interlanguage-link interwiki-sr"><a class="interlanguage-link-target" href="https://sr.wikipedia.org/wiki/Skriveni_Markovljev_model" hreflang="sr" lang="sr" title="Skriveni Markovljev model \xe2\x80\x93 Serbian">\xd0\xa1\xd1\x80\xd0\xbf\xd1\x81\xd0\xba\xd0\xb8 / srpski</a></li><li class="interlanguage-link interwiki-sh"><a class="interlanguage-link-target" href="https://sh.wikipedia.org/wiki/Skriveni_Markovljev_model" hreflang="sh" lang="sh" title="Skriveni Markovljev model \xe2\x80\x93 Serbo-Croatian">Srpskohrvatski / \xd1\x81\xd1\x80\xd0\xbf\xd1\x81\xd0\xba\xd0\xbe\xd1\x85\xd1\x80\xd0\xb2\xd0\xb0\xd1\x82\xd1\x81\xd0\xba\xd0\xb8</a></li><li class="interlanguage-link interwiki-fi"><a class="interlanguage-link-target" href="https://fi.wikipedia.org/wiki/Markovin_piilomalli" hreflang="fi" lang="fi" title="Markovin piilomalli \xe2\x80\x93 Finnish">Suomi</a></li><li class="interlanguage-link interwiki-sv"><a class="interlanguage-link-target" href="https://sv.wikipedia.org/wiki/Dold_Markovmodell" hreflang="sv" lang="sv" title="Dold Markovmodell \xe2\x80\x93 Swedish">Svenska</a></li><li class="interlanguage-link interwiki-th"><a class="interlanguage-link-target" href="https://th.wikipedia.org/wiki/%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B8%88%E0%B8%B3%E0%B8%A5%E0%B8%AD%E0%B8%87%E0%B8%A1%E0%B8%B2%E0%B8%A3%E0%B9%8C%E0%B8%84%E0%B8%AD%E0%B8%9F%E0%B8%8B%E0%B9%88%E0%B8%AD%E0%B8%99%E0%B9%80%E0%B8%A3%E0%B9%89%E0%B8%99" hreflang="th" lang="th" title="\xe0\xb9\x81\xe0\xb8\x9a\xe0\xb8\x9a\xe0\xb8\x88\xe0\xb8\xb3\xe0\xb8\xa5\xe0\xb8\xad\xe0\xb8\x87\xe0\xb8\xa1\xe0\xb8\xb2\xe0\xb8\xa3\xe0\xb9\x8c\xe0\xb8\x84\xe0\xb8\xad\xe0\xb8\x9f\xe0\xb8\x8b\xe0\xb9\x88\xe0\xb8\xad\xe0\xb8\x99\xe0\xb9\x80\xe0\xb8\xa3\xe0\xb9\x89\xe0\xb8\x99 \xe2\x80\x93 Thai">\xe0\xb9\x84\xe0\xb8\x97\xe0\xb8\xa2</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%9F%D1%80%D0%B8%D1%85%D0%BE%D0%B2%D0%B0%D0%BD%D0%B0_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D1%8C%D0%BA%D0%B0_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" hreflang="uk" lang="uk" title="\xd0\x9f\xd1\x80\xd0\xb8\xd1\x85\xd0\xbe\xd0\xb2\xd0\xb0\xd0\xbd\xd0\xb0 \xd0\xbc\xd0\xb0\xd1\x80\xd0\xba\xd0\xbe\xd0\xb2\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0 \xd0\xbc\xd0\xbe\xd0\xb4\xd0\xb5\xd0\xbb\xd1\x8c \xe2\x80\x93 Ukrainian">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-vi"><a class="interlanguage-link-target" href="https://vi.wikipedia.org/wiki/M%C3%B4_h%C3%ACnh_Markov_%E1%BA%A9n" hreflang="vi" lang="vi" title="M\xc3\xb4 h\xc3\xacnh Markov \xe1\xba\xa9n \xe2\x80\x93 Vietnamese">Ti\xe1\xba\xbfng Vi\xe1\xbb\x87t</a></li><li class="interlanguage-link interwiki-zh"><a class="interlanguage-link-target" href="https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B" hreflang="zh" lang="zh" title="\xe9\x9a\x90\xe9\xa9\xac\xe5\xb0\x94\xe5\x8f\xaf\xe5\xa4\xab\xe6\xa8\xa1\xe5\x9e\x8b \xe2\x80\x93 Chinese">\xe4\xb8\xad\xe6\x96\x87</a></li></ul>\n<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q176769#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>\n</div>\n</nav>\n</div>\n</div>\n<footer class="mw-footer" id="footer" role="contentinfo">\n<ul id="footer-info">\n<li id="footer-info-lastmod"> This page was last edited on 12 October 2020, at 18:59<span class="anonymous-show">\xc2\xa0(UTC)</span>.</li>\n<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id="footer-places">\n<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>\n<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Hidden_Markov_model&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>\n<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>\n<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n</ul>\n<ul class="noprint" id="footer-icons">\n<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" loading="lazy" src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88"/></a></li>\n<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" loading="lazy" src="/static/images/footer/poweredby_mediawiki_88x31.png" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>\n</ul>\n<div style="clear: both;"></div>\n</footer>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.600","walltime":"0.911","ppvisitednodes":{"value":3022,"limit":1000000},"postexpandincludesize":{"value":127871,"limit":2097152},"templateargumentsize":{"value":1832,"limit":2097152},"expansiondepth":{"value":13,"limit":40},"expensivefunctioncount":{"value":1,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":140068,"limit":5000000},"entityaccesscount":{"value":1,"limit":400},"timingprofile":["100.00%  583.613      1 -total"," 53.08%  309.776      1 Template:Reflist"," 36.58%  213.499     30 Template:Cite_journal"," 10.86%   63.380      1 Template:Short_description","  8.86%   51.715      5 Template:Main_other","  8.52%   49.698      1 Template:Commons_category","  7.82%   45.626      1 Template:Sister_project","  6.41%   37.438      1 Template:Good_article","  5.93%   34.607      1 Template:Pagetype","  5.85%   34.127      1 Template:Side_box"]},"scribunto":{"limitreport-timeusage":{"value":"0.263","limit":"10.000"},"limitreport-memusage":{"value":5614863,"limit":52428800}},"cachereport":{"origin":"mw1413","timestamp":"20201030000615","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Hidden Markov model","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Hidden_Markov_model","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q176769","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q176769","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2002-10-03T16:04:39Z","dateModified":"2020-10-12T18:59:20Z","headline":"statistical Markov model"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":178,"wgHostname":"mw1329"});});</script>\n</body></html>'