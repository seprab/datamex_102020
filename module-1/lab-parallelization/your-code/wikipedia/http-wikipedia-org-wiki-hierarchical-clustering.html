b'<!DOCTYPE html>\n\n<html class="client-nojs" dir="ltr" lang="en">\n<head>\n<meta charset="utf8"/>\n<title>Hierarchical clustering - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"20ca02a4-cdf6-44ec-b6c0-a2ff2d09f154","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Hierarchical_clustering","wgTitle":"Hierarchical clustering","wgCurRevisionId":982368331,"wgRevisionId":982368331,"wgArticleId":477573,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with short description","Short description is different from Wikidata","All articles with unsourced statements","Articles with unsourced statements from April 2009","Network analysis","Cluster analysis algorithms"],"wgPageContentLanguage":"en","wgPageContentModel":\n"wikitext","wgRelevantPageName":"Hierarchical_clustering","wgRelevantArticleId":477573,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q1277447"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready",\n"ext.math.styles":"ready","skins.vector.styles.legacy":"ready","mediawiki.toc.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta content="" name="ResourceLoaderDynamicStyles"/>\n<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<meta content="MediaWiki 1.36.0-wmf.14" name="generator"/>\n<meta content="origin" name="referrer"/>\n<meta content="origin-when-crossorigin" name="referrer"/>\n<meta content="origin-when-cross-origin" name="referrer"/>\n<link href="//en.m.wikipedia.org/wiki/Hierarchical_clustering" media="only screen and (max-width: 720px)" rel="alternate"/>\n<link href="/w/index.php?title=Hierarchical_clustering&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>\n<link href="/w/index.php?title=Hierarchical_clustering&amp;action=edit" rel="edit" title="Edit this page"/>\n<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>\n<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>\n<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>\n<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>\n<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>\n<link href="https://en.wikipedia.org/wiki/Hierarchical_clustering" rel="canonical"/>\n<link href="//login.wikimedia.org" rel="dns-prefetch"/>\n<link href="//meta.wikimedia.org" rel="dns-prefetch"/>\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Hierarchical_clustering rootpage-Hierarchical_clustering skin-vector action-view skin-vector-legacy"><div class="noprint" id="mw-page-base"></div>\n<div class="noprint" id="mw-head-base"></div>\n<div class="mw-body" id="content" role="main">\n<a id="top"></a>\n<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>\n<div class="mw-indicators mw-body-content">\n</div>\n<h1 class="firstHeading" id="firstHeading" lang="en">Hierarchical clustering</h1>\n<div class="mw-body-content" id="bodyContent">\n<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>\n<div id="contentSub"></div>\n<div id="contentSub2"></div>\n<div id="jump-to-nav"></div>\n<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n<a class="mw-jump-link" href="#searchInput">Jump to search</a>\n<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="hatnote navigation-not-searchable" role="note">"SLINK" redirects here. For the online magazine, see <a href="/wiki/Slink" title="Slink">Slink</a>.</div>\n<div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">A statistical method of analysis which seeks to build a hierarchy of clusters</div>\n<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><td style="padding-top:0.4em;line-height:1.2em">Part of a series on</td></tr><tr><th style="padding:0.2em 0.4em 0.2em;padding-top:0;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a><br/>and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="display:inline-block; padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>\xc2\xa0\xe2\x80\xa2 <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a class="mw-redirect" href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>\n<li><a class="mw-selflink selflink">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li>\n<li><a href="/wiki/Echo_state_network" title="Echo state network">ESN</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li>\n<li><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<p>In <a href="/wiki/Data_mining" title="Data mining">data mining</a> and <a href="/wiki/Statistics" title="Statistics">statistics</a>, <b>hierarchical clustering</b> (also called <b>hierarchical cluster analysis</b> or <b>HCA</b>) is a method of <a href="/wiki/Cluster_analysis" title="Cluster analysis">cluster analysis</a> which seeks to build a <a href="/wiki/Hierarchy" title="Hierarchy">hierarchy</a> of clusters. Strategies for hierarchical clustering generally fall into two types:<sup class="reference" id="cite_ref-clusteringMethods_1-0"><a href="#cite_note-clusteringMethods-1">[1]</a></sup>\n</p>\n<ul><li><b>Agglomerative</b>: This is a "<a href="/wiki/Top-down_and_bottom-up_design" title="Top-down and bottom-up design">bottom-up</a>" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.</li>\n<li><b>Divisive</b>: This is a "<a href="/wiki/Top-down_and_bottom-up_design" title="Top-down and bottom-up design">top-down</a>" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.</li></ul>\n<p>In general, the merges and splits are determined in a <a href="/wiki/Greedy_algorithm" title="Greedy algorithm">greedy</a> manner. The results of hierarchical clustering<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> are usually presented in a <a href="/wiki/Dendrogram" title="Dendrogram">dendrogram</a>.\n</p><p>The standard algorithm for <b>hierarchical agglomerative clustering</b> (HAC) has a <a href="/wiki/Time_complexity" title="Time complexity">time complexity</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(n^{3})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>3</mn>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(n^{3})}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {O}}(n^{3})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ff78e74de3bf7a5246829c66bc5acf0c2a94b67c" style="vertical-align: -0.838ex; width:6.108ex; height:3.176ex;"/></span> and requires <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\Omega (n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi mathvariant="normal">\xce\xa9<!-- \xce\xa9 --></mi>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\Omega (n^{2})}</annotation>\n</semantics>\n</math></span><img alt="\\Omega (n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c14304cd1cb8bf603cb59037b666c5a85cd8e7ae" style="vertical-align: -0.838ex; width:5.936ex; height:3.176ex;"/></span> memory, which makes it too slow for even medium data sets. However, for some special cases, optimal efficient agglomerative methods (of complexity <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(n^{2})}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {O}}(n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4441d9689c0e6b2c47994e2f587ac5378faeefba" style="vertical-align: -0.838ex; width:6.108ex; height:3.176ex;"/></span>) are known: <b>SLINK</b><sup class="reference" id="cite_ref-SLINK_3-0"><a href="#cite_note-SLINK-3">[3]</a></sup> for <a href="/wiki/Single-linkage_clustering" title="Single-linkage clustering">single-linkage</a> and CLINK<sup class="reference" id="cite_ref-CLINK_4-0"><a href="#cite_note-CLINK-4">[4]</a></sup> for <a href="/wiki/Complete-linkage_clustering" title="Complete-linkage clustering">complete-linkage clustering</a>. With a <a href="/wiki/Heap_(data_structure)" title="Heap (data structure)">heap</a>, the runtime of the general case can be reduced to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(n^{2}\\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n<mi>log</mi>\n<mo>\xe2\x81\xa1<!-- \xe2\x81\xa1 --></mo>\n<mi>n</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(n^{2}\\log n)}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal  {O}}(n^{2}\\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ff9d8247a11fce04adfd903d817db246a6d3d44b" style="vertical-align: -0.838ex; width:11.249ex; height:3.176ex;"/></span>, an improvement on the aforementioned bound of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(n^{3})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>3</mn>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(n^{3})}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {O}}(n^{3})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ff78e74de3bf7a5246829c66bc5acf0c2a94b67c" style="vertical-align: -0.838ex; width:6.108ex; height:3.176ex;"/></span>, at the cost of further increasing the memory requirements. In many cases, the memory overheads of this approach are too large to make it practically usable.\n</p><p>Except for the special case of single-linkage, none of the algorithms (except exhaustive search in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(2^{n})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mn>2</mn>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(2^{n})}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle {\\mathcal {O}}(2^{n})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9e36948445d0efd3f0b41d0bd7d281571e72492d" style="vertical-align: -0.838ex; width:6.04ex; height:2.843ex;"/></span>) can be guaranteed to find the optimum solution.\n</p><p>Divisive clustering with an exhaustive search is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {O}}(2^{n})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">O</mi>\n</mrow>\n</mrow>\n<mo stretchy="false">(</mo>\n<msup>\n<mn>2</mn>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {O}}(2^{n})}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle {\\mathcal {O}}(2^{n})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9e36948445d0efd3f0b41d0bd7d281571e72492d" style="vertical-align: -0.838ex; width:6.04ex; height:2.843ex;"/></span>, but it is common to use faster heuristics to choose splits, such as k-means.\n</p>\n<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Cluster_dissimilarity"><span class="tocnumber">1</span> <span class="toctext">Cluster dissimilarity</span></a>\n<ul>\n<li class="toclevel-2 tocsection-2"><a href="#Metric"><span class="tocnumber">1.1</span> <span class="toctext">Metric</span></a></li>\n<li class="toclevel-2 tocsection-3"><a href="#Linkage_criteria"><span class="tocnumber">1.2</span> <span class="toctext">Linkage criteria</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-4"><a href="#Discussion"><span class="tocnumber">2</span> <span class="toctext">Discussion</span></a></li>\n<li class="toclevel-1 tocsection-5"><a href="#Agglomerative_clustering_example"><span class="tocnumber">3</span> <span class="toctext">Agglomerative clustering example</span></a></li>\n<li class="toclevel-1 tocsection-6"><a href="#Divisive_clustering"><span class="tocnumber">4</span> <span class="toctext">Divisive clustering</span></a></li>\n<li class="toclevel-1 tocsection-7"><a href="#Software"><span class="tocnumber">5</span> <span class="toctext">Software</span></a>\n<ul>\n<li class="toclevel-2 tocsection-8"><a href="#Open_source_implementations"><span class="tocnumber">5.1</span> <span class="toctext">Open source implementations</span></a></li>\n<li class="toclevel-2 tocsection-9"><a href="#Commercial_implementations"><span class="tocnumber">5.2</span> <span class="toctext">Commercial implementations</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-10"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-11"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>\n<li class="toclevel-1 tocsection-12"><a href="#Further_reading"><span class="tocnumber">8</span> <span class="toctext">Further reading</span></a></li>\n</ul>\n</div>\n<h2><span class="mw-headline" id="Cluster_dissimilarity">Cluster dissimilarity</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=1" title="Edit section: Cluster dissimilarity">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>In order to decide which clusters should be combined (for agglomerative), or where a cluster should be split (for divisive), a measure of dissimilarity between sets of observations is required. In most methods of hierarchical clustering, this is achieved by use of an appropriate <a href="/wiki/Metric_(mathematics)" title="Metric (mathematics)">metric</a> (a measure of <a href="/wiki/Distance" title="Distance">distance</a> between pairs of observations), and a linkage criterion which specifies the dissimilarity of sets as a function of the pairwise distances of observations in the sets.\n</p>\n<h3><span class="mw-headline" id="Metric">Metric</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=2" title="Edit section: Metric">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div class="hatnote navigation-not-searchable" role="note">Further information: <a href="/wiki/Metric_(mathematics)" title="Metric (mathematics)">Metric (mathematics)</a></div>\n<p>The choice of an appropriate metric will influence the shape of the clusters, as some elements may be relatively closer to one another under one metric than another. For example, in two dimensions, under the Manhattan distance metric, the distance between the origin (0,0) and (.5, .5) is the same as the distance between the origin and (0, 1), while under the Euclidean distance metric the latter is strictly greater.\n</p><p>Some commonly used metrics for hierarchical clustering are:<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>\n</p>\n<table class="wikitable">\n<tbody><tr>\n<th>Names\n</th>\n<th>Formula\n</th></tr>\n<tr>\n<td><a href="/wiki/Euclidean_distance" title="Euclidean distance">Euclidean distance</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\|a-b\\|_{2}={\\sqrt {\\sum _{i}(a_{i}-b_{i})^{2}}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msub>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<msqrt>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</munder>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<msup>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</msqrt>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\|a-b\\|_{2}={\\sqrt {\\sum _{i}(a_{i}-b_{i})^{2}}}}</annotation>\n</semantics>\n</math></span><img alt="\\|a-b\\|_{2}={\\sqrt  {\\sum _{i}(a_{i}-b_{i})^{2}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c28af99d6b7c1ff13d2b79347e90fec407aa9ef0" style="vertical-align: -3.338ex; width:26.755ex; height:6.176ex;"/></span>\n</td></tr>\n<tr>\n<td>Squared Euclidean distance\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\|a-b\\|_{2}^{2}=\\sum _{i}(a_{i}-b_{i})^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<msubsup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msubsup>\n<mo>=</mo>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</munder>\n<mo stretchy="false">(</mo>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<msup>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\|a-b\\|_{2}^{2}=\\sum _{i}(a_{i}-b_{i})^{2}}</annotation>\n</semantics>\n</math></span><img alt="\\|a-b\\|_{2}^{2}=\\sum _{i}(a_{i}-b_{i})^{2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/be73281c1511a38c598b2a40c2985e2ede226eab" style="vertical-align: -3.005ex; width:24.431ex; height:5.509ex;"/></span>\n</td></tr>\n<tr>\n<td><a class="mw-redirect" href="/wiki/Manhattan_distance" title="Manhattan distance">Manhattan distance</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\|a-b\\|_{1}=\\sum _{i}|a_{i}-b_{i}|}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>=</mo>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</munder>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\|a-b\\|_{1}=\\sum _{i}|a_{i}-b_{i}|}</annotation>\n</semantics>\n</math></span><img alt="\\|a-b\\|_{1}=\\sum _{i}|a_{i}-b_{i}|" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6a2e701957744dcdf361a0dc0d79633491e17bfb" style="vertical-align: -3.005ex; width:23.248ex; height:5.509ex;"/></span>\n</td></tr>\n<tr>\n<td><a href="/wiki/Uniform_norm" title="Uniform norm">Maximum distance</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\|a-b\\|_{\\infty }=\\max _{i}|a_{i}-b_{i}|}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="normal">\xe2\x88\x9e<!-- \xe2\x88\x9e --></mi>\n</mrow>\n</msub>\n<mo>=</mo>\n<munder>\n<mo form="prefix" movablelimits="true">max</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</munder>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\|a-b\\|_{\\infty }=\\max _{i}|a_{i}-b_{i}|}</annotation>\n</semantics>\n</math></span><img alt="\\|a-b\\|_{\\infty }=\\max _{i}|a_{i}-b_{i}|" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c275abbd06f5262461af5fda82cf7f53eb8161e8" style="vertical-align: -2.005ex; width:25.04ex; height:4.009ex;"/></span>\n</td></tr>\n<tr>\n<td><a href="/wiki/Mahalanobis_distance" title="Mahalanobis distance">Mahalanobis distance</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\sqrt {(a-b)^{\\top }S^{-1}(a-b)}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<msqrt>\n<mo stretchy="false">(</mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<msup>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi mathvariant="normal">\xe2\x8a\xa4<!-- \xe2\x8a\xa4 --></mi>\n</mrow>\n</msup>\n<msup>\n<mi>S</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n</mrow>\n</msup>\n<mo stretchy="false">(</mo>\n<mi>a</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>b</mi>\n<mo stretchy="false">)</mo>\n</msqrt>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\sqrt {(a-b)^{\\top }S^{-1}(a-b)}}}</annotation>\n</semantics>\n</math></span><img alt="{\\sqrt  {(a-b)^{{\\top }}S^{{-1}}(a-b)}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4394a5fa306f849f2f712e765697deff7685279f" style="vertical-align: -1.671ex; width:21.443ex; height:4.843ex;"/></span> where <i>S</i> is the <a href="/wiki/Covariance_matrix" title="Covariance matrix">Covariance matrix</a>\n</td></tr>\n</tbody></table>\n<p>For text or other non-numeric data, metrics such as the <a href="/wiki/Hamming_distance" title="Hamming distance">Hamming distance</a> or <a href="/wiki/Levenshtein_distance" title="Levenshtein distance">Levenshtein distance</a> are often used.\n</p><p>A review of cluster analysis in health psychology research found that the most common distance measure in published studies in that research area is the Euclidean distance or the squared Euclidean distance.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2009)">citation needed</span></a></i>]</sup>\n</p>\n<h3><span class="mw-headline" id="Linkage_criteria">Linkage criteria</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=3" title="Edit section: Linkage criteria">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The linkage criterion determines the distance between sets of observations as a function of the pairwise distances between observations.\n</p><p>Some commonly used linkage criteria between two sets of observations <i>A</i> and <i>B</i> are:<sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup><sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>\n</p>\n<table class="wikitable">\n<tbody><tr>\n<th>Names\n</th>\n<th>Formula\n</th></tr>\n<tr>\n<td>Maximum or <a href="/wiki/Complete-linkage_clustering" title="Complete-linkage clustering">complete-linkage clustering</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\max \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}.}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo form="prefix" movablelimits="true">max</mo>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">{</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>a</mi>\n<mo>,</mo>\n<mi>b</mi>\n<mo stretchy="false">)</mo>\n<mo>:</mo>\n<mi>a</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n<mo>,</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>b</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>B</mi>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">}</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\max \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}.}</annotation>\n</semantics>\n</math></span><img alt="\\max \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ea47cb29523a267681865d874c59575c56860d0" style="vertical-align: -0.838ex; width:29.519ex; height:2.843ex;"/></span>\n</td></tr>\n<tr>\n<td>Minimum or <a href="/wiki/Single-linkage_clustering" title="Single-linkage clustering">single-linkage clustering</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\min \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}.}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo form="prefix" movablelimits="true">min</mo>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">{</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>a</mi>\n<mo>,</mo>\n<mi>b</mi>\n<mo stretchy="false">)</mo>\n<mo>:</mo>\n<mi>a</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n<mo>,</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>b</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>B</mi>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">}</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\min \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}.}</annotation>\n</semantics>\n</math></span><img alt="\\min \\,\\{\\,d(a,b):a\\in A,\\,b\\in B\\,\\}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d701e358058dbf66bb18b11a570a089a150ef356" style="vertical-align: -0.838ex; width:29.069ex; height:2.843ex;"/></span>\n</td></tr>\n<tr>\n<td>Unweighted average linkage clustering (or <a href="/wiki/UPGMA" title="UPGMA">UPGMA</a>)\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\frac {1}{|A|\\cdot |B|}}\\sum _{a\\in A}\\sum _{b\\in B}d(a,b).}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>A</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mo>\xe2\x8b\x85<!-- \xe2\x8b\x85 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>B</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n</mrow>\n</mfrac>\n</mrow>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>a</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>A</mi>\n</mrow>\n</munder>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>b</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mi>B</mi>\n</mrow>\n</munder>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>a</mi>\n<mo>,</mo>\n<mi>b</mi>\n<mo stretchy="false">)</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\frac {1}{|A|\\cdot |B|}}\\sum _{a\\in A}\\sum _{b\\in B}d(a,b).}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle {\\frac {1}{|A|\\cdot |B|}}\\sum _{a\\in A}\\sum _{b\\in B}d(a,b).}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82a2de7a124d8e0f2166fd2d495cd1e437a03d7a" style="vertical-align: -3.171ex; width:23.414ex; height:6.509ex;"/></span>\n</td></tr>\n<tr>\n<td>Weighted average linkage clustering (or <a href="/wiki/WPGMA" title="WPGMA">WPGMA</a>)\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle d(i\\cup j,k)={\\frac {d(i,k)+d(j,k)}{2}}.}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>i</mi>\n<mo>\xe2\x88\xaa<!-- \xe2\x88\xaa --></mo>\n<mi>j</mi>\n<mo>,</mo>\n<mi>k</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mrow>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>i</mi>\n<mo>,</mo>\n<mi>k</mi>\n<mo stretchy="false">)</mo>\n<mo>+</mo>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>j</mi>\n<mo>,</mo>\n<mi>k</mi>\n<mo stretchy="false">)</mo>\n</mrow>\n<mn>2</mn>\n</mfrac>\n</mrow>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle d(i\\cup j,k)={\\frac {d(i,k)+d(j,k)}{2}}.}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle d(i\\cup j,k)={\\frac {d(i,k)+d(j,k)}{2}}.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e1b3c894e5ba8264d8b80c22e1056fde29e1f1e0" style="vertical-align: -1.838ex; width:29.336ex; height:5.676ex;"/></span>\n</td></tr>\n<tr>\n<td>Centroid linkage clustering, or UPGMC\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\|c_{s}-c_{t}\\|}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi>c</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>s</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>c</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>t</mi>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\|c_{s}-c_{t}\\|}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle \\|c_{s}-c_{t}\\|}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3982c2dbc00dc22b17e5d18f9881fae054d0823e" style="vertical-align: -0.838ex; width:9.008ex; height:2.843ex;"/></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle c_{s}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>c</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>s</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle c_{s}}</annotation>\n</semantics>\n</math></span><img alt="c_{s}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/75b83e050da28fa0d83e2aa786963805742ab756" style="vertical-align: -0.671ex; width:2.01ex; height:2.009ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle c_{t}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>c</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>t</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle c_{t}}</annotation>\n</semantics>\n</math></span><img alt="c_{t}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/93578e37f3234419a34df79845836bc0ec5ef76c" style="vertical-align: -0.671ex; width:1.833ex; height:2.009ex;"/></span> are the centroids of clusters <i>s</i> and <i>t</i>, respectively.\n</td></tr>\n<tr>\n<td><a href="/wiki/Energy_distance" title="Energy distance">Minimum energy clustering</a>\n</td>\n<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\frac {2}{nm}}\\sum _{i,j=1}^{n,m}\\|a_{i}-b_{j}\\|_{2}-{\\frac {1}{n^{2}}}\\sum _{i,j=1}^{n}\\|a_{i}-a_{j}\\|_{2}-{\\frac {1}{m^{2}}}\\sum _{i,j=1}^{m}\\|b_{i}-b_{j}\\|_{2}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>2</mn>\n<mrow>\n<mi>n</mi>\n<mi>m</mi>\n</mrow>\n</mfrac>\n</mrow>\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>,</mo>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n<mo>,</mo>\n<mi>m</mi>\n</mrow>\n</munderover>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<msup>\n<mi>n</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mfrac>\n</mrow>\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>,</mo>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</munderover>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>a</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<msup>\n<mi>m</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mfrac>\n</mrow>\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>,</mo>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>m</mi>\n</mrow>\n</munderover>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<msub>\n<mi>b</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>j</mi>\n</mrow>\n</msub>\n<msub>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\frac {2}{nm}}\\sum _{i,j=1}^{n,m}\\|a_{i}-b_{j}\\|_{2}-{\\frac {1}{n^{2}}}\\sum _{i,j=1}^{n}\\|a_{i}-a_{j}\\|_{2}-{\\frac {1}{m^{2}}}\\sum _{i,j=1}^{m}\\|b_{i}-b_{j}\\|_{2}}</annotation>\n</semantics>\n</math></span><img alt="{\\frac  {2}{nm}}\\sum _{{i,j=1}}^{{n,m}}\\|a_{i}-b_{j}\\|_{2}-{\\frac  {1}{n^{2}}}\\sum _{{i,j=1}}^{{n}}\\|a_{i}-a_{j}\\|_{2}-{\\frac  {1}{m^{2}}}\\sum _{{i,j=1}}^{{m}}\\|b_{i}-b_{j}\\|_{2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e140be09a89b1c70b4e002083daed90df2ee63d4" style="vertical-align: -3.338ex; width:61.368ex; height:7.343ex;"/></span>\n</td></tr></tbody></table>\n<p>where <i>d</i> is the chosen metric.  Other linkage criteria include:\n</p>\n<ul><li>The sum of all intra-cluster variance.</li>\n<li>The increase in variance for the cluster being merged (<a href="/wiki/Ward%27s_method" title="Ward\'s method">Ward\'s criterion</a>).<sup class="reference" id="cite_ref-wards_method_8-0"><a href="#cite_note-wards_method-8">[8]</a></sup></li>\n<li>The probability that candidate clusters spawn from the same distribution function (V-linkage).</li>\n<li>The product of in-degree and out-degree on a k-nearest-neighbour graph (graph degree linkage).<sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup></li>\n<li>The increment of some cluster descriptor (i.e., a quantity defined for measuring the quality of a cluster) after merging two clusters.<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup><sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup><sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup></li></ul>\n<h2><span class="mw-headline" id="Discussion">Discussion</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=4" title="Edit section: Discussion">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Hierarchical clustering has the distinct advantage that any valid measure of distance can be used. In fact, the observations themselves are not required: all that is used is a matrix of distances.\n</p>\n<h2><span class="mw-headline" id="Agglomerative_clustering_example">Agglomerative clustering example</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=5" title="Edit section: Agglomerative clustering example">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="thumb tnone"><div class="thumbinner" style="width:252px;"><a class="image" href="/wiki/File:Clusters.svg"><img alt="" class="thumbimage" data-file-height="251" data-file-width="250" decoding="async" height="251" src="//upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Clusters.svg/250px-Clusters.svg.png" width="250"/></a> <div class="thumbcaption">Raw data</div></div></div>\n<p>For example, suppose this data is to be clustered, and the <a href="/wiki/Euclidean_distance" title="Euclidean distance">Euclidean distance</a> is the <a href="/wiki/Metric_(mathematics)" title="Metric (mathematics)">distance metric</a>.\n</p><p>The hierarchical clustering <a href="/wiki/Dendrogram" title="Dendrogram">dendrogram</a> would be as such:\n</p>\n<div class="thumb tnone"><div class="thumbinner" style="width:420px;"><a class="image" href="/wiki/File:Hierarchical_clustering_simple_diagram.svg"><img alt="" class="thumbimage" data-file-height="333" data-file-width="418" decoding="async" height="333" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Hierarchical_clustering_simple_diagram.svg/418px-Hierarchical_clustering_simple_diagram.svg.png" width="418"/></a> <div class="thumbcaption">Traditional representation</div></div></div>\n<p>Cutting the tree at a given height will give a partitioning clustering at a selected precision. In this example, cutting after the second row (from the top) of the <a href="/wiki/Dendrogram" title="Dendrogram">dendrogram</a> will yield clusters {a} {b c} {d e} {f}. Cutting after the third row will yield clusters {a} {b c} {d e f}, which is a coarser clustering, with a smaller number but larger clusters.\n</p><p>This method builds the hierarchy from the individual elements by progressively merging clusters. In our example, we have six elements {a} {b} {c} {d} {e} and {f}. The first step is to determine which elements to merge in a cluster. Usually, we want to take the two closest elements, according to the chosen distance.\n</p><p>Optionally, one can also construct a <a href="/wiki/Distance_matrix" title="Distance matrix">distance matrix</a> at this stage, where the number in the <i>i</i>-th row <i>j</i>-th column is the distance between the <i>i</i>-th and <i>j</i>-th elements. Then, as clustering progresses, rows and columns are merged as the clusters are merged and the distances updated. This is a common way to implement this type of clustering, and has the benefit of caching distances between clusters. A simple agglomerative clustering algorithm is described in the <a href="/wiki/Single-linkage_clustering" title="Single-linkage clustering">single-linkage clustering</a> page; it can easily be adapted to different types of linkage (see below).\n</p><p>Suppose we have merged the two closest elements <i>b</i> and <i>c</i>, we now have the following clusters {<i>a</i>}, {<i>b</i>, <i>c</i>}, {<i>d</i>}, {<i>e</i>} and {<i>f</i>}, and want to merge them further. To do that, we need to take the distance between {a} and {b c}, and therefore define the distance between two clusters.\nUsually the distance between two clusters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {A}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">A</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {A}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {A}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/280ae03440942ab348c2ca9b8db6b56ffa9618f8" style="vertical-align: -0.338ex; width:1.903ex; height:2.343ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {B}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">B</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {B}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {B}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e5622de88a69f68340f8dcb43d0b8bd443ba9e13" style="vertical-align: -0.338ex; width:1.543ex; height:2.176ex;"/></span> is one of the following:\n</p>\n<ul><li>The maximum distance between elements of each cluster (also called <a href="/wiki/Complete-linkage_clustering" title="Complete-linkage clustering">complete-linkage clustering</a>):</li></ul>\n<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\max\\{\\,d(x,y):x\\in {\\mathcal {A}},\\,y\\in {\\mathcal {B}}\\,\\}.}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo form="prefix" movablelimits="true">max</mo>\n<mo fence="false" stretchy="false">{</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>:</mo>\n<mi>x</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">A</mi>\n</mrow>\n</mrow>\n<mo>,</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>y</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">B</mi>\n</mrow>\n</mrow>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">}</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\max\\{\\,d(x,y):x\\in {\\mathcal {A}},\\,y\\in {\\mathcal {B}}\\,\\}.}</annotation>\n</semantics>\n</math></span><img alt="\\max\\{\\,d(x,y):x\\in {\\mathcal  {A}},\\,y\\in {\\mathcal  {B}}\\,\\}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b1f1ffd5fd585304a25e76ed387979afa70694f" style="vertical-align: -0.838ex; width:29.587ex; height:2.843ex;"/></span></dd></dl></dd></dl>\n<ul><li>The minimum distance between elements of each cluster (also called <a href="/wiki/Single-linkage_clustering" title="Single-linkage clustering">single-linkage clustering</a>):</li></ul>\n<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\min\\{\\,d(x,y):x\\in {\\mathcal {A}},\\,y\\in {\\mathcal {B}}\\,\\}.}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mo form="prefix" movablelimits="true">min</mo>\n<mo fence="false" stretchy="false">{</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>:</mo>\n<mi>x</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">A</mi>\n</mrow>\n</mrow>\n<mo>,</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>y</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">B</mi>\n</mrow>\n</mrow>\n<mspace width="thinmathspace"></mspace>\n<mo fence="false" stretchy="false">}</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\min\\{\\,d(x,y):x\\in {\\mathcal {A}},\\,y\\in {\\mathcal {B}}\\,\\}.}</annotation>\n</semantics>\n</math></span><img alt="\\min\\{\\,d(x,y):x\\in {\\mathcal  {A}},\\,y\\in {\\mathcal  {B}}\\,\\}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65bc2866cb68a9e595f3887113eb4d3c784ae66f" style="vertical-align: -0.838ex; width:29.137ex; height:2.843ex;"/></span></dd></dl></dd></dl>\n<ul><li>The mean distance between elements of each cluster (also called average linkage clustering, used e.g. in <a href="/wiki/UPGMA" title="UPGMA">UPGMA</a>):</li></ul>\n<dl><dd><dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {1 \\over {|{\\mathcal {A}}|\\cdot |{\\mathcal {B}}|}}\\sum _{x\\in {\\mathcal {A}}}\\sum _{y\\in {\\mathcal {B}}}d(x,y).}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">A</mi>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mo>\xe2\x8b\x85<!-- \xe2\x8b\x85 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">B</mi>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n</mrow>\n</mfrac>\n</mrow>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>x</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">A</mi>\n</mrow>\n</mrow>\n</mrow>\n</munder>\n<munder>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>y</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">B</mi>\n</mrow>\n</mrow>\n</mrow>\n</munder>\n<mi>d</mi>\n<mo stretchy="false">(</mo>\n<mi>x</mi>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {1 \\over {|{\\mathcal {A}}|\\cdot |{\\mathcal {B}}|}}\\sum _{x\\in {\\mathcal {A}}}\\sum _{y\\in {\\mathcal {B}}}d(x,y).}</annotation>\n</semantics>\n</math></span><img alt="{1 \\over {|{\\mathcal  {A}}|\\cdot |{\\mathcal  {B}}|}}\\sum _{{x\\in {\\mathcal  {A}}}}\\sum _{{y\\in {\\mathcal  {B}}}}d(x,y)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e29192983147607536e467cd1bcf9ce3cb86b49" style="vertical-align: -3.338ex; width:23.639ex; height:6.676ex;"/></span></dd></dl></dd></dl>\n<ul><li>The sum of all intra-cluster variance.</li>\n<li>The increase in variance for the cluster being merged (<a href="/wiki/Ward%27s_method" title="Ward\'s method">Ward\'s method</a><sup class="reference" id="cite_ref-wards_method_8-1"><a href="#cite_note-wards_method-8">[8]</a></sup>)</li>\n<li>The probability that candidate clusters spawn from the same distribution function (V-linkage).</li></ul>\n<p>In case of tied minimum distances, a pair is randomly chosen, thus being able to generate several structurally different dendrograms. Alternatively, all tied pairs may be joined at the same time, generating a unique dendrogram.<sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>\n</p><p>One can always decide to stop clustering when there is a sufficiently small number of clusters (number criterion). Some linkages may also guarantee that agglomeration occurs at a greater distance between clusters than the previous agglomeration, and then one can stop clustering when the clusters are too far apart to be merged (distance criterion). However, this is not the case of, e.g., the centroid linkage where the so-called reversals<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> (inversions, departures from ultrametricity) may occur.\n</p>\n<h2><span class="mw-headline" id="Divisive_clustering">Divisive clustering</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=6" title="Edit section: Divisive clustering">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The basic principle of divisive clustering was published as the DIANA (DIvisive ANAlysis Clustering) algorithm.<sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> Initially, all data is in the same cluster, and the largest cluster is split until every object is separate.\nBecause there exist <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle O(2^{n})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>O</mi>\n<mo stretchy="false">(</mo>\n<msup>\n<mn>2</mn>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msup>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle O(2^{n})}</annotation>\n</semantics>\n</math></span><img alt="O(2^{n})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d4b1a4ff0bc4f81ebf79f28260c6fb54ee08ff8d" style="vertical-align: -0.838ex; width:5.964ex; height:2.843ex;"/></span> ways of splitting each cluster, heuristics are needed. DIANA chooses the object with the maximum average dissimilarity and then moves all objects to this cluster that are more similar to the new cluster than to the remainder.\n</p>\n<h2><span class="mw-headline" id="Software">Software</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=7" title="Edit section: Software">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<h3><span class="mw-headline" id="Open_source_implementations">Open source implementations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=8" title="Edit section: Open source implementations">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a class="image" href="/wiki/File:Iris_dendrogram.png"><img alt="" class="thumbimage" data-file-height="1300" data-file-width="910" decoding="async" height="314" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/12/Iris_dendrogram.png/220px-Iris_dendrogram.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/12/Iris_dendrogram.png/330px-Iris_dendrogram.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/12/Iris_dendrogram.png/440px-Iris_dendrogram.png 2x" width="220"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Iris_dendrogram.png" title="Enlarge"></a></div>Hierarchical clustering <a href="/wiki/Dendrogram" title="Dendrogram">dendrogram</a> of the <a href="/wiki/Iris_flower_data_set" title="Iris flower data set">Iris dataset</a> (using <a href="/wiki/R_(programming_language)" title="R (programming language)">R</a>). <a class="external text" href="https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html" rel="nofollow">Source</a></div></div></div>\n<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a class="image" href="/wiki/File:Orange-data-mining-hierarchical-clustering.png"><img alt="" class="thumbimage" data-file-height="1270" data-file-width="1224" decoding="async" height="228" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/97/Orange-data-mining-hierarchical-clustering.png/220px-Orange-data-mining-hierarchical-clustering.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/97/Orange-data-mining-hierarchical-clustering.png/330px-Orange-data-mining-hierarchical-clustering.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/97/Orange-data-mining-hierarchical-clustering.png/440px-Orange-data-mining-hierarchical-clustering.png 2x" width="220"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Orange-data-mining-hierarchical-clustering.png" title="Enlarge"></a></div>Hierarchical clustering and interactive dendrogram visualization in <a href="/wiki/Orange_(software)" title="Orange (software)">Orange data mining suite</a>.</div></div></div>\n<ul><li><a href="/wiki/ALGLIB" title="ALGLIB">ALGLIB</a> implements several hierarchical clustering algorithms (single-link, complete-link, Ward) in C++ and C# with O(n\xc2\xb2) memory and O(n\xc2\xb3) run time.</li>\n<li><a href="/wiki/ELKI" title="ELKI">ELKI</a> includes multiple hierarchical clustering algorithms, various linkage strategies and also includes the efficient SLINK,<sup class="reference" id="cite_ref-SLINK_3-1"><a href="#cite_note-SLINK-3">[3]</a></sup> CLINK<sup class="reference" id="cite_ref-CLINK_4-1"><a href="#cite_note-CLINK-4">[4]</a></sup> and Anderberg algorithms, flexible cluster extraction from dendrograms and various other <a href="/wiki/Cluster_analysis" title="Cluster analysis">cluster analysis</a> algorithms.</li>\n<li><a href="/wiki/GNU_Octave" title="GNU Octave">Octave</a>, the <a href="/wiki/GNU" title="GNU">GNU</a> analog to <a href="/wiki/MATLAB" title="MATLAB">MATLAB</a> implements hierarchical clustering in function "linkage".</li>\n<li><a href="/wiki/Orange_(software)" title="Orange (software)">Orange</a>, a data mining software suite, includes hierarchical clustering with interactive dendrogram visualisation.</li>\n<li><a href="/wiki/R_(programming_language)" title="R (programming language)">R</a> has many packages that provide functions for hierarchical clustering.</li>\n<li><a href="/wiki/SciPy" title="SciPy">SciPy</a> implements hierarchical clustering in Python, including the efficient SLINK algorithm.</li>\n<li><a href="/wiki/Scikit-learn" title="Scikit-learn">scikit-learn</a> also implements hierarchical clustering in Python.</li>\n<li><a href="/wiki/Weka_(machine_learning)" title="Weka (machine learning)">Weka</a> includes hierarchical cluster analysis.</li></ul>\n<h3><span class="mw-headline" id="Commercial_implementations">Commercial implementations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=9" title="Edit section: Commercial implementations">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<ul><li><a href="/wiki/MathWorks" title="MathWorks">MATLAB</a> includes hierarchical cluster analysis.</li>\n<li><a class="mw-redirect" href="/wiki/SAS_System" title="SAS System">SAS</a> includes hierarchical cluster analysis in PROC CLUSTER.</li>\n<li><a class="mw-redirect" href="/wiki/Mathematica" title="Mathematica">Mathematica</a> includes a Hierarchical Clustering Package.</li>\n<li><a href="/wiki/NCSS_(statistical_software)" title="NCSS (statistical software)">NCSS</a> includes hierarchical cluster analysis.</li>\n<li><a href="/wiki/SPSS" title="SPSS">SPSS</a> includes hierarchical cluster analysis.</li>\n<li><a href="/wiki/Qlucore" title="Qlucore">Qlucore</a> Omics Explorer includes hierarchical cluster analysis.</li>\n<li><a href="/wiki/Stata" title="Stata">Stata</a> includes hierarchical cluster analysis.</li>\n<li><a href="/wiki/CrimeStat" title="CrimeStat">CrimeStat</a> includes a nearest neighbor hierarchical cluster algorithm with a graphical output for a Geographic Information System.</li></ul>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=10" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="div-col columns column-width" style="-moz-column-width: 20em; -webkit-column-width: 20em; column-width: 20em;">\n<ul><li><a href="/wiki/Binary_space_partitioning" title="Binary space partitioning">Binary space partitioning</a></li>\n<li><a href="/wiki/Bounding_volume_hierarchy" title="Bounding volume hierarchy">Bounding volume hierarchy</a></li>\n<li><a href="/wiki/Brown_clustering" title="Brown clustering">Brown clustering</a></li>\n<li><a href="/wiki/Cladistics" title="Cladistics">Cladistics</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Cluster analysis</a></li>\n<li><a href="/wiki/Computational_phylogenetics" title="Computational phylogenetics">Computational phylogenetics</a></li>\n<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE data clustering algorithm</a></li>\n<li><a href="/wiki/Dasgupta%27s_objective" title="Dasgupta\'s objective">Dasgupta\'s objective</a></li>\n<li><a href="/wiki/Dendrogram" title="Dendrogram">Dendrogram</a></li>\n<li><a href="/wiki/Determining_the_number_of_clusters_in_a_data_set" title="Determining the number of clusters in a data set">Determining the number of clusters in a data set</a></li>\n<li><a href="/wiki/Hierarchical_clustering_of_networks" title="Hierarchical clustering of networks">Hierarchical clustering of networks</a></li>\n<li><a href="/wiki/Locality-sensitive_hashing" title="Locality-sensitive hashing">Locality-sensitive hashing</a></li>\n<li><a href="/wiki/Nearest_neighbor_search" title="Nearest neighbor search">Nearest neighbor search</a></li>\n<li><a href="/wiki/Nearest-neighbor_chain_algorithm" title="Nearest-neighbor chain algorithm">Nearest-neighbor chain algorithm</a></li>\n<li><a href="/wiki/Numerical_taxonomy" title="Numerical taxonomy">Numerical taxonomy</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS algorithm</a></li>\n<li><a href="/wiki/Statistical_distance" title="Statistical distance">Statistical distance</a></li>\n<li><a href="/wiki/Persistent_homology" title="Persistent homology">Persistent homology</a></li></ul></div>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=11" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">\n<ol class="references">\n<li id="cite_note-clusteringMethods-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-clusteringMethods_1-0">^</a></b></span> <span class="reference-text">Rokach, Lior, and Oded Maimon. "Clustering methods." Data mining and knowledge discovery handbook. Springer US, 2005. 321-352.</span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFFrank_Nielsen2016">Frank Nielsen (2016). <a class="external text" href="https://www.researchgate.net/publication/314700681" rel="nofollow">"Chapter 8: Hierarchical Clustering"</a>. <a class="external text" href="https://www.springer.com/gp/book/9783319219028" rel="nofollow"><i>Introduction to HPC with MPI for Data Science</i></a>. Springer.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+8%3A+Hierarchical+Clustering&amp;rft.btitle=Introduction+to+HPC+with+MPI+for+Data+Science&amp;rft.pub=Springer&amp;rft.date=2016&amp;rft.au=Frank+Nielsen&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F314700681&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><style data-mw-deduplicate="TemplateStyles:r982806391">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span>\n</li>\n<li id="cite_note-SLINK-3"><span class="mw-cite-backlink">^ <a href="#cite_ref-SLINK_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SLINK_3-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFR._Sibson1973">R. Sibson (1973). <a class="external text" href="http://www.cs.gsu.edu/~wkim/index_files/papers/sibson.pdf" rel="nofollow">"SLINK: an optimally efficient algorithm for the single-link cluster method"</a> <span class="cs1-format">(PDF)</span>. <i>The Computer Journal</i>. British Computer Society. <b>16</b> (1): 30\xe2\x80\x9334. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fcomjnl%2F16.1.30" rel="nofollow">10.1093/comjnl/16.1.30</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Computer+Journal&amp;rft.atitle=SLINK%3A+an+optimally+efficient+algorithm+for+the+single-link+cluster+method&amp;rft.volume=16&amp;rft.issue=1&amp;rft.pages=30-34&amp;rft.date=1973&amp;rft_id=info%3Adoi%2F10.1093%2Fcomjnl%2F16.1.30&amp;rft.au=R.+Sibson&amp;rft_id=http%3A%2F%2Fwww.cs.gsu.edu%2F~wkim%2Findex_files%2Fpapers%2Fsibson.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-CLINK-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-CLINK_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-CLINK_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFD._Defays1977">D. Defays (1977). <a class="external text" href="http://comjnl.oxfordjournals.org/content/20/4/364.abstract" rel="nofollow">"An efficient algorithm for a complete-link method"</a>. <i>The Computer Journal</i>. British Computer Society. <b>20</b> (4): 364\xe2\x80\x93366. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="https://doi.org/10.1093%2Fcomjnl%2F20.4.364" rel="nofollow">10.1093/comjnl/20.4.364</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Computer+Journal&amp;rft.atitle=An+efficient+algorithm+for+a+complete-link+method&amp;rft.volume=20&amp;rft.issue=4&amp;rft.pages=364-366&amp;rft.date=1977&amp;rft_id=info%3Adoi%2F10.1093%2Fcomjnl%2F20.4.364&amp;rft.au=D.+Defays&amp;rft_id=http%3A%2F%2Fcomjnl.oxfordjournals.org%2Fcontent%2F20%2F4%2F364.abstract&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_distance_sect016.htm" rel="nofollow">"The DISTANCE Procedure: Proximity Measures"</a>. <i>SAS/STAT 9.2 Users Guide</i>. <a href="/wiki/SAS_Institute" title="SAS Institute">SAS Institute</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2009-04-26</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=SAS%2FSTAT+9.2+Users+Guide&amp;rft.atitle=The+DISTANCE+Procedure%3A+Proximity+Measures&amp;rft_id=https%3A%2F%2Fsupport.sas.com%2Fdocumentation%2Fcdl%2Fen%2Fstatug%2F63033%2FHTML%2Fdefault%2Fstatug_distance_sect016.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a class="external text" href="https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_cluster_sect012.htm" rel="nofollow">"The CLUSTER Procedure: Clustering Methods"</a>. <i>SAS/STAT 9.2 Users Guide</i>. <a href="/wiki/SAS_Institute" title="SAS Institute">SAS Institute</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2009-04-26</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=SAS%2FSTAT+9.2+Users+Guide&amp;rft.atitle=The+CLUSTER+Procedure%3A+Clustering+Methods&amp;rft_id=https%3A%2F%2Fsupport.sas.com%2Fdocumentation%2Fcdl%2Fen%2Fstatug%2F63033%2FHTML%2Fdefault%2Fstatug_cluster_sect012.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFSz\xc3\xa9kelyRizzo2005">Sz\xc3\xa9kely, G. J.; Rizzo, M. L. (2005). "Hierarchical clustering via Joint Between-Within Distances: Extending Ward\'s Minimum Variance Method". <i>Journal of Classification</i>. <b>22</b> (2): 151\xe2\x80\x93183. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs00357-005-0012-9" rel="nofollow">10.1007/s00357-005-0012-9</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Classification&amp;rft.atitle=Hierarchical+clustering+via+Joint+Between-Within+Distances%3A+Extending+Ward%27s+Minimum+Variance+Method&amp;rft.volume=22&amp;rft.issue=2&amp;rft.pages=151-183&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1007%2Fs00357-005-0012-9&amp;rft.aulast=Sz%C3%A9kely&amp;rft.aufirst=G.+J.&amp;rft.au=Rizzo%2C+M.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-wards_method-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-wards_method_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-wards_method_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFWard1963">Ward, Joe H. (1963). "Hierarchical Grouping to Optimize an Objective Function". <i>Journal of the American Statistical Association</i>. <b>58</b> (301): 236\xe2\x80\x93244. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.2307%2F2282967" rel="nofollow">10.2307/2282967</a>. <a class="mw-redirect" href="/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>\xc2\xa0<a class="external text" href="//www.jstor.org/stable/2282967" rel="nofollow">2282967</a>. <a class="mw-redirect" href="/wiki/MR_(identifier)" title="MR (identifier)">MR</a>\xc2\xa0<a class="external text" href="//www.ams.org/mathscinet-getitem?mr=0148188" rel="nofollow">0148188</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Hierarchical+Grouping+to+Optimize+an+Objective+Function&amp;rft.volume=58&amp;rft.issue=301&amp;rft.pages=236-244&amp;rft.date=1963&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D0148188&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2282967&amp;rft_id=info%3Adoi%2F10.2307%2F2282967&amp;rft.aulast=Ward&amp;rft.aufirst=Joe+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFZhangWangZhaoTang2012">Zhang, Wei; Wang, Xiaogang; Zhao, Deli; Tang, Xiaoou (2012).  Fitzgibbon, Andrew; Lazebnik, Svetlana; Perona, Pietro; Sato, Yoichi; Schmid, Cordelia (eds.). "Graph Degree Linkage: Agglomerative Clustering on a Directed Graph". <i>Computer Vision \xe2\x80\x93 ECCV 2012</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. <b>7572</b>: 428\xe2\x80\x93441. <a class="mw-redirect" href="/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1208.5092" rel="nofollow">1208.5092</a></span>. <a class="mw-redirect" href="/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2012arXiv1208.5092Z" rel="nofollow">2012arXiv1208.5092Z</a>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2F978-3-642-33718-5_31" rel="nofollow">10.1007/978-3-642-33718-5_31</a>. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/9783642337185" title="Special:BookSources/9783642337185"><bdi>9783642337185</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Vision+%E2%80%93+ECCV+2012&amp;rft.atitle=Graph+Degree+Linkage%3A+Agglomerative+Clustering+on+a+Directed+Graph&amp;rft.volume=7572&amp;rft.pages=428-441&amp;rft.date=2012&amp;rft_id=info%3Aarxiv%2F1208.5092&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-642-33718-5_31&amp;rft_id=info%3Abibcode%2F2012arXiv1208.5092Z&amp;rft.isbn=9783642337185&amp;rft.aulast=Zhang&amp;rft.aufirst=Wei&amp;rft.au=Wang%2C+Xiaogang&amp;rft.au=Zhao%2C+Deli&amp;rft.au=Tang%2C+Xiaoou&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/> See also: <a class="external free" href="https://github.com/waynezhanghk/gacluster" rel="nofollow">https://github.com/waynezhanghk/gacluster</a></span>\n</li>\n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text">Zhang, et al. "Agglomerative clustering via maximum incremental path integral." Pattern Recognition (2013).</span>\n</li>\n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">Zhao, and Tang. "Cyclizing clusters via zeta function of a graph."Advances in Neural Information Processing Systems. 2008.</span>\n</li>\n<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text">Ma, et al. "Segmentation of multivariate mixed data via lossy data coding and compression." IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(9) (2007): 1546-1562.</span>\n</li>\n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal cs1" id="CITEREFFern\xc3\xa1ndezG\xc3\xb3mez2008">Fern\xc3\xa1ndez, Alberto; G\xc3\xb3mez, Sergio (2008). "Solving Non-uniqueness in Agglomerative Hierarchical Clustering Using Multidendrograms". <i>Journal of Classification</i>. <b>25</b> (1): 43\xe2\x80\x9365. <a class="mw-redirect" href="/wiki/ArXiv_(identifier)" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/cs/0608049" rel="nofollow">cs/0608049</a></span>. <a class="mw-redirect" href="/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs00357-008-9004-x" rel="nofollow">10.1007/s00357-008-9004-x</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Classification&amp;rft.atitle=Solving+Non-uniqueness+in+Agglomerative+Hierarchical+Clustering+Using+Multidendrograms&amp;rft.volume=25&amp;rft.issue=1&amp;rft.pages=43-65&amp;rft.date=2008&amp;rft_id=info%3Aarxiv%2Fcs%2F0608049&amp;rft_id=info%3Adoi%2F10.1007%2Fs00357-008-9004-x&amp;rft.aulast=Fern%C3%A1ndez&amp;rft.aufirst=Alberto&amp;rft.au=G%C3%B3mez%2C+Sergio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFLegendreLegendre2003">Legendre, P.; Legendre, L. (2003). <i>Numerical Ecology</i>. Elsevier Science BV.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Numerical+Ecology&amp;rft.pub=Elsevier+Science+BV&amp;rft.date=2003&amp;rft.aulast=Legendre&amp;rft.aufirst=P.&amp;rft.au=Legendre%2C+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text">Kaufman, L., &amp; Roussew, P. J. (1990). Finding Groups in Data - An Introduction to Cluster Analysis. A Wiley-Science Publication John Wiley &amp; Sons.</span>\n</li>\n</ol></div>\n<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Hierarchical_clustering&amp;action=edit&amp;section=12" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><cite class="citation book cs1" id="CITEREFKaufmanRousseeuw1990">Kaufman, L.; Rousseeuw, P.J. (1990). <span class="cs1-lock-registration" title="Free registration required"><a class="external text" href="https://archive.org/details/findinggroupsind00kauf" rel="nofollow"><i>Finding Groups in Data: An Introduction to Cluster Analysis</i></a></span> (1 ed.). New York: John Wiley. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/0-471-87876-6" title="Special:BookSources/0-471-87876-6"><bdi>0-471-87876-6</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Finding+Groups+in+Data%3A+An+Introduction+to+Cluster+Analysis&amp;rft.place=New+York&amp;rft.edition=1&amp;rft.pub=John+Wiley&amp;rft.date=1990&amp;rft.isbn=0-471-87876-6&amp;rft.aulast=Kaufman&amp;rft.aufirst=L.&amp;rft.au=Rousseeuw%2C+P.J.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Ffindinggroupsind00kauf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></li>\n<li><cite class="citation book cs1" id="CITEREFHastieTibshiraniFriedman2009"><a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Hastie, Trevor</a>; <a href="/wiki/Robert_Tibshirani" title="Robert Tibshirani">Tibshirani, Robert</a>; Friedman, Jerome (2009). <a class="external text" href="https://web.archive.org/web/20091110212529/http://www-stat.stanford.edu/~tibs/ElemStatLearn/" rel="nofollow">"14.3.12 Hierarchical clustering"</a>. <i>The Elements of Statistical Learning</i> (2nd ed.). New York: Springer. pp.\xc2\xa0520\xe2\x80\x93528. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-387-84857-0" title="Special:BookSources/978-0-387-84857-0"><bdi>978-0-387-84857-0</bdi></a>. Archived from <a class="external text" href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/" rel="nofollow">the original</a> <span class="cs1-format">(PDF)</span> on 2009-11-10<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-10-20</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=14.3.12+Hierarchical+clustering&amp;rft.btitle=The+Elements+of+Statistical+Learning&amp;rft.place=New+York&amp;rft.pages=520-528&amp;rft.edition=2nd&amp;rft.pub=Springer&amp;rft.date=2009&amp;rft.isbn=978-0-387-84857-0&amp;rft.aulast=Hastie&amp;rft.aufirst=Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft.au=Friedman%2C+Jerome&amp;rft_id=http%3A%2F%2Fwww-stat.stanford.edu%2F~tibs%2FElemStatLearn%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHierarchical+clustering"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></li></ul>\n<!-- \nNewPP limit report\nParsed by mw1268\nCached time: 20201029221205\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.348 seconds\nReal time usage: 0.517 seconds\nPreprocessor visited node count: 1407/1000000\nPost\xe2\x80\x90expand include size: 53763/2097152 bytes\nTemplate argument size: 1956/2097152 bytes\nHighest expansion depth: 12/40\nExpensive parser function count: 2/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 41281/5000000 bytes\nLua time usage: 0.140/10.000 seconds\nLua memory usage: 4.58 MB/50 MB\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  351.722      1 -total\n 38.28%  134.655      1 Template:Reflist\n 24.39%   85.768      4 Template:Cite_book\n 15.26%   53.668      1 Template:Short_description\n 12.41%   43.651      1 Template:Redirect\n 11.16%   39.240      1 Template:Machine_learning_bar\n 10.91%   38.375      1 Template:Citation_needed\n  9.89%   34.772      1 Template:Sidebar_with_collapsible_lists\n  9.00%   31.671      6 Template:Cite_journal\n  8.78%   30.887      1 Template:Fix\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:477573-0!canonical!math=5 and timestamp 20201029221205 and revision id 982368331\n -->\n</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript>\n<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Hierarchical_clustering&amp;oldid=982368331">https://en.wikipedia.org/w/index.php?title=Hierarchical_clustering&amp;oldid=982368331</a>"</div></div>\n<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Network_analysis" title="Category:Network analysis">Network analysis</a></li><li><a href="/wiki/Category:Cluster_analysis_algorithms" title="Category:Cluster analysis algorithms">Cluster analysis algorithms</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_April_2009" title="Category:Articles with unsourced statements from April 2009">Articles with unsourced statements from April 2009</a></li></ul></div></div>\n</div>\n</div>\n<div id="mw-data-after-content">\n<div class="read-more-container"></div>\n</div>\n<div id="mw-navigation">\n<h2>Navigation menu</h2>\n<div id="mw-head">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-personal-label" class="mw-portlet mw-portlet-personal vector-menu" id="p-personal" role="navigation">\n<h3 id="p-personal-label">\n<span>Personal tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Hierarchical+clustering" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Hierarchical+clustering" title="You\'re encouraged to log in; however, it\'s not mandatory. [o]">Log in</a></li></ul>\n</div>\n</nav>\n<div id="left-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-namespaces-label" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" id="p-namespaces" role="navigation">\n<h3 id="p-namespaces-label">\n<span>Namespaces</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Hierarchical_clustering" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Hierarchical_clustering" rel="discussion" title="Discuss improvements to the content page [t]">Talk</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-variants-label" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" id="p-variants" role="navigation">\n<input aria-labelledby="p-variants-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-variants-label">\n<span>Variants</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n</div>\n<div id="right-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-views-label" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" id="p-views" role="navigation">\n<h3 id="p-views-label">\n<span>Views</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-view"><a href="/wiki/Hierarchical_clustering">Read</a></li><li id="ca-edit"><a accesskey="e" href="/w/index.php?title=Hierarchical_clustering&amp;action=edit" title="Edit this page [e]">Edit</a></li><li id="ca-history"><a accesskey="h" href="/w/index.php?title=Hierarchical_clustering&amp;action=history" title="Past revisions of this page [h]">View history</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-cactions-label" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" id="p-cactions" role="navigation">\n<input aria-labelledby="p-cactions-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-cactions-label">\n<span>More</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n<div id="p-search" role="search">\n<h3>\n<label for="searchInput">Search</label>\n</h3>\n<form action="/w/index.php" id="searchform">\n<div data-search-loc="header-navigation" id="simpleSearch">\n<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>\n<input name="title" type="hidden" value="Special:Search"/>\n<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search">\n<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>\n</input></div>\n</form>\n</div>\n</div>\n</div>\n<div id="mw-panel">\n<div id="p-logo" role="banner">\n<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>\n</div>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-navigation-label" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal portal-first" id="p-navigation" role="navigation">\n<h3 id="p-navigation-label">\n<span>Navigation</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Visit a randomly selected article [x]">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-interaction-label" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" id="p-interaction" role="navigation">\n<h3 id="p-interaction-label">\n<span>Contribute</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-tb-label" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" id="p-tb" role="navigation">\n<h3 id="p-tb-label">\n<span>Tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Hierarchical_clustering" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Hierarchical_clustering" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Hierarchical_clustering&amp;oldid=982368331" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Hierarchical_clustering&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Hierarchical_clustering&amp;id=982368331&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1277447" title="Structured data on this page hosted by Wikidata [g]">Wikidata item</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-coll-print_export-label" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" id="p-coll-print_export" role="navigation">\n<h3 id="p-coll-print_export-label">\n<span>Print/export</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Hierarchical_clustering&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Hierarchical_clustering&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-wikibase-otherprojects-label" class="mw-portlet mw-portlet-wikibase-otherprojects vector-menu vector-menu-portal portal" id="p-wikibase-otherprojects" role="navigation">\n<h3 id="p-wikibase-otherprojects-label">\n<span>In other projects</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Hierarchical_clustering" hreflang="en">Wikimedia Commons</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-lang-label" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" id="p-lang" role="navigation">\n<h3 id="p-lang-label">\n<span>Languages</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-ar"><a class="interlanguage-link-target" href="https://ar.wikipedia.org/wiki/%D8%AA%D8%AC%D9%85%D9%8A%D8%B9_%D9%87%D8%B1%D9%85%D9%8A" hreflang="ar" lang="ar" title="\xd8\xaa\xd8\xac\xd9\x85\xd9\x8a\xd8\xb9 \xd9\x87\xd8\xb1\xd9\x85\xd9\x8a \xe2\x80\x93 Arabic">\xd8\xa7\xd9\x84\xd8\xb9\xd8\xb1\xd8\xa8\xd9\x8a\xd8\xa9</a></li><li class="interlanguage-link interwiki-cs"><a class="interlanguage-link-target" href="https://cs.wikipedia.org/wiki/Hierarchick%C3%A9_shlukov%C3%A1n%C3%AD" hreflang="cs" lang="cs" title="Hierarchick\xc3\xa9 shlukov\xc3\xa1n\xc3\xad \xe2\x80\x93 Czech">\xc4\x8ce\xc5\xa1tina</a></li><li class="interlanguage-link interwiki-de"><a class="interlanguage-link-target" href="https://de.wikipedia.org/wiki/Hierarchische_Clusteranalyse" hreflang="de" lang="de" title="Hierarchische Clusteranalyse \xe2\x80\x93 German">Deutsch</a></li><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico" hreflang="es" lang="es" title="Agrupamiento jer\xc3\xa1rquico \xe2\x80\x93 Spanish">Espa\xc3\xb1ol</a></li><li class="interlanguage-link interwiki-eu"><a class="interlanguage-link-target" href="https://eu.wikipedia.org/wiki/Multzokatze_hierarkiko" hreflang="eu" lang="eu" title="Multzokatze hierarkiko \xe2\x80\x93 Basque">Euskara</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%D8%AE%D9%88%D8%B4%D9%87%E2%80%8C%D8%A8%D9%86%D8%AF%DB%8C_%D8%B3%D9%84%D8%B3%D9%84%D9%87%E2%80%8C%D9%85%D8%B1%D8%A7%D8%AA%D8%A8%DB%8C" hreflang="fa" lang="fa" title="\xd8\xae\xd9\x88\xd8\xb4\xd9\x87\xe2\x80\x8c\xd8\xa8\xd9\x86\xd8\xaf\xdb\x8c \xd8\xb3\xd9\x84\xd8\xb3\xd9\x84\xd9\x87\xe2\x80\x8c\xd9\x85\xd8\xb1\xd8\xa7\xd8\xaa\xd8\xa8\xdb\x8c \xe2\x80\x93 Persian">\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique" hreflang="fr" lang="fr" title="Regroupement hi\xc3\xa9rarchique \xe2\x80\x93 French">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-it"><a class="interlanguage-link-target" href="https://it.wikipedia.org/wiki/Clustering_gerarchico" hreflang="it" lang="it" title="Clustering gerarchico \xe2\x80\x93 Italian">Italiano</a></li><li class="interlanguage-link interwiki-pl"><a class="interlanguage-link-target" href="https://pl.wikipedia.org/wiki/Grupowanie_hierarchiczne" hreflang="pl" lang="pl" title="Grupowanie hierarchiczne \xe2\x80\x93 Polish">Polski</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F" hreflang="ru" lang="ru" title="\xd0\x98\xd0\xb5\xd1\x80\xd0\xb0\xd1\x80\xd1\x85\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd0\xba\xd0\xb0\xd1\x8f \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd0\xb8\xd1\x8f \xe2\x80\x93 Russian">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%86%D1%94%D1%80%D0%B0%D1%80%D1%85%D1%96%D1%87%D0%BD%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D1%96%D1%8F" hreflang="uk" lang="uk" title="\xd0\x86\xd1\x94\xd1\x80\xd0\xb0\xd1\x80\xd1\x85\xd1\x96\xd1\x87\xd0\xbd\xd0\xb0 \xd0\xba\xd0\xbb\xd0\xb0\xd1\x81\xd1\x82\xd0\xb5\xd1\x80\xd0\xb8\xd0\xb7\xd0\xb0\xd1\x86\xd1\x96\xd1\x8f \xe2\x80\x93 Ukrainian">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li></ul>\n<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1277447#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>\n</div>\n</nav>\n</div>\n</div>\n<footer class="mw-footer" id="footer" role="contentinfo">\n<ul id="footer-info">\n<li id="footer-info-lastmod"> This page was last edited on 7 October 2020, at 18:21<span class="anonymous-show">\xc2\xa0(UTC)</span>.</li>\n<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id="footer-places">\n<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>\n<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Hierarchical_clustering&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>\n<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>\n<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n</ul>\n<ul class="noprint" id="footer-icons">\n<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" loading="lazy" src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88"/></a></li>\n<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" loading="lazy" src="/static/images/footer/poweredby_mediawiki_88x31.png" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>\n</ul>\n<div style="clear: both;"></div>\n</footer>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.348","walltime":"0.517","ppvisitednodes":{"value":1407,"limit":1000000},"postexpandincludesize":{"value":53763,"limit":2097152},"templateargumentsize":{"value":1956,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":2,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":41281,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  351.722      1 -total"," 38.28%  134.655      1 Template:Reflist"," 24.39%   85.768      4 Template:Cite_book"," 15.26%   53.668      1 Template:Short_description"," 12.41%   43.651      1 Template:Redirect"," 11.16%   39.240      1 Template:Machine_learning_bar"," 10.91%   38.375      1 Template:Citation_needed","  9.89%   34.772      1 Template:Sidebar_with_collapsible_lists","  9.00%   31.671      6 Template:Cite_journal","  8.78%   30.887      1 Template:Fix"]},"scribunto":{"limitreport-timeusage":{"value":"0.140","limit":"10.000"},"limitreport-memusage":{"value":4806068,"limit":52428800}},"cachereport":{"origin":"mw1268","timestamp":"20201029221205","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Hierarchical clustering","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Hierarchical_clustering","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q1277447","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q1277447","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2004-02-20T01:38:40Z","dateModified":"2020-10-07T18:21:32Z","headline":"method of cluster analysis which seeks to build a hierarchy of clusters"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":148,"wgHostname":"mw1320"});});</script>\n</body></html>'