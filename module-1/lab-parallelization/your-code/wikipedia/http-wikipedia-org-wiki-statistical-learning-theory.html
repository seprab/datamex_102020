b'<!DOCTYPE html>\n\n<html class="client-nojs" dir="ltr" lang="en">\n<head>\n<meta charset="utf8"/>\n<title>Statistical learning theory - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"bb2a39ff-6749-476d-95e9-e760b217eaff","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Statistical_learning_theory","wgTitle":"Statistical learning theory","wgCurRevisionId":967208509,"wgRevisionId":967208509,"wgArticleId":1053303,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Machine learning","Estimation theory"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Statistical_learning_theory","wgRelevantArticleId":1053303,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[\n],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q7604400"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.styles.legacy":"ready","mediawiki.toc.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready",\n"ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta content="" name="ResourceLoaderDynamicStyles"/>\n<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>\n<meta content="MediaWiki 1.36.0-wmf.14" name="generator"/>\n<meta content="origin" name="referrer"/>\n<meta content="origin-when-crossorigin" name="referrer"/>\n<meta content="origin-when-cross-origin" name="referrer"/>\n<link href="//en.m.wikipedia.org/wiki/Statistical_learning_theory" media="only screen and (max-width: 720px)" rel="alternate"/>\n<link href="/w/index.php?title=Statistical_learning_theory&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>\n<link href="/w/index.php?title=Statistical_learning_theory&amp;action=edit" rel="edit" title="Edit this page"/>\n<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>\n<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>\n<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>\n<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>\n<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>\n<link href="https://en.wikipedia.org/wiki/Statistical_learning_theory" rel="canonical"/>\n<link href="//login.wikimedia.org" rel="dns-prefetch"/>\n<link href="//meta.wikimedia.org" rel="dns-prefetch"/>\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Statistical_learning_theory rootpage-Statistical_learning_theory skin-vector action-view skin-vector-legacy"><div class="noprint" id="mw-page-base"></div>\n<div class="noprint" id="mw-head-base"></div>\n<div class="mw-body" id="content" role="main">\n<a id="top"></a>\n<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>\n<div class="mw-indicators mw-body-content">\n</div>\n<h1 class="firstHeading" id="firstHeading" lang="en">Statistical learning theory</h1>\n<div class="mw-body-content" id="bodyContent">\n<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>\n<div id="contentSub"></div>\n<div id="contentSub2"></div>\n<div id="jump-to-nav"></div>\n<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n<a class="mw-jump-link" href="#searchInput">Jump to search</a>\n<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="hatnote navigation-not-searchable" role="note">This article is about statistical learning in machine learning. For its use in psychology, see <a href="/wiki/Statistical_learning_in_language_acquisition" title="Statistical learning in language acquisition">Statistical learning in language acquisition</a>.</div>\n<div class="hatnote navigation-not-searchable" role="note">See also: <a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></div>\n<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><td style="padding-top:0.4em;line-height:1.2em">Part of a series on</td></tr><tr><th style="padding:0.2em 0.4em 0.2em;padding-top:0;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a><br/>and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="display:inline-block; padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>\xc2\xa0\xe2\x80\xa2 <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a class="mw-redirect" href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li>\n<li><a href="/wiki/Echo_state_network" title="Echo state network">ESN</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li>\n<li><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a class="mw-selflink selflink">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<p><b>Statistical learning theory</b> is a framework for <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>\ndrawing from the fields of <a href="/wiki/Statistics" title="Statistics">statistics</a> and <a href="/wiki/Functional_analysis" title="Functional analysis">functional analysis</a>.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup><sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> Statistical learning theory deals with the problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a>, <a href="/wiki/Speech_recognition" title="Speech recognition">speech recognition</a>, and <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a>.\n</p>\n<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Introduction"><span class="tocnumber">1</span> <span class="toctext">Introduction</span></a></li>\n<li class="toclevel-1 tocsection-2"><a href="#Formal_description"><span class="tocnumber">2</span> <span class="toctext">Formal description</span></a></li>\n<li class="toclevel-1 tocsection-3"><a href="#Loss_functions"><span class="tocnumber">3</span> <span class="toctext">Loss functions</span></a>\n<ul>\n<li class="toclevel-2 tocsection-4"><a href="#Regression"><span class="tocnumber">3.1</span> <span class="toctext">Regression</span></a></li>\n<li class="toclevel-2 tocsection-5"><a href="#Classification"><span class="tocnumber">3.2</span> <span class="toctext">Classification</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-6"><a href="#Regularization"><span class="tocnumber">4</span> <span class="toctext">Regularization</span></a></li>\n<li class="toclevel-1 tocsection-7"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-8"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>\n</ul>\n</div>\n<h2><span class="mw-headline" id="Introduction">Introduction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=1" title="Edit section: Introduction">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The goals of learning are understanding and prediction. Learning falls into many categories, including <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>, <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a>, <a href="/wiki/Online_machine_learning" title="Online machine learning">online learning</a>, and <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>. From the perspective of statistical learning theory, supervised learning is best understood.<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> Supervised learning involves learning from a <a class="mw-redirect" href="/wiki/Training_set" title="Training set">training set</a> of data. Every point in the training is an input-output pair, where the input maps to an output. The learning problem consists of inferring the function that maps between the input and the output, such that the learned function can be used to predict the output from future input.\n</p><p>Depending on the type of output, supervised learning problems are either problems of <a href="/wiki/Regression_analysis" title="Regression analysis">regression</a> or problems of <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>. If the output takes a continuous range of values, it is a regression problem. Using <a class="mw-redirect" href="/wiki/Ohm%27s_Law" title="Ohm\'s Law">Ohm\'s Law</a> as an example, a regression could be performed with voltage as input and current as an output. The regression would find the functional relationship between voltage and current to be <span class="nowrap"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle R}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>R</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle R}</annotation>\n</semantics>\n</math></span><img alt="R" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b0bfb3769bf24d80e15374dc37b0441e2616e33" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;"/></span></span>, such that\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle V=IR}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>V</mi>\n<mo>=</mo>\n<mi>I</mi>\n<mi>R</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle V=IR}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle V=IR}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3604da12028748671ffe4d4feef5d28092d455dc" style="vertical-align: -0.338ex; width:7.821ex; height:2.176ex;"/></span></dd></dl>\n<p>Classification problems are those for which the output will be an element from a discrete set of labels. Classification is very common for machine learning applications. In <a href="/wiki/Facial_recognition_system" title="Facial recognition system">facial recognition</a>, for instance, a picture of a person\'s face would be the input, and the output label would be that person\'s name. The input would be represented by a large multidimensional vector whose elements represent pixels in the picture.\n</p><p>After learning a function based on the training set data, that function is validated on a test set of data, data that did not appear in the training set.\n</p>\n<h2><span class="mw-headline" id="Formal_description">Formal description</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=2" title="Edit section: Formal description">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Take <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>X</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n</semantics>\n</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span> to be the <a href="/wiki/Vector_space" title="Vector space">vector space</a> of all possible inputs, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n</semantics>\n</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span> to be\nthe vector space of all possible outputs. Statistical learning theory takes the perspective that there is some unknown <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> over the product space <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Z=X\\times Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Z</mi>\n<mo>=</mo>\n<mi>X</mi>\n<mo>\xc3\x97<!-- \xc3\x97 --></mo>\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Z=X\\times Y}</annotation>\n</semantics>\n</math></span><img alt="Z = X \\times Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c8af2c76ff03cd3f68caf3caeb6792ee1f7f0898" style="vertical-align: -0.338ex; width:11.373ex; height:2.176ex;"/></span>, i.e. there exists some unknown <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p(z)=p({\\vec {x}},y)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mi>z</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p(z)=p({\\vec {x}},y)}</annotation>\n</semantics>\n</math></span><img alt="p(z)=p({\\vec  {x}},y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f39df3dba644c278439cea9c931fb328ab202014" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:13.753ex; height:2.843ex;"/></span>. The training set is made up of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>n</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle n}</annotation>\n</semantics>\n</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> samples from this probability distribution, and is notated \n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle S=\\{({\\vec {x}}_{1},y_{1}),\\dots ,({\\vec {x}}_{n},y_{n})\\}=\\{{\\vec {z}}_{1},\\dots ,{\\vec {z}}_{n}\\}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>S</mi>\n<mo>=</mo>\n<mo fence="false" stretchy="false">{</mo>\n<mo stretchy="false">(</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<mo stretchy="false">(</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo fence="false" stretchy="false">}</mo>\n<mo>=</mo>\n<mo fence="false" stretchy="false">{</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>z</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>1</mn>\n</mrow>\n</msub>\n<mo>,</mo>\n<mo>\xe2\x80\xa6<!-- \xe2\x80\xa6 --></mo>\n<mo>,</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>z</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</msub>\n<mo fence="false" stretchy="false">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle S=\\{({\\vec {x}}_{1},y_{1}),\\dots ,({\\vec {x}}_{n},y_{n})\\}=\\{{\\vec {z}}_{1},\\dots ,{\\vec {z}}_{n}\\}}</annotation>\n</semantics>\n</math></span><img alt="S=\\{({\\vec  {x}}_{1},y_{1}),\\dots ,({\\vec  {x}}_{n},y_{n})\\}=\\{{\\vec  {z}}_{1},\\dots ,{\\vec  {z}}_{n}\\}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/96193cc7296413d9547ecf9226fef229147553fd" style="vertical-align: -0.838ex; width:42.6ex; height:2.843ex;"/></span></dd></dl>\n<p>Every <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\vec {x}}_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\vec {x}}_{i}}</annotation>\n</semantics>\n</math></span><img alt="{\\vec {x}}_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/97dc64e456d28b08c449ec343111cc5c3ce39f72" style="vertical-align: -0.671ex; width:2.129ex; height:2.676ex;"/></span> is an input vector from the training data, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y_{i}}</annotation>\n</semantics>\n</math></span><img alt="y_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;"/></span>\nis the output that corresponds to it.\n</p><p>In this formalism, the inference problem consists of finding a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f:X\\to Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n<mo>:</mo>\n<mi>X</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f:X\\to Y}</annotation>\n</semantics>\n</math></span><img alt="f:X\\to Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/abd1e080abef4bbdab67b43819c6431e7561361c" style="vertical-align: -0.671ex; width:10.583ex; height:2.509ex;"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f({\\vec {x}})\\sim y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>\xe2\x88\xbc<!-- \xe2\x88\xbc --></mo>\n<mi>y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f({\\vec {x}})\\sim y}</annotation>\n</semantics>\n</math></span><img alt="f({\\vec  {x}})\\sim y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6f6d2201a45b4626332d3ec00e7bcd3abdeac4e" style="vertical-align: -0.838ex; width:8.672ex; height:2.843ex;"/></span>. Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> be a space of functions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f:X\\to Y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n<mo>:</mo>\n<mi>X</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n<mi>Y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f:X\\to Y}</annotation>\n</semantics>\n</math></span><img alt="f:X\\to Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/abd1e080abef4bbdab67b43819c6431e7561361c" style="vertical-align: -0.671ex; width:10.583ex; height:2.509ex;"/></span> called the hypothesis space. The hypothesis space is the space of functions the algorithm will search through. Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle V(f({\\vec {x}}),y)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)}</annotation>\n</semantics>\n</math></span><img alt="V(f({\\vec  {x}}),y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f4858385026efb76bd83a1a5d640cecaee985" style="vertical-align: -0.838ex; width:10.204ex; height:2.843ex;"/></span> be the <a href="/wiki/Loss_function" title="Loss function">loss function</a>, a metric for the difference between the predicted value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f({\\vec {x}})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f({\\vec {x}})}</annotation>\n</semantics>\n</math></span><img alt="f({\\vec {x}})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/546ff1db2de71c7abcb09ef533f42dad5e89bf19" style="vertical-align: -0.838ex; width:4.418ex; height:2.843ex;"/></span> and the actual value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle y}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>y</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n</semantics>\n</math></span><img alt="y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;"/></span>. The <a class="new" href="/w/index.php?title=Expected_risk&amp;action=edit&amp;redlink=1" title="Expected risk (page does not exist)">expected risk</a> is defined to be\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>I</mi>\n<mo stretchy="false">[</mo>\n<mi>f</mi>\n<mo stretchy="false">]</mo>\n<mo>=</mo>\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mo>\xe2\x88\xab<!-- \xe2\x88\xab --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>X</mi>\n<mo>\xc3\x97<!-- \xc3\x97 --></mo>\n<mi>Y</mi>\n</mrow>\n</msub>\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mspace width="thinmathspace"></mspace>\n<mi>d</mi>\n<mi>y</mi>\n</mstyle>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c97de659352fa60d6624a1f54f4d3f0b32c73af" style="vertical-align: -2.338ex; width:35.466ex; height:5.676ex;"/></span></dd></dl>\n<p>The target function, the best possible function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n</semantics>\n</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> that can be\nchosen, is given by the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n</semantics>\n</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> that satisfies\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>f</mi>\n<mo>=</mo>\n<munder>\n<mo form="prefix" movablelimits="true">inf</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>h</mi>\n<mo>\xe2\x88\x88<!-- \xe2\x88\x88 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mrow>\n</munder>\n<mi>I</mi>\n<mo stretchy="false">[</mo>\n<mi>h</mi>\n<mo stretchy="false">]</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/47c982d6049c9ce70930b327589b5ff00915406f" style="vertical-align: -2.171ex; width:12ex; height:4.176ex;"/></span></dd></dl>\n<p>Because the probability distribution <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p({\\vec {x}},y)}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p({\\vec {x}},y)}</annotation>\n</semantics>\n</math></span><img alt="p({\\vec  {x}},y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1595e98c5caecb110c42a3b688b2e2c294220fa9" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.587ex; height:2.843ex;"/></span> is unknown, a\nproxy measure for the expected risk must be used. This measure is based on the training set, a sample from this unknown probability distribution. It is called the <a class="new" href="/w/index.php?title=Empirical_risk&amp;action=edit&amp;redlink=1" title="Empirical risk (page does not exist)">empirical risk</a>\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle I_{S}[f]={\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>I</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>S</mi>\n</mrow>\n</msub>\n<mo stretchy="false">[</mo>\n<mi>f</mi>\n<mo stretchy="false">]</mo>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<mi>n</mi>\n</mfrac>\n</mrow>\n<mstyle displaystyle="true" scriptlevel="0">\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</munderover>\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle I_{S}[f]={\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})}</annotation>\n</semantics>\n</math></span><img alt="I_{S}[f]={\\frac  {1}{n}}\\displaystyle \\sum _{{i=1}}^{n}V(f({\\vec  {x}}_{i}),y_{i})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0418e949bbea67e3cdbe4455429c3af2c3f09781" style="vertical-align: -3.005ex; width:26.133ex; height:6.843ex;"/></span></dd></dl>\n<p>A learning algorithm that chooses the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f_{S}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>S</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f_{S}}</annotation>\n</semantics>\n</math></span><img alt="f_S" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b44c97f83aebb50c3fd26b567ff9b005dc7b82b" style="vertical-align: -0.671ex; width:2.432ex; height:2.509ex;"/></span> that minimizes\nthe empirical risk is called <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk minimization</a>.\n</p>\n<h2><span class="mw-headline" id="Loss_functions">Loss functions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=3" title="Edit section: Loss functions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The choice of loss function is a determining factor on the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle f_{S}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<msub>\n<mi>f</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>S</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle f_{S}}</annotation>\n</semantics>\n</math></span><img alt="f_S" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b44c97f83aebb50c3fd26b567ff9b005dc7b82b" style="vertical-align: -0.671ex; width:2.432ex; height:2.509ex;"/></span> that will be chosen by the learning algorithm. The loss function\nalso affects the convergence rate for an algorithm. It is important for the loss function to be convex.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>\n</p><p>Different loss functions are used depending on whether the problem is\none of regression or one of classification.\n</p>\n<h3><span class="mw-headline" id="Regression">Regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=4" title="Edit section: Regression">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The most common loss function for regression is the square loss function (also known as the <a class="mw-redirect" href="/wiki/L2-norm" title="L2-norm">L2-norm</a>). This familiar loss function is used in <a class="new" href="/w/index.php?title=Ordinary_Least_Squares_regression&amp;action=edit&amp;redlink=1" title="Ordinary Least Squares regression (page does not exist)">Ordinary Least Squares regression</a>. The form is:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle V(f({\\vec {x}}),y)=(y-f({\\vec {x}}))^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mo stretchy="false">(</mo>\n<mi>y</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<msup>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=(y-f({\\vec {x}}))^{2}}</annotation>\n</semantics>\n</math></span><img alt="V(f({\\vec  {x}}),y)=(y-f({\\vec  {x}}))^{2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c971ef7591ca3bc4c5d7642d8f90369b29992a53" style="vertical-align: -0.838ex; width:24.579ex; height:3.176ex;"/></span></dd></dl>\n<p>The absolute value loss (also known as the <a class="mw-redirect" href="/wiki/L1-norm" title="L1-norm">L1-norm</a>) is also sometimes used:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle V(f({\\vec {x}}),y)=|y-f({\\vec {x}})|}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n<mi>y</mi>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mo stretchy="false">|</mo>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=|y-f({\\vec {x}})|}</annotation>\n</semantics>\n</math></span><img alt="V(f({\\vec  {x}}),y)=|y-f({\\vec  {x}})|" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9c353d1b2ca9828d0ab260278ba4b914e308cdd" style="vertical-align: -0.838ex; width:23.009ex; height:2.843ex;"/></span></dd></dl>\n<h3><span class="mw-headline" id="Classification">Classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=5" title="Edit section: Classification">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div class="hatnote navigation-not-searchable" role="note">Main article: <a href="/wiki/Statistical_classification" title="Statistical classification">Statistical classification</a></div>\n<p>In some sense the 0-1 <a href="/wiki/Indicator_function" title="Indicator function">indicator function</a> is the most natural loss function for classification. It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output. For binary classification with <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle Y=\\{-1,1\\}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>Y</mi>\n<mo>=</mo>\n<mo fence="false" stretchy="false">{</mo>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mn>1</mn>\n<mo>,</mo>\n<mn>1</mn>\n<mo fence="false" stretchy="false">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle Y=\\{-1,1\\}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle Y=\\{-1,1\\}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4916f8d7711119d44385e1d2f628cc139de2c953" style="vertical-align: -0.838ex; width:12.364ex; height:2.843ex;"/></span>, this is:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<mi>y</mi>\n<mo stretchy="false">)</mo>\n<mo>=</mo>\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n<mo stretchy="false">(</mo>\n<mo>\xe2\x88\x92<!-- \xe2\x88\x92 --></mo>\n<mi>y</mi>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mo stretchy="false">)</mo>\n<mo stretchy="false">)</mo>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6aed24bedecfd114ed5bc77e5fdb1f36537d9330" style="vertical-align: -0.838ex; width:23.583ex; height:2.843ex;"/></span></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\theta }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xce\xb8<!-- \xce\xb8 --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n</semantics>\n</math></span><img alt="\\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span> is the <a href="/wiki/Heaviside_step_function" title="Heaviside step function">Heaviside step function</a>.\n</p>\n<h2><span class="mw-headline" id="Regularization">Regularization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=6" title="Edit section: Regularization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a class="image" href="/wiki/File:Overfitting_on_Training_Set_Data.pdf"><img alt="" class="thumbimage" data-file-height="743" data-file-width="760" decoding="async" height="215" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-220px-Overfitting_on_Training_Set_Data.pdf.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-330px-Overfitting_on_Training_Set_Data.pdf.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-440px-Overfitting_on_Training_Set_Data.pdf.jpg 2x" width="220"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Overfitting_on_Training_Set_Data.pdf" title="Enlarge"></a></div>This image represents an example of overfitting in machine learning. The red dots represent training set data. The green line represents the true functional relationship, while the blue line shows the learned function, which has fallen victim to overfitting.</div></div></div>\n<p>In machine learning problems, a major problem that arises is that of <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>. Because learning is a prediction problem, the goal is not to find a function that most closely fits the (previously observed) data, but to find one that will most accurately predict output from future input. <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a> runs this risk of overfitting: finding a function that matches the data exactly but does not predict future output well.\n</p><p>Overfitting is symptomatic of unstable solutions; a small perturbation in the training set data would cause a large variation in the learned function. It can be shown that if the stability for the solution can be guaranteed, generalization and consistency are guaranteed as well.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup><sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">Regularization</a> can solve the overfitting problem and give\nthe problem stability.\n</p><p>Regularization can be accomplished by restricting the hypothesis space <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span>. A common example would be restricting <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> to linear functions: this can be seen as a reduction to the standard problem of <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> could also be restricted to polynomial of degree <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle p}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>p</mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle p}</annotation>\n</semantics>\n</math></span><img alt="p" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;"/></span>, exponentials, or bounded functions on <a href="/wiki/Lp_space" title="Lp space">L1</a>. Restriction of the hypothesis space avoids overfitting because the form of the potential functions are limited, and so does not allow for the choice of a function that gives empirical risk arbitrarily close to zero.\n</p><p>One example of regularization is <a href="/wiki/Tikhonov_regularization" title="Tikhonov regularization">Tikhonov regularization</a>. This consists of minimizing\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mfrac>\n<mn>1</mn>\n<mi>n</mi>\n</mfrac>\n</mrow>\n<mstyle displaystyle="true" scriptlevel="0">\n<munderover>\n<mo>\xe2\x88\x91<!-- \xe2\x88\x91 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>n</mi>\n</mrow>\n</munderover>\n<mi>V</mi>\n<mo stretchy="false">(</mo>\n<mi>f</mi>\n<mo stretchy="false">(</mo>\n<msub>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mover>\n<mi>x</mi>\n<mo stretchy="false">\xe2\x86\x92<!-- \xe2\x86\x92 --></mo>\n</mover>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>,</mo>\n<msub>\n<mi>y</mi>\n<mrow class="MJX-TeXAtom-ORD">\n<mi>i</mi>\n</mrow>\n</msub>\n<mo stretchy="false">)</mo>\n<mo>+</mo>\n<mi>\xce\xb3<!-- \xce\xb3 --></mi>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mi>f</mi>\n<msubsup>\n<mo fence="false" stretchy="false">\xe2\x80\x96<!-- \xe2\x80\x96 --></mo>\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n<mrow class="MJX-TeXAtom-ORD">\n<mn>2</mn>\n</mrow>\n</msubsup>\n</mstyle>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}</annotation>\n</semantics>\n</math></span><img alt="{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d281a9698fde8d2015871615891a677457d0a4e2" style="vertical-align: -3.005ex; width:27.474ex; height:6.843ex;"/></span></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle \\gamma }" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mi>\xce\xb3<!-- \xce\xb3 --></mi>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle \\gamma }</annotation>\n</semantics>\n</math></span><img alt="\\gamma " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a" style="vertical-align: -0.838ex; width:1.262ex; height:2.176ex;"/></span> is a fixed and positive parameter, the regularization parameter. Tikhonov regularization ensures existence, uniqueness, and stability of the solution.<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>\n</p>\n<div style="clear:both;"></div>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=7" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a class="mw-redirect" href="/wiki/Reproducing_kernel_Hilbert_spaces" title="Reproducing kernel Hilbert spaces">Reproducing kernel Hilbert spaces</a> are a useful choice for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\\displaystyle {\\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">\n<semantics>\n<mrow class="MJX-TeXAtom-ORD">\n<mstyle displaystyle="true" scriptlevel="0">\n<mrow class="MJX-TeXAtom-ORD">\n<mrow class="MJX-TeXAtom-ORD">\n<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n</semantics>\n</math></span><img alt="{\\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span>.</li>\n<li><a href="/wiki/Proximal_gradient_methods_for_learning" title="Proximal gradient methods for learning">Proximal gradient methods for learning</a></li></ul>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=8" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Trevor Hastie</a>, Robert Tibshirani, Jerome Friedman (2009) <i>The Elements of Statistical Learning</i>, Springer-Verlag <style data-mw-deduplicate="TemplateStyles:r982806391">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/978-0-387-84857-0" title="Special:BookSources/978-0-387-84857-0">978-0-387-84857-0</a>.</span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation book cs1" id="CITEREFMohriRostamizadehTalwalkar2012"><a href="/wiki/Mehryar_Mohri" title="Mehryar Mohri">Mohri, Mehryar</a>; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). <i>Foundations of Machine Learning</i>. USA, Massachusetts: MIT Press. <a class="mw-redirect" href="/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>\xc2\xa0<a href="/wiki/Special:BookSources/9780262018258" title="Special:BookSources/9780262018258"><bdi>9780262018258</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Foundations+of+Machine+Learning&amp;rft.place=USA%2C+Massachusetts&amp;rft.pub=MIT+Press&amp;rft.date=2012&amp;rft.isbn=9780262018258&amp;rft.aulast=Mohri&amp;rft.aufirst=Mehryar&amp;rft.au=Rostamizadeh%2C+Afshin&amp;rft.au=Talwalkar%2C+Ameet&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+learning+theory"></span><link href="mw-data:TemplateStyles:r982806391" rel="mw-deduplicated-inline-style"/></span>\n</li>\n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Tomaso Poggio, Lorenzo Rosasco, et al. <i>Statistical Learning Theory and Applications</i>, 2012, <a class="external text" href="https://www.mit.edu/~9.520/spring12/slides/class01/class01.pdf" rel="nofollow">Class 1</a></span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">Rosasco, L., Vito, E.D., Caponnetto, A., Fiana, M., and Verri A. 2004. <i>Neural computation</i> Vol 16, pp 1063-1076</span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">Vapnik, V.N. and Chervonenkis, A.Y. 1971. <a class="external text" href="http://ai2-s2-pdfs.s3.amazonaws.com/a36b/028d024bf358c4af1a5e1dc3ca0aed23b553.pdf" rel="nofollow">On the uniform convergence of relative frequencies of events to their probabilities</a>. <i>Theory of Probability and Its Applications</i> Vol 16, pp 264-280.</span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text">Mukherjee, S., Niyogi, P. Poggio, T., and Rifkin, R. 2006. <a class="external text" href="https://link.springer.com/article/10.1007/s10444-004-7634-z" rel="nofollow">Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization</a>. <i>Advances in Computational Mathematics</i>. Vol 25, pp 161-193.</span>\n</li>\n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Tomaso Poggio, Lorenzo Rosasco, et al. <i>Statistical Learning Theory and Applications</i>, 2012, <a class="external text" href="https://www.mit.edu/~9.520/spring12/slides/class02/class02.pdf" rel="nofollow">Class 2</a></span>\n</li>\n</ol></div></div>\n<!-- \nNewPP limit report\nParsed by mw1329\nCached time: 20201029235845\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.284 seconds\nReal time usage: 0.638 seconds\nPreprocessor visited node count: 879/1000000\nPost\xe2\x80\x90expand include size: 31044/2097152 bytes\nTemplate argument size: 1292/2097152 bytes\nHighest expansion depth: 16/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 9632/5000000 bytes\nLua time usage: 0.067/10.000 seconds\nLua memory usage: 2.77 MB/50 MB\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  496.101      1 -total\n 33.94%  168.400      1 Template:Machine_learning_bar\n 33.06%  164.001      1 Template:Sidebar_with_collapsible_lists\n 29.92%  148.437      1 Template:Reflist\n 29.49%  146.287      1 Template:About\n 15.29%   75.868      1 Template:Isbn\n 11.89%   58.965      1 Template:Cite_Mehryar_Afshin_Ameet_2012\n 11.21%   55.611      1 Template:Cite_book\n  8.77%   43.487      1 Template:Catalog_lookup_link\n  5.27%   26.142      1 Template:Longitem\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:1053303-0!canonical!math=5 and timestamp 20201029235844 and revision id 967208509\n -->\n</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript>\n<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;oldid=967208509">https://en.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;oldid=967208509</a>"</div></div>\n<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li><li><a href="/wiki/Category:Estimation_theory" title="Category:Estimation theory">Estimation theory</a></li></ul></div></div>\n</div>\n</div>\n<div id="mw-data-after-content">\n<div class="read-more-container"></div>\n</div>\n<div id="mw-navigation">\n<h2>Navigation menu</h2>\n<div id="mw-head">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-personal-label" class="mw-portlet mw-portlet-personal vector-menu" id="p-personal" role="navigation">\n<h3 id="p-personal-label">\n<span>Personal tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Statistical+learning+theory" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Statistical+learning+theory" title="You\'re encouraged to log in; however, it\'s not mandatory. [o]">Log in</a></li></ul>\n</div>\n</nav>\n<div id="left-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-namespaces-label" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" id="p-namespaces" role="navigation">\n<h3 id="p-namespaces-label">\n<span>Namespaces</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Statistical_learning_theory" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Statistical_learning_theory" rel="discussion" title="Discuss improvements to the content page [t]">Talk</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-variants-label" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" id="p-variants" role="navigation">\n<input aria-labelledby="p-variants-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-variants-label">\n<span>Variants</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n</div>\n<div id="right-navigation">\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-views-label" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" id="p-views" role="navigation">\n<h3 id="p-views-label">\n<span>Views</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="selected" id="ca-view"><a href="/wiki/Statistical_learning_theory">Read</a></li><li id="ca-edit"><a accesskey="e" href="/w/index.php?title=Statistical_learning_theory&amp;action=edit" title="Edit this page [e]">Edit</a></li><li id="ca-history"><a accesskey="h" href="/w/index.php?title=Statistical_learning_theory&amp;action=history" title="Past revisions of this page [h]">View history</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-cactions-label" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" id="p-cactions" role="navigation">\n<input aria-labelledby="p-cactions-label" class="vector-menu-checkbox" type="checkbox"/>\n<h3 id="p-cactions-label">\n<span>More</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"></ul>\n</div>\n</nav>\n<div id="p-search" role="search">\n<h3>\n<label for="searchInput">Search</label>\n</h3>\n<form action="/w/index.php" id="searchform">\n<div data-search-loc="header-navigation" id="simpleSearch">\n<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>\n<input name="title" type="hidden" value="Special:Search"/>\n<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search">\n<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>\n</input></div>\n</form>\n</div>\n</div>\n</div>\n<div id="mw-panel">\n<div id="p-logo" role="banner">\n<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>\n</div>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-navigation-label" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal portal-first" id="p-navigation" role="navigation">\n<h3 id="p-navigation-label">\n<span>Navigation</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Visit a randomly selected article [x]">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-interaction-label" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" id="p-interaction" role="navigation">\n<h3 id="p-interaction-label">\n<span>Contribute</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-tb-label" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" id="p-tb" role="navigation">\n<h3 id="p-tb-label">\n<span>Tools</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Statistical_learning_theory" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Statistical_learning_theory" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Statistical_learning_theory&amp;oldid=967208509" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Statistical_learning_theory&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Statistical_learning_theory&amp;id=967208509&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q7604400" title="Structured data on this page hosted by Wikidata [g]">Wikidata item</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-coll-print_export-label" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" id="p-coll-print_export" role="navigation">\n<h3 id="p-coll-print_export-label">\n<span>Print/export</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Statistical_learning_theory&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Statistical_learning_theory&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>\n</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav aria-labelledby="p-lang-label" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" id="p-lang" role="navigation">\n<h3 id="p-lang-label">\n<span>Languages</span>\n</h3>\n<div class="vector-menu-content">\n<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Th%C3%A9orie_de_l%27apprentissage_statistique" hreflang="fr" lang="fr" title="Th\xc3\xa9orie de l\'apprentissage statistique \xe2\x80\x93 French">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%ED%86%B5%EA%B3%84%EC%A0%81_%ED%95%99%EC%8A%B5%EC%9D%B4%EB%A1%A0" hreflang="ko" lang="ko" title="\xed\x86\xb5\xea\xb3\x84\xec\xa0\x81 \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4\xeb\xa1\xa0 \xe2\x80\x93 Korean">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F" hreflang="ru" lang="ru" title="\xd0\xa1\xd1\x82\xd0\xb0\xd1\x82\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd0\xba\xd0\xb0\xd1\x8f \xd1\x82\xd0\xb5\xd0\xbe\xd1\x80\xd0\xb8\xd1\x8f \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xe2\x80\x93 Russian">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D1%96%D1%8F_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BD%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F" hreflang="uk" lang="uk" title="\xd0\xa2\xd0\xb5\xd0\xbe\xd1\x80\xd1\x96\xd1\x8f \xd1\x81\xd1\x82\xd0\xb0\xd1\x82\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe \xd0\xbd\xd0\xb0\xd0\xb2\xd1\x87\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8f \xe2\x80\x93 Ukrainian">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-zh"><a class="interlanguage-link-target" href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA" hreflang="zh" lang="zh" title="\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe7\x90\x86\xe8\xae\xba \xe2\x80\x93 Chinese">\xe4\xb8\xad\xe6\x96\x87</a></li></ul>\n<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q7604400#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>\n</div>\n</nav>\n</div>\n</div>\n<footer class="mw-footer" id="footer" role="contentinfo">\n<ul id="footer-info">\n<li id="footer-info-lastmod"> This page was last edited on 11 July 2020, at 20:44<span class="anonymous-show">\xc2\xa0(UTC)</span>.</li>\n<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id="footer-places">\n<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>\n<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>\n<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>\n<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n</ul>\n<ul class="noprint" id="footer-icons">\n<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" loading="lazy" src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88"/></a></li>\n<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" loading="lazy" src="/static/images/footer/poweredby_mediawiki_88x31.png" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>\n</ul>\n<div style="clear: both;"></div>\n</footer>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.284","walltime":"0.638","ppvisitednodes":{"value":879,"limit":1000000},"postexpandincludesize":{"value":31044,"limit":2097152},"templateargumentsize":{"value":1292,"limit":2097152},"expansiondepth":{"value":16,"limit":40},"expensivefunctioncount":{"value":0,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":9632,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  496.101      1 -total"," 33.94%  168.400      1 Template:Machine_learning_bar"," 33.06%  164.001      1 Template:Sidebar_with_collapsible_lists"," 29.92%  148.437      1 Template:Reflist"," 29.49%  146.287      1 Template:About"," 15.29%   75.868      1 Template:Isbn"," 11.89%   58.965      1 Template:Cite_Mehryar_Afshin_Ameet_2012"," 11.21%   55.611      1 Template:Cite_book","  8.77%   43.487      1 Template:Catalog_lookup_link","  5.27%   26.142      1 Template:Longitem"]},"scribunto":{"limitreport-timeusage":{"value":"0.067","limit":"10.000"},"limitreport-memusage":{"value":2900607,"limit":52428800}},"cachereport":{"origin":"mw1329","timestamp":"20201029235845","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Statistical learning theory","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Statistical_learning_theory","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q7604400","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q7604400","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2004-10-09T22:10:29Z","dateModified":"2020-07-11T20:44:36Z","headline":"Wikimedia disambiguation page"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":151,"wgHostname":"mw1371"});});</script>\n</body></html>'